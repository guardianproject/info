<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Signing on Guardian Project</title>
    <link>https://guardianproject.github.io/info/tags/signing/</link>
    <description>Recent content in Signing on Guardian Project</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 15 Jul 2023 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://guardianproject.github.io/info/tags/signing/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>F-Droid&#39;s Community-controlled Backup Ceremony</title>
      <link>https://guardianproject.github.io/info/2023/07/15/f-droids-community-controlled-backup-ceremony/</link>
      <pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://guardianproject.github.io/info/2023/07/15/f-droids-community-controlled-backup-ceremony/</guid>
      <description>&lt;p&gt;(&lt;em&gt;Guest post from F-Droid, originally on &lt;a href=&#34;https://f-droid.org/2023/07/15/community-controlled-backup-ceremony.html&#34;&gt;f-droid.org&lt;/a&gt;&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;Seven core contributors and one board member met in Scotland, the birthplace of F-Droid, for the first in-person F-Droid team meeting.  One of the most pressing tasks we needed to take care of was setting up a contributor-controlled backup of all of our signing keys.  The requirements made it necessary to have a lengthy, in-person, consensus-driven planning session.  We found no good documentation of such a procedure, so we&amp;rsquo;re going out on a limb here and publishing the general outline of our process.  This process was informally audited by multiple people with varying expertise before the public key was used to encrypt anything.&lt;/p&gt;

&lt;p&gt;F-Droid manages secret signing keys for thousands of apps.  Someone who has control over those keys could create malicious app releases that could be transparently installed as updates.  On top of that, &lt;a href=&#34;https://developer.android.com/about/versions/pie/android-9.0#apk-key-rotation&#34;&gt;Android&lt;/a&gt; does &lt;a href=&#34;https://guardianproject.info/2015/12/29/how-to-migrate-your-android-apps-signing-key/&#34;&gt;not&lt;/a&gt; make it &lt;a href=&#34;https://anandbose.gitlab.io/android-development/2020/05/08/android-signing-key-rotation-explained/&#34;&gt;easy&lt;/a&gt; to rotate to new signing keys, unlike TLS or Signal. So &lt;a href=&#34;https://f-droid.org/docs/Signing_Process/&#34;&gt;these keys&lt;/a&gt; are very important to &lt;a href=&#34;https://f-droid.org/docs/Building_a_Signing_Server/&#34;&gt;protect&lt;/a&gt;.  They are also very important to backup, since the Android OS uses the signing key combined with the Application ID as the unique identifier to represent each installed app. This meeting gave us the perfect opportunity to create a new backup process that ensures that at least 4 trusted community members must be physically present in order to decrypt the backup of all the keys.  First, we started with the requirements:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Regular backups as new keys get added.&lt;/li&gt;
&lt;li&gt;Strong, proven encryption for all backups.&lt;/li&gt;
&lt;li&gt;Minimum of four participants to decrypt.&lt;/li&gt;
&lt;li&gt;Specific technical experience should not be required to be a participant.&lt;/li&gt;
&lt;li&gt;The components should be physically spread out across jurisdictions.&lt;/li&gt;
&lt;li&gt;Access should minimized as much as possible (e.g. the signing server maintainer does not need access to the backups).&lt;/li&gt;
&lt;li&gt;As low a stress level as possible for each participant.&lt;/li&gt;
&lt;li&gt;Each participant could hand over their component if they are forced to, without jeopardizing the encryption.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Then we mapped out who was present:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Seven core contributors.&lt;/li&gt;
&lt;li&gt;One board member.&lt;/li&gt;
&lt;li&gt;One trusted external witness.&lt;/li&gt;
&lt;li&gt;No one else.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From that, we built the process:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Three roles for physical control: operator of the signing server, encrypted backup holder, passphrase shard holder.&lt;/li&gt;
&lt;li&gt;Each person only takes on a single role, for example, shard holders do not have access to the signing keys or the encrypted backup.&lt;/li&gt;
&lt;li&gt;The encryption key used for the data is public key cryptography.&lt;/li&gt;
&lt;li&gt;The private key was generated on a one-time-use, in-memory, disposable &lt;a href=&#34;https://tails.boum.org/&#34;&gt;TAILS&lt;/a&gt; session.&lt;/li&gt;
&lt;li&gt;The private key was sharded using &lt;a href=&#34;https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing&#34;&gt;Shamir&amp;rsquo;s Secret Sharing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;We used an implementation of Shamir&amp;rsquo;s Secret Sharing that has been maintained for over 15 years.  The installation that was used was confirmed via reproducible builds.&lt;/li&gt;
&lt;li&gt;Each shard was written to a removeable storage device bought in a store with cash without pre-order or registration.&lt;/li&gt;
&lt;li&gt;Each removeable storage device with a shard was physically handed each shard holder to pack in a tamper-evident envelope as the others observed.&lt;/li&gt;
&lt;li&gt;Backups must not be transmitted over the internet, only exchanged via in-person meetings between people who know each other.&lt;/li&gt;
&lt;li&gt;All involved sat around a table for the duration of the ceremony.  The security profile of in-person discussions is drastically easier to manage than secure online discussions.&lt;/li&gt;
&lt;li&gt;All present were observers of each step of the process, and verbally confirmed their agreement.&lt;/li&gt;
&lt;li&gt;The operators of the signing server and the holders of the backup data verified each others&amp;rsquo; identities via F-Droid networks, PGP Web of Trust, and checks of government issued IDs.&lt;/li&gt;
&lt;li&gt;Pieces from a minimum of two jurisdictions are required to decrypt: EU, Europe non-EU, US.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One important factor in reliable backups is regular updates.  New apps are constantly being added, and those usually get a new signing key assigned.  So we needed a system where it was easy to update the backup data while involving as few people as possible.  An operator of the signing server receives the public key to encrypt the backups via in-person exchange with a holder of the backups.  The holders of the backup data receives the encrypted backups from an operator of the signing server via in-person exchange.&lt;/p&gt;

&lt;p&gt;Holding such important secrets also brings some unavoidable stresses to the people holding them. One key design goal was to create a protocol that did not add to the stress of any existing operators.  Furthermore, we aimed to keep the individual stress as low as possible for all roles in this protocol.  That makes it possible to empower volunteer contributors without overburdening them.&lt;/p&gt;

&lt;p&gt;For restoring, we agreed that it should happen in an in-person meeting.  The process requires three shard holders meet with one encrypted backup holder, then the results need be given to a signing server operator. Requiring an in-person meeting could delay the restore process, but the added trust seemed worth it.  So this is the default process.  We could still switch to partially online process if the need arises.  That would require the agreement of five participants.&lt;/p&gt;

&lt;p&gt;We believe this is a secure and reliable backup procedure for very sensitive data.  We welcome further scrutiny and plan to update the procedure as needed in a future meeting.&lt;/p&gt;

&lt;p&gt;(&lt;em&gt;Travel costs for this meeting were paid for by the &lt;a href=&#34;https://guardianproject.info/2022/02/05/decentralizing-distribution/&#34;&gt;FFDW-DVD grant&lt;/a&gt;.&lt;/em&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Decentralizing Distribution</title>
      <link>https://guardianproject.github.io/info/2022/02/05/decentralizing-distribution/</link>
      <pubDate>Sat, 05 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://guardianproject.github.io/info/2022/02/05/decentralizing-distribution/</guid>
      <description>

&lt;p&gt;Guardian Project has been awarded a grant from the &lt;a href=&#34;https://www.ffdweb.org/guardian-project-annoucement&#34;&gt;Filecoin Foundation for the Decentralized Web (FFDW)&lt;/a&gt; to work on decentralizing veracity and distribution (DVD).  FFDW‚Äôs Mission is to ‚Äúensure the permanent preservation of humanity‚Äôs most important information by stewarding the development of open source software and open protocols for decentralized data storage and retrieval networks.‚Äù  Filecoin is built on top of IPFS, which is &amp;ldquo;&lt;a href=&#34;https://docs.ipfs.io/concepts/what-is-ipfs/&#34;&gt;a distributed system for storing and accessing files&lt;/a&gt;&amp;rdquo;.  The distribution component of the FFDW-DVD project is focused on improving F-Droid&amp;rsquo;s free, open, and decentralized mobile app ecosystem.  On top of the flagship unified experience offered by this website and the F-Droid official app, F-Droid provides all the pieces for anyone to create, build, remix, publish, reproduce, redistribute and review mobile apps.&lt;/p&gt;

&lt;p&gt;This is important to F-Droid users because it means that they are not locked into F-Droid as the monopoly app provider.  The F-Droid community needs to stay responsive to its users because it is possible to fork all of F-Droid (okay, except for the signing keys üö´Œ®üìùüîëüòâ).  Decentralization is also important because each user has specific needs and wishes that potentially conflict with other users.  Many want only free software, but others are willing to compromise in key places, and still others have strong privacy needs that conflict with other users&amp;rsquo; favorite features.  Decentralized app repositories provide users that flexibility without having to move away from the main F-Droid infrastructure.&lt;/p&gt;

&lt;p&gt;We share the concerns about the walled garden approach to app stores. While their design may have been driven out of concern for security and simplicity, they have become a source of unbridled control, censorship and surveillance.  Smartphones are the primary computer for most and apps are the central mobile tool.  Centralized, locked down phones keep the real power of modern computing needlessly out of reach of most of the world&amp;rsquo;s population.  The FFDW-DVD project will push F-Droid forward towards realizing full support for customization, curation, mirroring, censorship circumvention, and peer-to-peer sharing.  We can provide a more free and less fragile solution for the sharing of capability and knowledge to all.  On top of that, this project will give us focused time to work on making our processes run more efficiently and reliably.&lt;/p&gt;

&lt;p&gt;IPFS and Filecoin are central to this mission.  IPFS has the potential to provide the plumbing for the entire F-Droid ecosystem.  It is a decentralized filesystem where files are accessible by their &lt;a href=&#34;https://docs.ipfs.io/concepts/hashing/&#34;&gt;hash&lt;/a&gt; compiled into a &lt;a href=&#34;https://docs.ipfs.io/concepts/content-addressing/&#34;&gt;Content Identifier (CID)&lt;/a&gt;.  That means the unique signature of each file can be used to fetch that file from IPFS, no matter where it is actually stored.  It can be stored on some server farm or the other smartphone next to you when on a mountain top.  If the IPFS storage is reachable and contains the CID you need, it can be retrieved.  Internet is not required.  Additionally, if a file is important to you, you can &amp;ldquo;&lt;a href=&#34;https://docs.ipfs.io/how-to/pin-files/&#34;&gt;pin&lt;/a&gt;&amp;rdquo; it in your own IPFS storage or pay someone else to do it using Filecoin.  As long as someone is interested in having a file publicly available, it can be maintained in IPFS, even if the original creator has taken it down.&lt;/p&gt;

&lt;p&gt;IPFS is working now, and services are using it, including &lt;a href=&#34;https://blog.archive.org/2021/04/01/filecoin-foundation-grants-50000-fil-to-the-internet-archive/&#34;&gt;archive.org&lt;/a&gt;.  But there is much work to be done before it really can replace current web hosting and file distribution methods.  That means we will integrate IPFS in a hybrid approach, and we are already reporting our experiences upstream to help improve IPFS.  F-Droid already supports repositories and mirrors, and IPFS will plug right into those channels.  This gives the F-Droid ecosystem another layer of resiliency and flexibility.&lt;/p&gt;

&lt;p&gt;Since the &amp;ldquo;decentralized web&amp;rdquo; includes all sorts of things, it is important to also mention things that we will &lt;a href=&#34;https://www.theregister.com/2021/12/06/the_dark_equation_of_harm/&#34;&gt;not&lt;/a&gt; be doing with this grant.  We are not looking at NFTs, blockchain, DAOs, smart contracts or related aspects of &amp;ldquo;&lt;a href=&#34;https://en.wikipedia.org/wiki/Web3&#34;&gt;Web3&lt;/a&gt;&amp;rdquo;.&lt;/p&gt;

&lt;h2 id=&#34;funded-work&#34;&gt;Funded work&lt;/h2&gt;

&lt;p&gt;This work is focused on strengthening F-Droid foundations while enabling repositories to be hosted on decentralized storage, while spreading our platform as a viable alternative for all kinds of users and organizations.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Break out and overhaul core client logic around publishing and consuming repositories.&lt;/li&gt;
&lt;li&gt;Make client logic into libraries to make it easy to embed repositories in any app that needs it.&lt;/li&gt;
&lt;li&gt;Add support for mirroring repositories onto both IPFS and Filecoin.&lt;/li&gt;
&lt;li&gt;Add support in F-Droid client to use mirrors and repositories hosted on IPFS and Filecoin.&lt;/li&gt;
&lt;li&gt;Improve F-Droid ‚Äúwhite labeling‚Äù.&lt;/li&gt;
&lt;li&gt;Enhance F-Droid client‚Äôs existing ‚Äúnearby‚Äù and ‚Äúapp swap‚Äù capabilities, including utilizing libp2p-based communication.&lt;/li&gt;
&lt;li&gt;Improve the capability and usability of publishing and distributing multimedia content (documents, presentations, photos, videos, map files, and more).&lt;/li&gt;
&lt;li&gt;Update F-Droid‚Äôs RepoMaker tool (for easy ‚Äúpoint and click‚Äù curation and publishing of app repos) and add support for IPFS publishing.&lt;/li&gt;
&lt;li&gt;Expand access to F-Droid repositories to non-Android devices and the mobile web (progressive web apps, content).&lt;/li&gt;
&lt;li&gt;Set up a full archive of the f-droid.org repository on IPFS.&lt;/li&gt;
&lt;li&gt;Expand outreach and assistance to software developers, media organization, tech companies and more to promote adoption of the F-Droid platform for their software, content and devices (example: Mozilla could easily run a Mozilla app store that includes all the Mozilla channels: releases, nightlies, etc.  They could also include a curated collection of reproducibly built apps that Mozilla approves of.  Someone who trusts Mozilla can then easily choose to only have access to the Mozilla-curated app store)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can follow the work funded under this grant by checking the &lt;code&gt;FFDW-DVD&lt;/code&gt; label on &lt;a href=&#34;https://gitlab.com/groups/fdroid/-/issues?scope=all&amp;amp;state=opened&amp;amp;label_name[]=FFDW-DVD&#34;&gt;issues&lt;/a&gt; and &lt;a href=&#34;https://gitlab.com/groups/fdroid/-/merge_requests?scope=all&amp;amp;state=opened&amp;amp;label_name[]=FFDW-DVD&#34;&gt;merge requests&lt;/a&gt; in GitLab.&lt;/p&gt;

&lt;p&gt;Our first priority is splitting out the core client pieces as standalone
libraries. We will take this opportunity to modernize the index format and
ensure it works well with IPFS.  That effort is tracked using the &lt;code&gt;index-v2&lt;/code&gt; label on &lt;a href=&#34;https://gitlab.com/groups/fdroid/-/issues?scope=all&amp;amp;state=opened&amp;amp;label_name[]=index-v2&#34;&gt;issues&lt;/a&gt; and &lt;a href=&#34;https://gitlab.com/groups/fdroid/-/merge_requests?scope=all&amp;amp;state=opened&amp;amp;label_name[]=index-v2&#34;&gt;merge requests&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a Signing Server</title>
      <link>https://guardianproject.github.io/info/2017/12/18/building-a-signing-server/</link>
      <pubDate>Mon, 18 Dec 2017 05:43:34 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2017/12/18/building-a-signing-server/</guid>
      <description>

&lt;p&gt;The Android APK signing model sets the expectation that the signing key will be the same for the entire lifetime of the app. That can be seen in the recommended lifetype of an Android signing key: &lt;a href=&#34;https://developer.android.com/studio/publish/app-signing.html#considerations&#34;&gt;20+ years&lt;/a&gt;. On top of that, it is difficult to &lt;a href=&#34;https://guardianproject.info/2015/12/29/how-to-migrate-your-android-apps-signing-key/&#34;&gt;migrate an app to a new key&lt;/a&gt;. Since the signing key is an essential part to preventing APKs from impersonating another, Android signing keys must be kept safe for the entire life of the app.&lt;/p&gt;

&lt;p&gt;The F-Droid repo signing keys follow a very similar model: the signing key is the essential way to safely identify an F-Droid repo. So the same considerations apply to F-Droid repo signing keys as to APK signing keys. This also provides some really useful benefits. Since the integrity of the repo index file and the APKs are guaranteed by the repo signature, the files can be delivered via whatever method is most convenient, and their integrity will be automatically verified by the F-Droid client app, the &lt;em&gt;f-droid.org&lt;/em&gt; deploy process, and Repomaker.&lt;/p&gt;

&lt;p&gt;This means the security burden is shifted from the online, public webserver to a private signing machine. Just keeping that machine out of the public eye goes a long way towards improving security. There are a number of additional measures that can be taken to further improve the security of the signing process. Here are some approaches, starting with the easiest and least security, and going on to more secure setups that require more work to setup and run. Signing is not an resource intensive process, so any machine will work, even a 10 year old, basic laptop. We recommend using a minimal &lt;a href=&#34;https://www.debian.org&#34;&gt;Debian&lt;/a&gt; install, and rebuilding the machine from scratch.&lt;/p&gt;

&lt;h3 id=&#34;automated-signing-server-with-with-hsm&#34;&gt;Automated Signing Server with with HSM&lt;/h3&gt;

&lt;p&gt;For a fully automated signing setup, the machine running the signing needs to be online and running. Ideally this machine would have no remote access, at the very least remote access should be very carefully controlled and monitored. A laptop makes it easy to work with even when remote access is disabled, since it provides a built-in keyboard and monitor. If remote access is required, then any basic PC will work fine. Using a Hardware Security Module (HSM) to store the keys prevents them from being stolen if the server is broken into. An attacker could only run the signing process on that server.&lt;/p&gt;

&lt;p&gt;Ideally, this machine would only be accessible via Tor. That hides the physical location of the server, and hides the traffic from network. This makes it much harder attackers to find the actual machine to attack.&lt;/p&gt;

&lt;p&gt;For the HSM, we recommend using &lt;a href=&#34;https://www.nitrokey.com/&#34;&gt;Nitrokey&lt;/a&gt; hardware, since they are free software/hardware, and provide a wide range of options. Use a separate machine to put the signing keys on HSM. A good HSM will keep an audit trail of how many signatures have been made, so that information could be used to create an automatic auditing process to raise alarms if too many signatures have been made. That could mean that this server was breached and used to sign unauthorized packages.&lt;/p&gt;

&lt;p&gt;Other possibility it to use a setup like &lt;a href=&#34;https://pagure.io/sigul&#34;&gt;Fedora&lt;/a&gt;‚Äòs &lt;a href=&#34;http://www.devops-blog.net/koji/gpg-signing-rpms-with-sigul-signing-server-koji-integration&#34;&gt;Sigul&lt;/a&gt; that involves three machines.&lt;/p&gt;

&lt;h3 id=&#34;basic-laptop-dedicated-to-signing&#34;&gt;Basic laptop dedicated to signing&lt;/h3&gt;

&lt;p&gt;Start with a laptop that can be wiped clean and rebuilt from scratch. What is most important is that only the essential software is installed on it, and nothing else. Do not include any browser at all, for example, since that is the most common vector of attack. No remote access setup (e.g. SSH or VNC) should be installed or configured. To sign apps and repos, someone would take out this laptop, connect it to the network, and run the signing process. The signed results can then be published via the network connection. When the signing is complete, the machine can be turned off and disconnected and kept in a safe place.&lt;/p&gt;

&lt;p&gt;This could be made quite automatic with some custom scripts. The person running the process would only need to take out the machine, connect it, turn it on, wait until the process completes, then put it all away again.&lt;/p&gt;

&lt;h3 id=&#34;fully-offline-signing-laptop-with-usb-thumb-drives&#34;&gt;Fully offline signing laptop with USB thumb drives&lt;/h3&gt;

&lt;p&gt;_&lt;strong&gt;update&lt;/strong&gt;: apt-offline has a &lt;a href=&#34;https://bugs.debian.org/871656&#34;&gt;security bug&lt;/a&gt; so it was removed from Debian/buster. It is no longer recommended! Instead, use the Debian &amp;ldquo;&lt;a href=&#34;https://www.debian.org/doc/manuals/apt-offline&#34;&gt;apt offline&lt;/a&gt;&amp;rdquo; setup._&lt;/p&gt;

&lt;p&gt;This process is based on the same basic, stripped down laptop as the previous example. But this time, the networking should be entirely disabled before the install process. For example, it is easy in many laptops to physically remove the WiFi card. Therefore, it makes sense to use a laptop that does not include an ethernet jack, which are usually not possible to remove. Otherwise, blacklisting all kernel modules related to neworking can suffice. Since this machine is fully offline, the extra work of using an HSM is not as important, but it can‚Äôt hurt to include it.&lt;/p&gt;

&lt;p&gt;Download the full &amp;ldquo;CD&amp;rdquo; or &amp;ldquo;DVD&amp;rdquo; image of Debian to run the install. Be sure to &lt;a href=&#34;https://www.debian.org/CD/verify&#34;&gt;verify&lt;/a&gt; the GPG signatures and the SHA-256 hashes. One essential utility is &lt;em&gt;apt-offline&lt;/em&gt;, which automates the process of downloading Debian packages, verifying their signatures, and copying them over to an offline machine.&lt;/p&gt;

&lt;p&gt;To be extra careful, all of the software used should be verified. Chromebooks are nice, cheap laptops that run Linux natively. They also use Coreboot for the BIOS.&lt;/p&gt;

&lt;p&gt;&lt;li id=&#34;buy-a-computer-off-the-shelf-with-cash-avoid-having-it-shipped-especially-across-borders&#34;&gt;
  Buy a computer off the shelf with cash, avoid having it shipped, especially across borders
&lt;/li&gt;
&lt;li id=&#34;buy-a-debian-supported-chromebook-with-removeable-wifi-hardware-and-needs-no-binary-blobs&#34;&gt;
  Buy a Debian-supported &lt;a href=&#34;https://www.chromium.org/chromium-os/developer-information-for-chrome-os-devices/acer-c720-chromebook&#34;&gt;Chromebook&lt;/a&gt; with removeable WiFi hardware, and needs no binary blobs
&lt;/li&gt;
&lt;li id=&#34;install-a-reproducibly-built-coreboot-binary&#34;&gt;
  Install a reproducibly built coreboot binary
&lt;/li&gt;
&lt;li id=&#34;install-from-a-reproducibly-built-debian-image-wiping-out-chrome-os-entirely&#34;&gt;
  Install from a reproducibly built Debian image, wiping out Chrome OS entirely
&lt;/li&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-physical-environment&#34;&gt;The Physical Environment&lt;/h2&gt;

&lt;p&gt;The last thing to consider is the physical location where signatures happen, and where essential equipment is stored. The signing environment must be physically secure. Otherwise, there is no way to prevent laptops or HSMs from being lost or used to sign inappropriate content. For the offline machines, keeping them in a locked room is a good start. For an online machine, forcing all network traffic and remote access over Tor hides the physical location of the machine from network observers.&lt;/p&gt;

&lt;p&gt;For high risk signing keys, using multiple layers of defense is important:&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Restricted physical access to HSMs or smart cards&lt;/li&gt;
&lt;li&gt;Security cameras&lt;/li&gt;
&lt;li&gt;Onsite security guards&lt;/li&gt;
&lt;li&gt;Visitor logging&lt;/li&gt;
&lt;li&gt;A tools-resistant server safe for online code-signing servers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The signing server should be physically separate from the rest of the infrastructure. And the logs, machine, and network should be periodically audited.&lt;/p&gt;

&lt;h2 id=&#34;difficult-decisions&#34;&gt;Difficult decisions&lt;/h2&gt;

&lt;p&gt;Ideally all of these practices would be put into place, but each of these security measures comes at a cost of difficulty, expense, and complexity. They can also delay the process of getting regular updates out. So there are risks of implementing too strict security policies, much like the risks of not implementing enough.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Build Android apps with Debian: apt install android-sdk</title>
      <link>https://guardianproject.github.io/info/2017/03/13/build-android-apps-with-debian-apt-install-android-sdk/</link>
      <pubDate>Mon, 13 Mar 2017 10:03:30 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2017/03/13/build-android-apps-with-debian-apt-install-android-sdk/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2015/04/debian.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2015/04/debian-150x150.jpg&#34; alt=&#34;&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;alignright size-thumbnail wp-image-12920&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2015/04/debian-150x150.jpg 150w, https://guardianproject.info/wp-content/uploads/2015/04/debian-300x300.jpg 300w, https://guardianproject.info/wp-content/uploads/2015/04/debian-270x270.jpg 270w, https://guardianproject.info/wp-content/uploads/2015/04/debian-230x230.jpg 230w, https://guardianproject.info/wp-content/uploads/2015/04/debian.jpg 600w&#34; sizes=&#34;(max-width: 150px) 100vw, 150px&#34; /&gt;&lt;/a&gt;&lt;br /&gt;
In Debian stretch, the upcoming new release, it is now possible to build Android apps using only packages from Debian. This will provide all of the tools needed to build an Android app targeting the ‚Äúplatform‚Äù &lt;tt&gt;android-23&lt;/tt&gt; using the SDK &lt;tt&gt;build-tools&lt;/tt&gt; 24.0.0. Those two are the only versions of ‚Äúplatform‚Äù and ‚Äúbuild-tools‚Äù currently in Debian, but it is possible to use the Google binaries by installing them into &lt;tt&gt;/usr/lib/android-sdk&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;This doesn‚Äôt cover yet all of the libraries that are used in the app, like the Android Support libraries, or all of the other myriad libraries that are usually fetched from jCenter or Maven Central. One big question for us is whether and how libraries should be included in Debian. All the Java libraries in Debian can be used in an Android app, but including something like Android Support in Debian would be strange since they are only useful in an Android app, never for a Debian app.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Building apps with these packages&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Here are the steps for building Android apps using Debian‚Äôs Android SDK on Stretch.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;sudo apt install android-sdk android-sdk-platform-23&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;export ANDROID_HOME=/usr/lib/android-sdk&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In &lt;em&gt;build.gradle&lt;/em&gt;, set &lt;em&gt;compileSdkVersion&lt;/em&gt; to 23 and &lt;em&gt;buildToolsVersion&lt;/em&gt; to 24.0.0&lt;/li&gt;
&lt;li&gt;run &lt;code&gt;gradle assembleDebug&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The Gradle Android Plugin is also packaged. Using the Debian package instead of the one from online Maven repositories requires a little configuration before running Gradle. In the &lt;em&gt;buildscript&lt;/em&gt; block:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;add &lt;tt&gt;maven { url &amp;lsquo;file:///usr/share/maven-repo&amp;rsquo; }&lt;/tt&gt; to repositories&lt;/li&gt;
&lt;li&gt;use &lt;tt&gt;compile &amp;lsquo;com.android.tools.build:gradle:debian&amp;rsquo;&lt;/tt&gt; to load the plugin&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Currently there is only the target platform of API Level 23 packaged, so only apps targeted at &lt;em&gt;android-23&lt;/em&gt; can be built with only Debian packages. We will add more API platform packages via backports. Only &lt;em&gt;build-tools&lt;/em&gt; 24.0.0 is available, so in order to use the SDK, build scripts need to be modified. Beware that the Lint in this version of Gradle Android Plugin is still problematic, so running the :lint tasks might not work. They can be turned off with &lt;tt&gt;lintOptions.abortOnError&lt;/tt&gt; in &lt;em&gt;build.gradle&lt;/em&gt;. Google binaries can be combined with the Debian packages, for example to use a different version of the platform or build-tools.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why include the Android SDK in Debian?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;While Android developers could develop and ship apps right now using these Debian packages, this is not very flexible since only &lt;tt&gt;build-tools-24.0.0&lt;/tt&gt; and &lt;tt&gt;android-23&lt;/tt&gt; platform are available. Currently, we are not aiming to cover the most common use cases. Those are pretty well covered by Google‚Äôs binaries (except for the proprietary license on the Google binaries), and are probably the most work for the Debian Android Tools Team to cover. We are first working on use cases that are poorly covered by the Google binaries, for example, like where only specific parts of the whole SDK are used. Here are some we have in mind:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;tools for security researchers, forensics, reverse engineering, etc. which can then be included in live CDs and distros like Kali Linux&lt;/li&gt;
&lt;li&gt;a hardened APK signing server using &lt;em&gt;apksigner&lt;/em&gt; that uses a standard, audited, public configuration of all reproducibly built packages&lt;/li&gt;
&lt;li&gt;Replicant is a 100% free software Android distribution, so of course &lt;a href=&#34;http://blog.replicant.us/2017/02/replicant-6-0-development-updates/&#34; target=&#34;_blank&#34;&gt;they want to have a 100% free software SDK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;high security apps need a build environment that matches their level of security, the Debian Android Tools packages are &lt;a href=&#34;https://reproducible-builds.org&#34; target=&#34;_blank&#34;&gt;reproducibly built&lt;/a&gt; only from publicly available sources&lt;/li&gt;
&lt;li&gt;dead simple install with strong trust path with mirrors all over the world&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the long run, the &lt;a href=&#34;https://wiki.debian.org/AndroidTools&#34; target=&#34;_blank&#34;&gt;Debian Android Tools Team&lt;/a&gt; aims to cover more use cases well, and also building the Android NDK. This all will happen more quickly if we have more contributors! Android is the most popular mobile OS, and can be 100% free software like Debian. Debian and its derivatives are one of the most popular platforms for Android development.&lt;/p&gt;

&lt;p&gt;Last but not least, we want feedback on how this should all work. For example, we need ideas for how to nicely integrate Debian‚Äôs Java libraries into the Android &lt;em&gt;gradle&lt;/em&gt; workflow. And ideally, the Android Support libraries would also be reproducibly built and packaged somewhere that enforces only free software.&lt;/p&gt;

&lt;p&gt;For anyone interested in tools for working with Android apps and APKs, including for reverse engineering, inspection, auditing, etc. there are quite a few tools included now in Debian:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;apt install android-sdk androguard apktool diffoscope dummydroid enjarify gplaycli libsmali-java libscout repo&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Build Your Own App Store: Android Media Distribution for Everyone</title>
      <link>https://guardianproject.github.io/info/2017/02/22/build-your-own-app-store-android-media-distribution-for-everyone/</link>
      <pubDate>Wed, 22 Feb 2017 09:45:11 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2017/02/22/build-your-own-app-store-android-media-distribution-for-everyone/</guid>
      <description>

&lt;p&gt;Most people get their Android apps from Google Play. It is usually the simplest and most secure option for them. But there are also many people who do not have access to Google Play. This might be due to lack of a proper internet connection or simply because Google Play is blocked within their country.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://f-droid.org/&#34;&gt;F-Droid&lt;/a&gt; project already offers &lt;a href=&#34;https://guardianproject.github.io/info/2015/06/02/building-a-trustworthy-app-store-that-respects-privacy/&#34;&gt;tools to create independent app distribution channels for Android apps&lt;/a&gt;. These tools are ready for production, but require expert knowledge and the command-line to be used. Now, we want to build upon this foundation and develop curation tools that can also be used by people with little technical knowledge, thus making the app distribution technology more broadly available.&lt;/p&gt;

&lt;h3 id=&#34;use-cases&#34;&gt;Use-Cases&lt;/h3&gt;

&lt;p&gt;The primary use-case we want to address is to circumvent app store censorship and blocking. But there are other use-cases that benefit from easy-to-setup app stores as well.&lt;/p&gt;

&lt;p&gt;There are Android phones and tablets that do not have Google Play available, either because their manufacturer did not get a license from Google or because their owners prefer their phones Google-free.&lt;/p&gt;

&lt;p&gt;Similar to Apple‚Äôs app store, the terms of service of Google Play exclude certain apps from being distributed and these are being removed on a regular basis. Having alternative means for distribution of apps is often the only way to bring those apps to people.&lt;/p&gt;

&lt;h3 id=&#34;features&#34;&gt;Features&lt;/h3&gt;

&lt;h4 id=&#34;core-features&#34;&gt;Core Features&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Create a new app repository&lt;/li&gt;
&lt;li&gt;Add new apps/media to the repository&lt;/li&gt;
&lt;li&gt;Update existing apps/media to the repository&lt;/li&gt;
&lt;li&gt;Update the description and metadata of apps/media&lt;/li&gt;
&lt;li&gt;Remove apps/media from the repository&lt;/li&gt;
&lt;li&gt;Automatic generation of repository website with QR Code (and instructions)&lt;/li&gt;
&lt;li&gt;Import apps directly from other repositories&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;optional-future-features&#34;&gt;Optional Future Features&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Archive apps/media to archive repository&lt;/li&gt;
&lt;li&gt;Remove installed apps/media from user‚Äôs devices&lt;/li&gt;
&lt;li&gt;Provide hosted web-app with user-management (Sign-Up, Lost Password) as a service&lt;/li&gt;
&lt;li&gt;Allow multiple curators to manage the same repository&lt;/li&gt;
&lt;li&gt;Import apps (and their description) from Google Play&lt;/li&gt;
&lt;li&gt;Check for updates from Google Play periodically and automatically import them&lt;/li&gt;
&lt;li&gt;Making the repository available through the Tor network&lt;/li&gt;
&lt;li&gt;Generate custom white-labelled repository app (based on F-Droid)&lt;/li&gt;
&lt;li&gt;App security scanner for vulnerable libraries and Virus Total (opt-in) upload&lt;/li&gt;
&lt;li&gt;App browsing and download on generated repository website&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;target-audience&#34;&gt;Target Audience&lt;/h3&gt;

&lt;p&gt;The main audience for this work are activists and trainers with moderate technical knowledge who need to securely distribute apps and updates to their community. This is especially a concern in countries where the official app store is blocked. Organizations like Amnesty International for example still need to enable people in those countries to securely receive their apps and updates.&lt;/p&gt;

&lt;p&gt;The person maintaining the repository might use any operating system and in some cases might not even have a laptop/desktop computer available. They might be targeted by advanced attackers that can intercept and insert arbitrary traffic, but do not have the ability to compromise large service providers such as Amazon.&lt;/p&gt;

&lt;p&gt;Furthermore, this work might also be used by the following groups:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;service providers (who want own distribution and update mechanism for their apps)&lt;/li&gt;
&lt;li&gt;individual software developers (who want to distribute beta releases for e.g. user-testing)&lt;/li&gt;
&lt;li&gt;everybody else who needs full control of the entire distribution and update process&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;implementation-options&#34;&gt;Implementation Options&lt;/h3&gt;

&lt;p&gt;There are roughly four different ways, the app store curation tool could be implemented. Each has their own pro and cons as well as different implications for the usability.&lt;/p&gt;

&lt;h4 id=&#34;command-line-interface&#34;&gt;Command-line interface&lt;/h4&gt;

&lt;p&gt;The current app repository tools are already used via the command-line, but they require some setup and several non-intuitive commands to be executed. The goal here would be to reduce the number of required commands as much as possible and make them easy to understand and remember. This would be similar to how Letsencrypt‚Äôs Certbot simplified SSL certificate management.&lt;/p&gt;

&lt;p&gt;Pros&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;least amount of work building directly on existing tools&lt;/li&gt;
&lt;li&gt;signing key could be created and stored on local device&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;too difficult to use for people with no prior command-line experience&lt;/li&gt;
&lt;li&gt;off-putting and not inviting for potential non-expert curators&lt;/li&gt;
&lt;li&gt;adds little benefit to existing solution&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;cross-platform-desktop-application&#34;&gt;Cross-Platform Desktop Application&lt;/h4&gt;

&lt;p&gt;A graphical user interface (GUI) could be added to the existing tools to make them easier to use. Existing UI toolkits such as Qt, Gtk or Tcl/Tk could be used for this.&lt;/p&gt;

&lt;p&gt;Pros&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;can make use of existing python tools&lt;/li&gt;
&lt;li&gt;signing key could be created and stored on local device&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;requires a desktop computer and installation procedure (possibly of dependencies as well)&lt;/li&gt;
&lt;li&gt;need to maintain and support install packages for Windows and MacOS&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;android-app&#34;&gt;Android App&lt;/h4&gt;

&lt;p&gt;The free software &lt;a href=&#34;https://f-droid.org&#34;&gt;F-Droid app&lt;/a&gt; already includes repository functionality used for direct app swapping. This could be modified to publish repositories to remote servers and extended by curation functionality. Alternatively, a new app could be developed that is dedicated to repository curation and could contrary to F-Droid even be distributed via Google Play.&lt;/p&gt;

&lt;p&gt;Pros&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Simple installation&lt;/li&gt;
&lt;li&gt;No desktop computer required&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Needs reimplementation of existing Python code in Java&lt;/li&gt;
&lt;li&gt;Signing key stored on potentially less secure mobile device&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;web-app&#34;&gt;Web App&lt;/h4&gt;

&lt;p&gt;The user interface for repository curation could be implemented as a web application that is accessed through a web browser. Low-risk curators could use a hosted instance for maximum simplicity while others could also access the interface through a local (built-in) web-server. Powerful web frameworks such as Flask or Django might be a good choice for that job.&lt;/p&gt;

&lt;p&gt;Pros&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Very easy to use from every device&lt;/li&gt;
&lt;li&gt;Does not need installation (lower usage barrier)&lt;/li&gt;
&lt;li&gt;Can make use of existing python tools&lt;/li&gt;
&lt;li&gt;Makes multi-curator feature potentially easier to implement&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In hosted mode: signing keys need to be stored permanently on a web server&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;security-considerations&#34;&gt;Security Considerations&lt;/h3&gt;

&lt;h4 id=&#34;repository-attacks&#34;&gt;Repository Attacks&lt;/h4&gt;

&lt;p&gt;The technology used for app distribution needs to ensure the integrity and authenticity of apps provided in the repository. It can not prevent malicious apps from being &lt;em&gt;intentionally&lt;/em&gt; distributed, but can offer a security scanner to reduce the risk of unintentional distribution. An attack is considered successful when the content provided by the curator of the repository can be altered so that the changes propagate to users‚Äô devices.&lt;/p&gt;

&lt;p&gt;Malicious apps might compromise the targeted application or the entire phones (root exploit). There are two defenses against unintentional distribution of malicious apps:&lt;/p&gt;

&lt;ol type=&#34;1&#34;&gt;
  &lt;li&gt;
    app package signatures: clients trust the provided app signature on first installation (TOFU) and refuse updates with a different signature.
  &lt;/li&gt;
  &lt;li&gt;
    repository signature: clients check signature when repository is installed and with every update. They warn and refuse operations with the repository when the signature is invalid.
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first defense is out of scope for this work, because app packages are signed when the app is built so that they are already signed when added to the repository. The repository curation should still not allow to publish an update that carries a different signature.&lt;/p&gt;

&lt;p&gt;The second defense needs to be provided automatically by the curation tools. A repository signing key needs to be created and securely stored. If this key is compromised, an attacker can modify app metadata and can inject modified apps for specific or all users when they install them for the first time. Malicious updates of already installed apps are prevented by above package signature.&lt;/p&gt;

&lt;p&gt;If the repository key is created and stored automatically by a service (see implementation option 4), the curator needs to trust the service and the hosting provider. Both need to be out of reach of attackers from the curators‚Äô threat-model. For example, if the Guardian Project provides a repository service hosted in Amazon‚Äôs Cloud, this service should be out of reach of most attackers that have neither the ability to compromise the Guardian Project, nor Amazon. Advanced nation-state adversaries could compromise both and thus the repository. Recipients of apps need to trust their distributors/curators and their ability to keep their own system secure.&lt;/p&gt;

&lt;p&gt;However, we can generally not protect against attackers who has the ability to directly compromise the users‚Äô devices. All that can be done is to prevent malicious applications from being installed &lt;em&gt;via the repository&lt;/em&gt; (without knowledge of the curator). If the attacker can compromise users‚Äô devices through other means, this defense does not matter anymore.&lt;/p&gt;

&lt;h4 id=&#34;root-and-unknown-sources&#34;&gt;Root and Unknown Sources&lt;/h4&gt;

&lt;p&gt;In order to get content from the provided repository onto a generic device, the user needs to install F-Droid which requires allowing the installation of apps from unknown sources. This can put the user at risk, because it makes installing malicious application very easy. Alternatively, super user privileges (root) can be used to install F-Droid‚Äôs system extension effectively trusting all apps installed via F-Droid. However, the security risks associated with super user privileges are even more severe as they can lead to compromise of the entire device.&lt;/p&gt;

&lt;h4 id=&#34;lack-of-updates&#34;&gt;Lack of Updates&lt;/h4&gt;

&lt;p&gt;If a repository is the user‚Äôs sole source for an application, any delay in providing updates might put the user at risk of an adversary exploiting a vulnerability in that application that would have otherwise been fixed by the missing update.&lt;/p&gt;

&lt;h3 id=&#34;what-we-will-do&#34;&gt;What We Will Do&lt;/h3&gt;

&lt;p&gt;The main goal of the curation tools is to make creating and maintaining repositories as easy as possible for our target audience.&lt;/p&gt;

&lt;p&gt;This rules out the command line and the desktop application, since today‚Äôs user experience expectations are no longer being fulfilled by these technologies. While a desktop application comes closer, the need for an installation procedure and for maintaining it for different operating systems makes it too difficult and error-prone compared to the two other remaining options.&lt;/p&gt;

&lt;p&gt;Implementing the curation tools within an Android application has its merits. It comes with an easy installation procedure, provides a familiar state-of-the-art user interface and allows apps to be added directly from the curators‚Äô device. However, some existing functionality would need to be reimplemented in Java and maintained along-side the existing Python codebase. Also the curator needs to provide an external storage location for the repository which can be a barrier for many users and needs its own documentation.&lt;/p&gt;

&lt;p&gt;The easiest and most flexible solution is a web-application based on the existing Python tools. More advanced curators can use it on a local desktop computer with a built-in web-server just like a desktop application, only that the UI is in the browser. This usage scenario comes with the same pros and cons like the desktop application. The repository signing key for example is stored locally under the curator‚Äôs control.&lt;/p&gt;

&lt;p&gt;But it allows for other usage scenarios as well. If installed on a trusted web-server as a service, the curation tools can also be used by curators with little technical knowledge. The curators don‚Äôt need to install anything and can use them from any device. They can even switch devices without a data migration. However, they would need to give up control over the signing key.&lt;/p&gt;

&lt;p&gt;If time permits, the app store creator can be turned into a full repository service that allows user registrations and several repositories per user. A trusted organization such as the Guardian Project could host this as a service and provide it to an activist community. Software freedom would allow other organizations to host their own repository services as well. You can imagine the activist collective Riseup for example not only hosting its own repository of recommended apps, but also allowing its users to create and curate their own repositories.&lt;/p&gt;

&lt;p&gt;This becomes even more interesting when people fill their repositories not only with apps, but with all sorts of files such as books, music and photos.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building the most private app store</title>
      <link>https://guardianproject.github.io/info/2016/06/02/building-the-most-private-app-store/</link>
      <pubDate>Thu, 02 Jun 2016 11:08:52 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2016/06/02/building-the-most-private-app-store/</guid>
      <description>&lt;p&gt;&lt;em&gt;App stores can work well without any tracking at all&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2016/06/whichdoor.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2016/06/whichdoor-150x150.jpg&#34; alt=&#34;whichdoor&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;alignright size-thumbnail wp-image-13337&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Attackers are increasingly seeing app stores as a prime &lt;a href=&#34;https://guardianproject.info/2015/02/24/phishing-for-developers/&#34; target=&#34;_blank&#34;&gt;attack&lt;/a&gt; vector, whether it is aimed at the masses like &lt;a href=&#34;http://researchcenter.paloaltonetworks.com/2015/09/more-details-on-the-xcodeghost-malware-and-affected-ios-apps/&#34;&gt;XCodeGhost&lt;/a&gt; or very targeted like in FBI vs Apple. When we install software from an app store, we are placing a lot of trust in a lot of different parties involved in getting the source code from the original developer delivered to our device in a useful form. Most people are entirely unaware of how much trust they are putting into this system, which they are entrusting with their personal data. Even for people who do understand the technical details involved, figuring out whether the people and the system itself is trustworthy is difficult to do.&lt;/p&gt;

&lt;p&gt;We are building an app store that requires the bare minimum of trust: only the software developers themselves and the code they produce. We consider the app store operators and servers a threat. Building an ecosystem that enables automated, effective auditing lets the computers verify to make trust decisions easier. Effective external auditing requires an ecosystem that cannot deliver targeted content to just the auditing system, while feeding users something else (aka ‚Äúbinary transparency‚Äù).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Most app stores track as much as possible&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The vast majority of apps stores track their users actions in detail. Some is necessary when using the business model of the app store operator taking a percentage of sales, but none of the tracking is inherent to running an app store. For example, payment verification can be handled in the app itself like shareware. A software delivery system that tracks its users makes it simple to hide malware delivery since it can target any auditing system. Most app stores know a lot about their users:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;account name&lt;/li&gt;
&lt;li&gt;identity&lt;/li&gt;
&lt;li&gt;payment methods&lt;/li&gt;
&lt;li&gt;everything you search for in the app store&lt;/li&gt;
&lt;li&gt;everything you look at in the app store&lt;/li&gt;
&lt;li&gt;everything you download, install, uninstall&lt;/li&gt;
&lt;li&gt;which apps you actually run&lt;/li&gt;
&lt;li&gt;where you are, based on IP, declared preference, etc.&lt;/li&gt;
&lt;li&gt;your preferred language&lt;/li&gt;
&lt;li&gt;and more‚Ä¶&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Apps stores need to know very little in order to function: how to give you the files you request. That means indexes, descriptions, icons, apps, and install/delete requests (for ‚Äúpush‚Äù install/delete). Given that information, the client can do everything needed to provide a full app store user experience. For this work, we chose to build upon &lt;a href=&#34;https://f-droid.org&#34; target=&#34;_blank&#34;&gt;F-Droid&lt;/a&gt;, a community-run Android app store that distributes verified Free Software. The community has had an interest in privacy all along, and has always worked to avoid tracking. The security architecture is based on models proven by &lt;a href=&#34;https://wiki.debian.org/SecureApt&#34; target=&#34;_blank&#34;&gt;Debian&lt;/a&gt;, &lt;a href=&#34;https://github.com/theupdateframework/tuf/blob/develop/docs/tuf-spec.txt&#34; target=&#34;_blank&#34;&gt;The Update Framework&lt;/a&gt; , and others:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HTTPS connections by default&lt;/li&gt;
&lt;li&gt;pinned TLS certificate built into the client app&lt;/li&gt;
&lt;li&gt;updates verified based on the signature on the app itself&lt;/li&gt;
&lt;li&gt;file integrity protected by signed metadata&lt;/li&gt;
&lt;li&gt;signed metadata includes hashes of the app and its signing key&lt;/li&gt;
&lt;li&gt;signed metadata generated on a separate machine, which can be fully offline&lt;/li&gt;
&lt;li&gt;public key for verifying metadata signatures built into F-Droid client app&lt;/li&gt;
&lt;li&gt;signed metadata includes timestamp and expiry&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While the current setup is already a solid platform, we are implementing a number of improvements. The signed metadata will include list of official mirrors, then the client chooses mirrors based on availability and freshness based on local criteria like whether Tor is in use, closest on the internet, etc. We are also moving the standard HTTP ‚Äúetag‚Äù cache check from the server to the client so it cannot be abused to track users.&lt;/p&gt;

&lt;p&gt;In order to defend against an attacker that holds the signing keys for the app repository, there must be a trustworthy source of information to compare against. Reproducible builds means that anyone with the same source code will produce the exact same binary. When paired with an auditing system, it is easy to catch malware inserted in the build process, rather than the source code, like XCodeGhost. Reproducible builds also makes it possible to have all builds of a release binary have the exact same hash. Then any app repository can build apps only from source code, and have a source of verification data from any other app repository building the same app. Building software from source has become cheap enough that many companies like gitlab.com and Travis CI are offering free, automated build services in the cloud. Since the whole F-Droid toolset is free software and designed to be easy to setup, the barriers to setting up automatic auditing are quite low. People in separate areas of the world with different risk profiles can run verification servers to provide more trustworthy information.&lt;/p&gt;

&lt;p&gt;Another key aspect of the F-Droid project is to provide the complete toolset needed to run an app store. This enables a more decentralized ecosystem. Therefore, one key goal is to lower the risks of running the services, so that more people can run their own app stores. If the app store does not track its users, then that removes the hassle of protecting personal data from any attacker. These services can be run without fear of responding to secret orders for personal information. It also means that the server setup is a lot simpler because it does not need dynamic content. The app store serve only needs to serve files (e.g. indexes, apps, etc.). The app repository is generated on a secure machine, or even a fully offline machine, and posted to the server. The main server is purely a mirror of the offline machine where the signed repository is generated. Mirrors just shuffle bits from place to place, they are no longer an attack vector.&lt;/p&gt;

&lt;p&gt;Putting all these pieces together provides a system where users need only audit the source code in order to verify a trustworthy app delivery. The file pipeline provides redundantly secure data transmission, the apps can be reproducibly from source code, the app repositories can be automatically audited. Of course, this system relies not only on the power of cryptography, but also the power of transparency. Debian provides a great example of the power of transparency: Debian gives a thousand volunteers root access to every Debian install (by virtue of their ability to upload signed packages that get installed as root). Yet this system has been proven over the past 20+ years to provide solid security. Ultimately we hope that this will de-emphasize the signing key as the sole protection against abuse. If malware has a decent change of being spotted, it makes it much less likely to be used since malware authors either rigorously defend their exploits, or use well known exploits that are not difficult to automatically detect.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Future Work&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;One attack vector that is not well covered is malware that installable by everyone, that then uses data on the local device to target specific users. That would be a way to target individuals using an app store that does not track its users. We are starting to implement automated dynamic analysis of every app using tools like &lt;a href=&#34;https://labs.mwrinfosecurity.com/tools/drozer&#34; target=&#34;_blank&#34;&gt;Drozer&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We are also working towards making as many apps as possible build reproducibly. Some of our quick checks show that a large number of the apps in f-droid.org already will build reproducibly, given the right build environment. We are working on making the process of setting up that build environment as automated as possible.&lt;/p&gt;

&lt;p&gt;The F-Droid ‚Äúverification server‚Äù has been prototyped, and it will be further developed with the aim of making it dead simple to run in common cloud services.&lt;/p&gt;

&lt;p&gt;We already have the infrastructure in place to do verified double-signing, where the developer first signs the release bulid, then once f-droid.org reproduces that build, it adds its signature. Then Android would enforce that both signatures need to be present in order for it to be a valid update.&lt;/p&gt;

&lt;p&gt;As the full localization support is built out, the language that a user is using will not be reported to the server. While speaking Spanish in Spain does not provide much information, speaking Quechua in Uzbekistan can narrow it down to a single user. Instead of dividing the index metadata by language, it will instead be grouped by app. We will then group apps so that it is difficult to tell which app in the group is the one people are interested in. For example, if one very popular app is only grouped with apps that are rarely downloaded, then it is an easy assumption that someone getting info about that block of apps is most likely looking for that popular app.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Migrate Your Android App‚Äôs Signing Key</title>
      <link>https://guardianproject.github.io/info/2015/12/29/how-to-migrate-your-android-apps-signing-key/</link>
      <pubDate>Tue, 29 Dec 2015 12:03:54 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2015/12/29/how-to-migrate-your-android-apps-signing-key/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;It is time to update to a stronger signing key for your Android app! The old default RSA 1024-bit key is weak and officially deprecated.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;what&#34;&gt;What?&lt;/h2&gt;

&lt;p&gt;The Android OS requires that every application installed be signed by a digital key. The purpose behind this signature is to identify the author of the application, allow this author and this author alone to make updates to the app, as well as provide a mechanism to establish inter-application trust. The Android security model defines an app by two things: the package name (aka &lt;a href=&#34;https://developer.android.com/reference/android/content/Context.html#getPackageName%28%29&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;packageName&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://sites.google.com/a/android.com/tools/tech-docs/new-build-system/applicationid-vs-packagename&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ApplicationID&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://developer.android.com/guide/topics/manifest/manifest-element.html#package&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;package&lt;/code&gt;&lt;/a&gt;) and the signing key. If either of those are different, then Android considers it a different app. When the package name and signing key of one APK match an installed app, then the APK is considered an update and Android will replace the installed app with the APK. If the APK is signed by a different key, then Android will prevent installing and updating.&lt;/p&gt;

&lt;p&gt;First thing is to see what the current signing key is. Check any app‚Äôs signing key using our free utility app &lt;a href=&#34;https://play.google.com/store/apps/details?id=info.guardianproject.checkey&#34; target=&#34;_blank&#34;&gt;Checkey&lt;/a&gt;:&lt;/p&gt;

&lt;div id=&#34;attachment_13170&#34; style=&#34;width: 790px&#34; class=&#34;wp-caption alignnone&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2015/12/checkey-1.png&#34; rel=&#34;attachment wp-att-13170&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-13170&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2015/12/checkey-1-1024x576.png&#34; alt=&#34;Lookout needs to generate a new key!&#34; width=&#34;780&#34; height=&#34;439&#34; class=&#34;size-large wp-image-13170&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2015/12/checkey-1-1024x576.png 1024w, https://guardianproject.info/wp-content/uploads/2015/12/checkey-1-300x169.png 300w, https://guardianproject.info/wp-content/uploads/2015/12/checkey-1-768x432.png 768w, https://guardianproject.info/wp-content/uploads/2015/12/checkey-1-350x197.png 350w, https://guardianproject.info/wp-content/uploads/2015/12/checkey-1-860x484.png 860w, https://guardianproject.info/wp-content/uploads/2015/12/checkey-1.png 1280w&#34; sizes=&#34;(max-width: 780px) 100vw, 780px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-13170&#34; class=&#34;wp-caption-text&#34;&gt;
    Lookout needs to generate a new key!
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;The official Android docs have tons of useful information about what the signing keys are good for, how to generate them, and how to use them. Unfortunately, it doesn‚Äôt provide any instructions for migrating, and for many years, 1024-bit RSA was the default. But first, why would you want or need to migrate?&lt;/p&gt;

&lt;h2 id=&#34;why&#34;&gt;Why?&lt;/h2&gt;

&lt;p&gt;Depending on when you created your signing key, you might have a particularly weak key. The primary danger of a weak key is that an adversary could break your key in order to generate fake APK signatures. Then those malicious APKs can be installed as updates to your app. There are other nefarious purposes depending on how you use the signing key in your apps. Or if you are unfortunate enough to have suffered a loss of your private key material, then it is definitely time for a new signing key.&lt;/p&gt;

&lt;p&gt;According to our friends at the &lt;a href=&#34;https://androidobservatory.org/stats&#34; title=&#34;Android Observatory&#34;&gt;Android Observatory&lt;/a&gt;, over 64% of Android apps in their data store use 1024-bit signing keys (RSA or DSA).&lt;/p&gt;

&lt;div id=&#34;visualization&#34; style=&#34;width: 600px; height: 400px;&#34;&gt;
&lt;/div&gt;

&lt;p&gt;There are several good reasons to migrate off of 1024-bit RSA keys, even though there is no &lt;em&gt;public&lt;/em&gt; proof of a 1024 prime factorization required to generate any 1024-bit key at will. The evidence has been mounting for a decade.&lt;/p&gt;

&lt;p&gt;NIST‚Äôs &lt;a href=&#34;http://csrc.nist.gov/publications/nistpubs/800-57/sp800-57_part1_rev3_general.pdf&#34;&gt;official guidelines&lt;/a&gt; (PDF, page 64 and 67) deprecated 1024-bit RSA keys at the end of 2013. This deprecation by NIST isn‚Äôt an indication that 1024-bit RSA is compromised, instead it is a preemptive move to stay ahead of attacks. Confidence in NIST might be shaken in light of &lt;a href=&#34;http://blog.cryptographyengineering.com/2013/09/on-nsa.html&#34;&gt;recent revelations&lt;/a&gt;, but in this case increasing the RSA key size is unlikely to trigger any secret NSA backdoors. If anything, the deprecation year could have been extended slightly to allow the NSA a window where they had the capacity to factor 1024-bit keys and everyone was still using them. So, it‚Äôs time to move on.&lt;/p&gt;

&lt;p&gt;For an example, a decade ago the cost of building special purpose hardware capable of breaking a single 1024-bit RSA key in one year was estimated at $10 million (&lt;a href=&#34;http://tau.ac.il/~tromer/papers/cbtwirl.pdf&#34;&gt;Adi Shamir, Eran Tromer, On the cost of factoring RSA-1024&lt;/a&gt;, 2003). Presumably the techniques have improved by orders of magnatude, and the hardware value depreciated. It is conceivable the cost has fallen enough to be affordable not only by nation-state actors, but by large criminal enterprises too.&lt;/p&gt;

&lt;p&gt;For a comprehensive talk on the state of the art (as of December 2012) when it comes to breaking 1024-bit RSA, check out the 29C3 talk &lt;a href=&#34;http://events.ccc.de/congress/2012/Fahrplan/events/5275.en.html&#34; title=&#34;FactHacks: RSA factorization in the real world&#34;&gt;FactHacks: RSA factorization in the real world&lt;/a&gt; with the cryptographers Daniel J. Bernstein, Nadia Heninger, and Tanja Lange (&lt;a href=&#34;http://events.ccc.de/congress/2012/wiki/Documentation#Recordings&#34; title=&#34;29C3 Recordings&#34;&gt;watch recording&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;how&#34;&gt;How?&lt;/h2&gt;

&lt;p&gt;Migrating to a strong key for an Android app is, unfortunately, not so simple. If you are publishing a &lt;em&gt;new&lt;/em&gt; app to the app store, then simply generate a new strong signing key and you‚Äôre done. Congratulations! However, there exists no easy way to update your signing key for an existing application, because an installed application can only take updates from an APK signed with &lt;em&gt;the same&lt;/em&gt; key.&lt;/p&gt;

&lt;p&gt;Here we outline a basic method with which you can use to fake an update to your signing key. This is not as user friendly as we would like. Some of the hard facts of performing this process is that for most app stores including Google Play, you will lose ratings and reviews since the app will show up with a new package name, and the app store will treat it like an entirely new app. Also, the user will have to manually uninstall the original app once they finish the procedure. Here is a rough outline of the process:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;generate the new signing key, &lt;em&gt;RSA 4096&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Update the first app, &lt;em&gt;App1&lt;/em&gt;, with a mechanism for exporting private data, using &lt;a href=&#34;https://github.com/guardianproject/TrustedIntents&#34; target=&#34;_blank&#34;&gt;TrustedIntents&lt;/a&gt; with a signature pin of the new key, &lt;em&gt;RSA 4096&lt;/em&gt;, which &lt;a href=&#34;https://guardianproject.info/2014/07/30/introducing-trustedintents-for-android/&#34; target=&#34;_blank&#34;&gt;Checkey will generate for you&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Create a new version of the app with a different package name, &lt;em&gt;App2&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;sign &lt;em&gt;App2&lt;/em&gt; with new key, &lt;em&gt;RSA 4096&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Add method to &lt;em&gt;App2&lt;/em&gt; for receiving user data from &lt;em&gt;App1&lt;/em&gt;, including a signature pin of the old signing key, &lt;em&gt;RSA 1024&lt;/em&gt;, for use with TrustedIntents&lt;/li&gt;
&lt;li&gt;Publish &lt;em&gt;App2&lt;/em&gt; to the app stores&lt;/li&gt;
&lt;li&gt;From &lt;em&gt;App1&lt;/em&gt;, prompt user to install &lt;em&gt;App2&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;runs and imports data from &lt;em&gt;App1&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;App2&lt;/em&gt; prompts user to uninstall &lt;em&gt;App1&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For &lt;a href=&#34;https://f-droid.org&#34; target=&#34;_blank&#34;&gt;F-Droid&lt;/a&gt;, there will be some easier tools for handling this. The F-Droid system is already used to multiple signing keys per app since F-Droid uses its own signing key for many of the apps it releases, and that F-Droid signing key is different from the signing key that the original developer used in their Google Play uploads. F-Droid will likely be able to support APKs with the same package name but with multiple signing keys.&lt;/p&gt;

&lt;h3 id=&#34;a-note-on-compatibility&#34;&gt;A Note on Compatibility&lt;/h3&gt;

&lt;p&gt;There is security vs compatibility trade off a few might be interested in. Pre-4.3, Android did not support any signature algorithms except SHA1. With Android &amp;gt;= 4.3, SHA256 support was fixed, and SHA384, SHA512, and ECDSA were added (&lt;a href=&#34;https://code.google.com/p/android/issues/detail?id=38321&#34;&gt;source&lt;/a&gt;). There are still android 2.3.3 (&lt;code&gt;android-10&lt;/code&gt;) devices being sold, so anyone interested in backwards compatibility will have to heed this.&lt;/p&gt;

&lt;p&gt;Also, the larger the keysize and hashsize used, the longer it takes to install and update the application. So extremely large values might be unsuitable for slower hardware. The following probably doesn‚Äôt buy you a tremendous amount of additional security but cranks the paranoia to 11. It does so at the cost of compatibility and performance.&lt;br /&gt;
&lt;code&gt;&amp;lt;br /&amp;gt;
Gen with:&amp;lt;br /&amp;gt;
  keytool -genkey -v -keystore test.keystore -alias testkey -keyalg RSA -keysize 4096 -sigalg SHA512withRSA -dname &amp;quot;cn=Test,ou=Test,c=CA&amp;quot; -validity 10000&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;Sign with:&amp;lt;br /&amp;gt;
  jarsigner -verbose -sigalg SHA512withRSA -digestalg SHA512 -keystore test.keystore test.apk testkey&amp;lt;br /&amp;gt;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;We have some scripts that we use to generate keys in our &lt;a href=&#34;https://github.com/guardianproject/smartcard-apk-signing&#34; target=&#34;_blank&#34;&gt;smartcard-apk-signing&lt;/a&gt; repo. It is also possible to generate an Android signing key using openssl or other libraries. It is often wise to use different software than standard for doing things like generating keys. Since the Java &lt;code&gt;keytool&lt;/code&gt; approach that is the standard, recommended method for Android, that makes it a target for adversaries that are interested in breaking keys. If a key was generated using &lt;code&gt;openssl&lt;/code&gt; or GNU TLS instead, for example, then that key would not be affected if &lt;code&gt;keytool&lt;/code&gt; had &lt;a href=&#34;https://freedom-to-tinker.com/blog/kroll/software-transparency-debian-openssl-bug/&#34; target=&#34;_blank&#34;&gt;a bug like Debian‚Äôs&lt;/a&gt; &lt;a href=&#34;https://security-tracker.debian.org/tracker/CVE-2008-0166&#34; target=&#34;_blank&#34;&gt;CVE-2008-0166&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a trustworthy app store that respects privacy</title>
      <link>https://guardianproject.github.io/info/2015/06/02/building-a-trustworthy-app-store-that-respects-privacy/</link>
      <pubDate>Tue, 02 Jun 2015 16:38:03 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2015/06/02/building-a-trustworthy-app-store-that-respects-privacy/</guid>
      <description>&lt;p&gt;One core piece of our approach is thinking about very high risk situations, like Ai Weiwei or Edward Snowden, then making the tools for operating under that pressure as easy to use as possible. That means that we might occasionally come across as a little paranoid. It is important to dive into the depths of what might be possible. That is an essential step in evaluating what the risks and defenses are, and how to prioritize them. Making usable software is not just making things easy, but rather making tools for real world situations that are a simple as possible.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2015/06/hrome-crash.png&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2015/06/hrome-crash.png&#34; alt=&#34;chrome crash&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;alignright size-full wp-image-12966&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We recently received some vindication of our paranoia: we have been resistant to putting all of our trust into the Google Play app store, despite many obvious advantages. Even though Google Play is probably the most secure of the big app stores, its security approach is rather thin, &lt;a href=&#34;https://jon.oberheide.org/blog/2010/06/28/a-peek-inside-the-gtalkservice-connection/&#34; target=&#34;_blank&#34;&gt;relying mainly on HTTPS with no signature for verification&lt;/a&gt;, and the Five Eyes partnership (NSA, GCHQ, etc) noticed this, and &lt;a href=&#34;https://firstlook.org/theintercept/2015/05/21/nsa-five-eyes-google-samsung-app-stores-spyware&#34; target=&#34;_blank&#34;&gt;worked to exploit it&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The Android/Google Play security model is relatively simple, and that is mostly a good thing. There are two essential pieces: the signature on the APK file itself and the TLS connection to Google that provides the APK file. Once an app is installed, all APK files used to update an app must have a matching signing key. That provides a reasonably strong mechanism to defend against malware that wants to install over existing apps.&lt;/p&gt;

&lt;p&gt;Unlike package systems like Debian, there is no path to verify that the APK signing key. That means Google Play relies heavily on the TLS transport encryption to protect the APK files for when installing an Android apps for the first time. The first time an app is installed, the signing key in that app‚Äôs APK file is blindly trusted (this is called ‚ÄúTrust On First Use‚Äù or TOFU). It turns out that TOFU has a solid track record for security in the real world. One key aspect of implementing a good TOFU system is to make the first use indistinguishable from any other use, so that it is difficult to target only first uses while ignoring repeat uses. Intercepting repeat uses is very likely to trigger a warning and alert the user that something is wrong.&lt;/p&gt;

&lt;p&gt;Now let‚Äôs put together the pieces based on what the Chinese government can do. A few TLS certificate authorities have been caught &lt;a href=&#34;https://arstechnica.com//security/2010/03/govts-certificate-authorities-conspire-to-spy-on-ssl-users/&#34; target=&#34;_blank&#34;&gt;issuing &lt;/a&gt;&lt;a href=&#34;https://arstechnica.com//security/2011/08/earlier-this-year-an-iranian/&#34; target=&#34;_blank&#34;&gt;fake&lt;/a&gt; &lt;a href=&#34;https://arstechnica.com//business/2012/02/critics-slam-ssl-authority-for-minting-cert-used-to-impersonate-sites/&#34; target=&#34;_blank&#34;&gt;certificates&lt;/a&gt;. A company affiliated with CNNIC &lt;a href=&#34;https://arstechnica.com/security/2015/04/google-chrome-will-banish-chinese-certificate-authority-for-breach-of-trust/&#34; target=&#34;_blank&#34;&gt;was caught issuing certificates for Google domains&lt;/a&gt;. A trusted certificate authority can issue usable certificates for any domain, so any computer that trusts CNNIC would trust their fake certificates for Google. That lets the Chinese government transparently Man-in-the-Middle traffic to Google servers. China could then use the Great Firewall to generate targeted malware on the fly, seeing the user credentials that Google Play requires, seeing the list of apps that each user has installed, etc. Then when the targeted user goes to install a new app, the APK file is intercepted, malware is added, then it is re-signed and transparently sent off to the user.&lt;/p&gt;

&lt;p&gt;This targeted malware can be designed to avoid the malware scanners in Google Play, Lookout, etc. since it would be direct addition of code rather than via an exploit. It would be just adding Java classes to the APK. Or alternatively, in combination with some of the signing exploits that have been discovered in Android, like &lt;a href=&#34;http://www.saurik.com/id/19&#34; target=&#34;_blank&#34;&gt;Master Key&lt;/a&gt;, the Great Firewall is able to inject malware into the real APK itself without changing the signature.&lt;/p&gt;

&lt;p&gt;Of course, when Google Play‚Äôs TLS connection includes X.509 &lt;a href=&#34;https://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning&#34; target=&#34;_blank&#34;&gt;certificate pinning&lt;/a&gt;, then the above attack would not be possible since the client would have a whitelist of certificate authorities that it trusts for play.google.com, and CNNIC would probably not be on that whitelist. This highlights the importance of pinning certificate authorities in apps that need good security over TLS or HTTPS. All TLS connections &lt;a href=&#34;http://nelenkov.blogspot.com/2012/12/certificate-pinning-in-android-42.html&#34; target=&#34;_blank&#34;&gt;support pinning at the system level&lt;/a&gt; starting in Android 4.2. We are crazy enough to support down to Android 2.3 since there are lots of older Android devices in use, and even &lt;a href=&#34;https://arstechnica.com/gadgets/2014/12/android-2-3-gingerbread-four-years-later-the-os-just-wont-die/&#34; target=&#34;_blank&#34;&gt;new devices being sold with Android 2.3.3&lt;/a&gt;. That means we think about making apps self-contained in terms of security improvements like pinning.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2015/06/sadballs.png&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2015/06/sadballs-150x300.png&#34; alt=&#34;sad balls&#34; width=&#34;150&#34; height=&#34;300&#34; class=&#34;alignright size-medium wp-image-12969&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2015/06/sadballs-150x300.png 150w, https://guardianproject.info/wp-content/uploads/2015/06/sadballs.png 400w&#34; sizes=&#34;(max-width: 150px) 100vw, 150px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;It gets worse&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Many indigenous app stores like &lt;a href=&#34;http://cafebazaar.ir&#34; target=&#34;_blank&#34;&gt;Cafe Bazaar&lt;/a&gt; and Xiaomi‚Äôs &lt;a href=&#34;http://app.mi.com&#34; target=&#34;_blank&#34;&gt;MiMarket&lt;/a&gt; lack basic protections like TLS, making targeted attacks trivial for governments, or even anyone who gains control of a piece of the network path. These days that is actually easy to do by exploiting home routers, which are &lt;a href=&#34;https://arstechnica.com/security/2015/05/researchers-uncover-self-sustaining-botnets-of-poorly-secured-routers/&#34; target=&#34;_blank&#34;&gt;generally&lt;/a&gt; &lt;a href=&#34;https://arstechnica.com/security/2015/04/no-patch-for-remote-code-execution-bug-in-d-link-and-trendnet-routers/&#34; target=&#34;_blank&#34;&gt;easy&lt;/a&gt; to &lt;a href=&#34;https://arstechnica.com/security/2015/05/the-moose-is-loose-linux-based-worm-turns-routers-into-social-network-bots/&#34; target=&#34;_blank&#34;&gt;exploit&lt;/a&gt;. One of those botnets would easily start looking for app installs in the network traffic, then add exploits accordingly. As long as the first install is easy to detect and the user easy to track, then the malware can transparently inject malware designed to be difficult to detect by malware scanners and people alike.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2013/11/fdroidheader3.png&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2013/11/fdroidheader3.png&#34; alt=&#34;fdroidheader3&#34; width=&#34;720&#34; height=&#34;180&#34; class=&#34;alignnone size-full wp-image-11906&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2013/11/fdroidheader3.png 720w, https://guardianproject.info/wp-content/uploads/2013/11/fdroidheader3-300x75.png 300w&#34; sizes=&#34;(max-width: 720px) 100vw, 720px&#34; /&gt;&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;The Alternative&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://f-droid.org&#34; target=&#34;_blank&#34;&gt;FDroid&lt;/a&gt; also has the key advantage of being designed from the beginning to avoid tracking users, and to use proven methods of delivering software, following the signed repository model of Debian, Ubuntu, etc. but then served over a solid HTTPS channel for increased privacy and a backup layer of security. It is also possible to use privacy proxies like Tor or I2P via the proxy settings. There is no user credentials needed, it is all free software, so FDroid users can even hide themselves from the server delivering the apps, as well as any network observers. Since all APKs are delivered via signed metadata that is verified using a key built into the FDroid client app, there is no risk of getting served malware even if the HTTPS connection is completely and transparently broken.&lt;/p&gt;

&lt;p&gt;As part of our &lt;a href=&#34;https://dev.guardianproject.info/project/bazaar/wiki&#34; target=&#34;_blank&#34;&gt;Bazaar Project&lt;/a&gt;, we have been putting more and more efforts into the FDroid project, and working to make it much easier to use. All Guardian Project apps are available in FDroid, as well as all the core apps that you might need like Firefox, a Twitter client, K-9 email, etc. Tech journalist &lt;a href=&#34;https://medium.com/backchannel/why-i-m-saying-goodbye-to-apple-google-and-microsoft-78af12071bd&#34; target=&#34;_blank&#34;&gt;Dan Gillmor agrees&lt;/a&gt;: free software that respects privacy is not only for the √ºber-geek anymore.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Phishing for developers</title>
      <link>https://guardianproject.github.io/info/2015/02/24/phishing-for-developers/</link>
      <pubDate>Tue, 24 Feb 2015 04:41:29 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2015/02/24/phishing-for-developers/</guid>
      <description>&lt;p&gt;I recently received a very interesting phishing email directed at developers with apps in Google Play. One open question is, how targeted it was: did anyone else get this?&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/File:Trawling_Drawing.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2015/02/320px-Trawling_Drawing.jpg&#34; alt=&#34;320px-Trawling_Drawing&#34; width=&#34;320&#34; height=&#34;240&#34; class=&#34;alignright size-full wp-image-12873&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2015/02/320px-Trawling_Drawing.jpg 320w, https://guardianproject.info/wp-content/uploads/2015/02/320px-Trawling_Drawing-300x225.jpg 300w&#34; sizes=&#34;(max-width: 320px) 100vw, 320px&#34; /&gt;&lt;/a&gt;&lt;br /&gt;
It turns out that Google has been recently stepping up enforcement of certain terms, so it looks like some people are taking advantage of that. It is a pretty sophisticated or manually targeted phishing email since they got the name of the app, email address, and project name all correct. The one detail that gives it away is that the &lt;code&gt;From:&lt;/code&gt; address uses the fake domain, even though it would have been possible to send the email using the actual Google account in the &lt;code&gt;From:&lt;/code&gt; field. But this likely would have triggered spam and malware detection algorithms. So they took a subtly different approach by using a real Google address in the &lt;code&gt;Reply-To:&lt;/code&gt;. But they were clever enough to use the same sub-domain, &lt;code&gt;gooogle.com.de&lt;/code&gt;, in the From: address as in the phishing link &lt;code&gt;accounts.gooogle.com.de&lt;/code&gt;, following a Google pattern of subdomains. They also included other real Google links for support and as a ‚Äúfollow up‚Äù URL.&lt;/p&gt;

&lt;p&gt;When I received this, I didn‚Äôt notice the clickable link in the email since I never view HTML email. I forwarded it on to our internal email list where others figured out it was fake. In the HTML version of the email, it has this link from the fake domain &lt;code&gt;accounts.gooogle.com.de&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;p&gt;&lt;b&gt;Your application will be removed&lt;/b&gt; if you do not sign in to the &lt;a
href=&#34;http://accounts.gooogle.com.de/ServiceLogin?service=androiddeveloper&amp;passive=1209600&amp;continue=https://play.google.com/apps/publish/&amp;followup=https://play.google.com/apps/publish/&amp;type=3days&amp;pkg=org.torproject.android&#34;&gt;Developer
Console&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;This attacker might have been targeting anyone who would fall for the trick, without really caring what kind of app it was. For any accounts that the attacker got access to, they would be able to change the description text, home page, email address, etc. transparently without raising any particular warning signs. The attacker could place a recommendation in the app descriptions to also install another app, and that app would be the attacker‚Äôs malware.&lt;/p&gt;

&lt;p&gt;The attacker could not upload their own updates to an existing app, because Google Play checks uploaded APKs to make sure that the signing keys match the APKs that are already there. The attacker could create a whole new app in that developer‚Äôs account, and hope to gain installs since it would be related. Google Play has a standard view to show users apps by the same developer, for example.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Two-factor authentication and beyond&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If a developer fell for this phishing attack, but had the forethought to have set up &lt;a href=&#34;https://support.google.com/accounts/answer/180744&#34; target=&#34;_blank&#34;&gt;Google 2-Step Verification&lt;/a&gt;, then even if the phisher got the username and password, they would be unable to log into that account since they would not have access to the two-factor SMS or &lt;a href=&#34;https://support.google.com/accounts/answer/1066447&#34; target=&#34;_blank&#34;&gt;Google Authenticator&lt;/a&gt; message. All developer accounts on Google Play should be required to use Google 2-Step Verification. Set it up &lt;strong&gt;now&lt;/strong&gt;, if you have not already!&lt;/p&gt;

&lt;p&gt;We also need to consider the kinds of sophisticated attacks from large state actors that are leaking out to the public. Indeed, many of these attacks are also available for any government to &lt;a href=&#34;https://netzpolitik.org/2014/gamma-finfisher-hacked-40-gb-of-internal-documents-and-source-code-of-government-malware-published/&#34; target=&#34;_blank&#34;&gt;purchase from companies like Finfisher&lt;/a&gt;. And it is only a matter of time before these techniques are widespread and easier, following the rule of ‚Äúattacks never get worse; they only get better‚Äù. This phishing website could also contain malicious Javascript that installs malware that can both log all key strokes in search of passwords, as well as search for known secret caches like Java keystores for Android signing keys, and browser cookies that allow the user to skip two-factor authentication, like the &lt;a href=&#34;https://support.google.com/accounts/answer/2544838&#34; target=&#34;_blank&#34;&gt;cookie from Google‚Äôs two-step authentication&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One takeaway here: developers should &lt;strong&gt;never&lt;/strong&gt; keep or use their APK signing keys on a machine that they also use to read email and browse the web.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Full source of the email&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Here is the full source of the original email that I received, for those who might be interested in digging deeper. Another detail you can see there is that the email was not sent using Google infrastructure at all.&lt;/p&gt;

&lt;pre&gt;Return-Path: &lt;n&amp;#x6f;&amp;#x72;e&amp;#x70;&amp;#x6c;y&amp;#x2d;&amp;#x64;e&amp;#x76;&amp;#x65;l&amp;#x6f;&amp;#x70;e&amp;#x72;&amp;#x2d;g&amp;#x6f;&amp;#x6f;g&amp;#x6c;&amp;#x65;p&amp;#x6c;&amp;#x61;y&amp;#x40;&amp;#x67;o&amp;#x6f;&amp;#x6f;gl&amp;#x65;.c&amp;#x6f;m.&amp;#x64;e&gt;
X-Spam-Checker-Version: SpamAssassin 3.3.2 (2011-06-06) on
    rodolpho.mayfirst.org
X-Spam-Level: *
X-Spam-Status: No, score=1.3 required=5.0 tests=HTML_MESSAGE,RDNS_NONE
    autolearn=disabled version=3.3.2
X-Original-To: s&amp;#x75;p&amp;#x70;o&amp;#x72;t&amp;#x40;gu&amp;#x61;r&amp;#x64;i&amp;#x61;n&amp;#x70;ro&amp;#x6a;e&amp;#x63;t&amp;#x2e;i&amp;#x6e;f&amp;#x6f;
Delivered-To: gphan&amp;#x73;&amp;#x40;&amp;#x72;&amp;#x6f;&amp;#x64;olpho&amp;#x2e;&amp;#x6d;&amp;#x61;&amp;#x79;&amp;#x66;irst.&amp;#x6f;&amp;#x72;&amp;#x67;
Received: from rodolpho.mayfirst.org (localhost [127.0.0.1])
    by rodolpho.mayfirst.org (Postfix) with ESMTP id 4CFCD5E3D
    for &lt;&amp;#x73;&amp;#x75;&amp;#x70;port@&amp;#x67;&amp;#x75;&amp;#x61;&amp;#x72;dian&amp;#x70;&amp;#x72;&amp;#x6f;&amp;#x6a;ect.&amp;#x69;&amp;#x6e;&amp;#x66;&amp;#x6f;&gt;; Fri, 20 Feb 2015 04:30:50 -0500 (EST)
X-Greylist: delayed 543 seconds by postgrey-1.34 at rodolpho; Fri, 20 Feb 2015
04:30:49 EST
Received: from astra1695.startdedicated.com (unknown [85.25.194.40])
    by rodolpho.mayfirst.org (Postfix) with ESMTP id D74C83CD84
    for &lt;sup&amp;#x70;&amp;#x6f;&amp;#x72;t@g&amp;#x75;&amp;#x61;&amp;#x72;dia&amp;#x6e;&amp;#x70;&amp;#x72;ojec&amp;#x74;&amp;#x2e;&amp;#x69;nfo&gt;; Fri, 20 Feb 2015 04:30:48 -0500 (EST)
Received: from gooogle.com.de (astra1695 [85.25.194.40])
    by astra1695.startdedicated.com (Postfix) with ESMTPA id 209D57C0918
    for &lt;su&amp;#x70;&amp;#x70;or&amp;#x74;&amp;#x40;gua&amp;#x72;&amp;#x64;ia&amp;#x6e;&amp;#x70;ro&amp;#x6a;&amp;#x65;ct.&amp;#x69;&amp;#x6e;fo&gt;; Fri, 20 Feb 2015 10:21:32 +0100 (CET)
Date: Fri, 20 Feb 2015 09:21:32 +0000
To: The Tor Project &lt;&amp;#x73;u&amp;#x70;p&amp;#x6f;rt&amp;#x40;g&amp;#x75;ar&amp;#x64;i&amp;#x61;np&amp;#x72;o&amp;#x6a;e&amp;#x63;&amp;#x74;.&amp;#x69;n&amp;#x66;o&gt;
From: Google Play Developer Support &lt;n&amp;#x6f;r&amp;#x65;p&amp;#x6c;y&amp;#x2d;de&amp;#x76;e&amp;#x6c;o&amp;#x70;e&amp;#x72;-g&amp;#x6f;o&amp;#x67;l&amp;#x65;p&amp;#x6c;a&amp;#x79;@g&amp;#x6f;o&amp;#x6f;g&amp;#x6c;e&amp;#x2e;co&amp;#x6d;.&amp;#x64;e&gt;
Reply-To: Google Play Developer Support &lt;norepl&amp;#x79;&amp;#x2d;&amp;#x64;&amp;#x65;&amp;#x76;&amp;#x65;loper-g&amp;#x6f;&amp;#x6f;&amp;#x67;&amp;#x6c;&amp;#x65;&amp;#x70;lay@go&amp;#x6f;&amp;#x67;&amp;#x6c;&amp;#x65;&amp;#x2e;&amp;#x63;om&gt;
Subject: 7-Day Notification of Google Play Developer Term Violation
Message-ID: &lt;7f7&amp;#x32;&amp;#x35;&amp;#x34;&amp;#x30;087c&amp;#x38;&amp;#x31;&amp;#x66;fe2e&amp;#x61;&amp;#x64;&amp;#x35;6042&amp;#x35;&amp;#x64;&amp;#x30;d477&amp;#x40;&amp;#x67;&amp;#x6f;oogl&amp;#x65;&amp;#x2e;&amp;#x63;om.d&amp;#x65;&gt;
X-Priority: 3
X-Mailer: PHPMailer 5.2.9 (https://github.com/PHPMailer/PHPMailer/)
MIME-Version: 1.0
Content-Type: multipart/alternative;
    boundary=&#34;b1_7f72540087c81ffe2ead560425d0d477&#34;
Content-Transfer-Encoding: 8bit
X-Virus-Scanned: ClamAV using ClamSMTP

--b1_7f72540087c81ffe2ead560425d0d477
Content-Type: text/plain; charset=us-ascii

Hello Google Play Developer,
This is a notification that your application, Orbot: Proxy with Tor, with
package ID org.torproject.android, is currently in violation of our developer
terms.
REASON FOR WARNING: Violation of the spam provisions of the Content Policy.
Please refer to the spam policy help article for more information.
Do not use irrelevant, misleading, or excessive keywords in apps descriptions,
titles, or metadata.
Please refer to the keyword spam policy help article for more information.
Your application will be removed if you do not sign in to the Developer
Console and make modifications to your application&#39;s description to bring it
into compliance within 7 days of the issuance of this notification.If you have
additional applications in your catalog, please also review them for
compliance. Note that any remaining applications found to be in violation will
be removed from the Google Play Store.
Please also consult the Policy and Best Practices and the Developer
Distribution Agreement as you bring your applications into compliance. You can
also review this Google Play Help Center article for more information on this
warning.
All violations are tracked. Serious or repeated violations of any nature will
result in the termination of your developer account, and investigation and
possible termination of related Google accounts.
Regards,
Google Play Team
1600 Amphitheatre Parkway
Mountain View, CA 94043


--b1_7f72540087c81ffe2ead560425d0d477
Content-Type: text/html; charset=us-ascii

&lt;p&gt;Hello Google Play Developer,&lt;/p&gt;
&lt;p&gt;This is a notification that your application, &lt;b&gt;Orbot: Proxy with Tor&lt;/b&gt;,
with package ID &lt;b&gt;org.torproject.android&lt;/b&gt;, is currently in violation of
our developer terms.&lt;br /&gt;
&lt;b&gt;REASON FOR WARNING&lt;/b&gt;: Violation of the spam provisions of the Content
Policy. Please refer to the spam policy help article for more information.&lt;/p&gt;
&lt;p&gt;Do not use irrelevant, misleading, or excessive keywords in apps
descriptions, titles, or metadata.&lt;br /&gt;
Please refer to the keyword spam policy help article for more information.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Your application will be removed&lt;/b&gt; if you do not sign in to the &lt;a
href=&#34;http://accounts.gooogle.com.de/ServiceLogin?service=androiddeveloper&amp;passive=1209600&amp;continue=https://play.google.com/apps/publish/&amp;followup=https://play.google.com/apps/publish/&amp;type=3days&amp;pkg=org.torproject.android&#34;&gt;Developer
Console&lt;/a&gt; and make modifications to your application&amp;#x27;s description to
bring it into compliance within &lt;b&gt;7 days&lt;/b&gt; of the issuance of this
notification.&lt;br&gt;If you have additional applications in your catalog, please
also review them for compliance. Note that any remaining applications found to
be in violation will be removed from the Google Play Store.&lt;/p&gt;
&lt;p&gt;Please also consult the &lt;a
href=&#34;https://support.google.com/googleplay/android-developer/#topic=2364761&#34;&gt;Policy
and Best Practices&lt;/a&gt; and the &lt;a
href=&#34;https://play.google.com/about/developer-distribution-agreement.html&#34;&gt;Developer
Distribution Agreement&lt;/a&gt; as you bring your applications into compliance. You
can also review this Google Play Help Center article for more information on
this warning.&lt;br /&gt;
All violations are tracked. Serious or repeated violations of any nature will
result in the termination of your developer account, and investigation and
possible termination of related Google accounts.&lt;/p&gt;
&lt;p&gt;Regards,&lt;br&gt;
Google Play Team&lt;br&gt;
1600 Amphitheatre Parkway&lt;br&gt;
Mountain View, CA 94043&lt;/p&gt;



--b1_7f72540087c81ffe2ead560425d0d477--
&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Reducing metadata leakage from software updates</title>
      <link>https://guardianproject.github.io/info/2014/10/16/reducing-metadata-leakage-from-software-updates/</link>
      <pubDate>Thu, 16 Oct 2014 12:48:04 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2014/10/16/reducing-metadata-leakage-from-software-updates/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: now you can &lt;a href=&#34;https://guardianproject.info/2016/07/31/howto-get-all-your-debian-packages-via-tor-onion-services/&#34;&gt;do this with Tor Onion Services&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2014/10/leakage.png&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2014/10/leakage-300x199.png&#34; alt=&#34;leakage&#34; width=&#34;300&#34; height=&#34;199&#34; class=&#34;alignright size-medium wp-image-12699&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/10/leakage-300x199.png 300w, https://guardianproject.info/wp-content/uploads/2014/10/leakage-100x66.png 100w, https://guardianproject.info/wp-content/uploads/2014/10/leakage-150x99.png 150w, https://guardianproject.info/wp-content/uploads/2014/10/leakage-200x132.png 200w, https://guardianproject.info/wp-content/uploads/2014/10/leakage.png 410w&#34; sizes=&#34;(max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;Many software update systems use code signing to ensure that only the correct software is downloaded and installed, and to prevent the code from being altered. This is an effective way to prevent the code from being modified, and because of that, software update systems often use plain, unencrypted HTTP connections for downloading code updates. That means that the metadata of what packages a machine has installed is available in plain text for any network observer, from someone sitting on the same public WiFi as you, to state actors with full network observation capabilities.&lt;/p&gt;

&lt;p&gt;That means that potentially private information is leaking. That private information could be which packages you have installed and which versions. That information can help an attacker figure out the best way to break into the target machine. Also, a unique fingerprint can be generated based on which packages a machine has installed, and that could help de-anonymize traffic that goes over Tor or other anonymity tool.&lt;/p&gt;

&lt;p&gt;For people who use &lt;code&gt;apt-get&lt;/code&gt; in Debian, Ubuntu or any related GNU/Linux distro, there is a lot of metadata leaked to the internet when &lt;code&gt;apt-get&lt;/code&gt; contacts Debian repositories using a standard configuration. Mostly, that is because by default, the connections are unencrypted (http, ftp, rsync). The integrity of the package itself is not reason enough to use HTTPS since the GPG signing is much more reliable for that task. Here is how I break it down:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;package authenticity&lt;br /&gt;
(&lt;em&gt;software can be modified while being downloaded&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;repo availability&lt;br /&gt;
( &lt;em&gt;whole sites or specific URL paths can be selectively blocked by governments and companies&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;package availability&lt;br /&gt;
(&lt;em&gt;software security updates can be individually blocked&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;who‚Äôs downloading what package (&lt;em&gt;currently visible to anyone who can see the&lt;br /&gt;
network traffic, including open wifi, etc.&lt;/em&gt;)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The current apt model covers #1 well, but only covers #2 and #3 with a two week window (the expiration date on the repo metadata). And it does not cover #4 at all. Using HTTPS for apt repos is a simple way to improve the security of all 4. It adds a weak backup security layer for #1, it makes it much more difficult for a portion of a large internet mirror to be seletively blocked (e.g. #2 and #3). For example, if you use HTTPS to mirrors.kernel.org, everything has to be blocked to block Debian repos or packages. And pipelining downloads through a reused HTTPS connection makes it very difficult for the network observer to track metadata about packages, #4).&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2014/10/leakage-control.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2014/10/leakage-control-150x150.jpg&#34; alt=&#34;leakage control&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;alignright size-thumbnail wp-image-12701&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/10/leakage-control-150x150.jpg 150w, https://guardianproject.info/wp-content/uploads/2014/10/leakage-control-100x100.jpg 100w, https://guardianproject.info/wp-content/uploads/2014/10/leakage-control-200x200.jpg 200w, https://guardianproject.info/wp-content/uploads/2014/10/leakage-control.jpg 300w&#34; sizes=&#34;(max-width: 150px) 100vw, 150px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Luckily, there are some relatively easy steps that greatly reduce the amount of metadata that is leaked: using HTTPS connections to the mirrors and running those connections through Tor. Setting &lt;code&gt;apt-get&lt;/code&gt; to pipeline as many transactions into a given HTTPS session is also useful, but currently only supported for HTTP and not HTTPS. Even though HTTPS/TLS has security weaknesses, it is a lot better than nothing, and can help provide real world protection. The downside is that it is not common for Debian machines to connect to apt mirrors using HTTPS, so that potentially marks the install as a machine worth targeting. There are more and more HTTPS mirrors, and more interest in using them, so I think in time, that will only lessen as a concern. Here are the HTTPS mirrors that I have had good luck with:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;mirrors.ece.ubc.ca&lt;/li&gt;
&lt;li&gt;mirrors.kernel.org&lt;/li&gt;
&lt;li&gt;mirror.cse.unsw.edu.au&lt;/li&gt;
&lt;li&gt;spout.ussg.indiana.edu&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On that note, here is the config that I have been using on a number of Debian-deriv machines, and it has been working well. It requires &lt;code&gt;apt-transport-https&lt;/code&gt;, and &lt;a href=&#34;http://ubuntuguide.org/wiki/Tor#Privoxy&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;privoxy&lt;/code&gt; setup as an HTTP proxy for Tor&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;$ cat /etc/apt/apt.conf.d/99force-tor
# force everything through privoxy HTTP proxy to tor
Acquire::ftp::Proxy &#34;http://127.0.0.1:8118&#34;;
Acquire::http::Proxy &#34;http://127.0.0.1:8118&#34;;
Acquire::https::Proxy &#34;http://127.0.0.1:8118&#34;;

# don&#39;t use SSL, its insecure, only use TLS
Acquire::https::SslForceVersion &#34;TLSv1&#34;;
&lt;/pre&gt;

&lt;p&gt;I have found about 10 official Debian mirrors that have reliable HTTPS. Then I have a &lt;a href=&#34;https://gist.github.com/eighthave/7285154&#34; target=&#34;_blank&#34;&gt;script that finds all of them&lt;/a&gt;, but many have self-signed certs and other issues. A number of the HTTPS mirrors also mirror the ‚Äúsecurity‚Äù archive, but I recommend that the &lt;code&gt;http&lt;/code&gt; URL to the official &lt;code&gt;security.debian.org&lt;/code&gt; repo is still included to make sure that security updates are promptly available.&lt;/p&gt;

&lt;p&gt;I also have a test security repo running that is only available via an .onion address. I hope to encourage people to run official mirrors on a Tor Hidden Service, then HTTPS is not needed. Note that &lt;code&gt;apt-transport-tor&lt;/code&gt; is not required if a tor proxy is setup. To try mine, add it to your &lt;code&gt;sources.list&lt;/code&gt; (and make sure &lt;code&gt;apt-get&lt;/code&gt; is somehow using Tor). The order is important, that determines the priority of where &lt;code&gt;apt-get&lt;/code&gt; will get the package from is all other variables are the same.&lt;/p&gt;

&lt;pre&gt;deb http://dju2peblv7upfz3q.onion/debian-security/ wheezy/updates main
deb http://security.debian.org/ wheezy/updates main
&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: Use the official &lt;a href=&#34;https://onion.debian.org/&#34; target=&#34;_blank&#34;&gt;Debian Tor Onion Services&lt;/a&gt; now, &lt;tt&gt;dju2peblv7upfz3q.onion&lt;/tt&gt; is deprecated and will be shut down!&lt;/p&gt;

&lt;h3 id=&#34;a-specific-example-tails&#34;&gt;A specific example: TAILS&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://tails.boum.org/&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2014/10/Tails-150x150.png&#34; alt=&#34;Tails&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;alignleft size-thumbnail wp-image-12711&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/10/Tails-150x150.png 150w, https://guardianproject.info/wp-content/uploads/2014/10/Tails-100x100.png 100w, https://guardianproject.info/wp-content/uploads/2014/10/Tails-200x200.png 200w, https://guardianproject.info/wp-content/uploads/2014/10/Tails.png 256w&#34; sizes=&#34;(max-width: 150px) 100vw, 150px&#34; /&gt;&lt;/a&gt;&lt;a href=&#34;https://tails.boum.org/&#34; target=&#34;_blank&#34;&gt;TAILS&lt;/a&gt; is an operating system that aims to be as private and anonymous as possible to enable, and has allowed &lt;a href=&#34;https://freedom.press/blog/2014/04/help-support-little-known-privacy-tool-has-been-critical-journalists-reporting-nsa&#34; target=&#34;_blank&#34;&gt;journalists&lt;/a&gt; like &lt;a href=&#34;https://www.wired.com/2014/10/laura-poitras-crypto-tools-made-snowden-film-possible/&#34; target=&#34;_blank&#34;&gt;Laura Poitras&lt;/a&gt; to work without leaking information despite being targeted by some very skilled and highly resourced organizations. TAILS mostly works as a ‚Äúlive CD‚Äù, meaning the whole operating system is downloaded as a single ‚Äúimage‚Äù file, then either burned to a CD/DVD, or to a USB thumb drive. Updates work the same way. But TAILS has an optional feature to use the Debian package system to install and persist packages that are not included by default. TAILS does not use the default set of mirrors that a standard Debian install uses, it is set up by default with a range of possible Debian package sources, including the current stable version (called wheezy), the versions in testing, and packages backported to the stable version. That means that when this feature is used, TAILS fetches the metadata for all of those sections of Debian (stable/wheezy, testing, wheezy-backports, unstable).&lt;/p&gt;

&lt;p&gt;Given all of the proven fingerprinting approaches, like using the font list from the browser, I think its a safe assumption that the apt-get metadata will also provide similar fingerprinting opportunities. For basic TAILS use, this is all avoided since updates are done via ISO images. But once a user installs packages via &lt;code&gt;apt-get&lt;/code&gt;, that changes since TAILS then goes out onto the internet to fetch all of the repo metadata. That goes over Tor since TAILS forces all network traffic over Tor, so that helps break the link between the machine downloading the updates and those that can see that machines internet traffic.&lt;/p&gt;

&lt;p&gt;It seems quite likely that the set of mirrors and the order in which they are run will provide a way to identify the system as TAILS. As for identifying individual machines, &lt;code&gt;apt-get&lt;/code&gt; sends a lot of metadata, like language that the system is using, which packages need updates, etc. On top of the set of mirrors used, there is potentially enough metadata there to fingerprint the individual machine.&lt;/p&gt;

&lt;p&gt;One open question is how the &lt;code&gt;apt-get&lt;/code&gt; downloads map to different Tor circuits. If all of the traffic from a given &lt;code&gt;apt-get&lt;/code&gt; session goes over a single Tor circuit, then the exit node, the mirror server, and any network observer that can see the traffic between those two can use that as the fingerprint.&lt;/p&gt;

&lt;p&gt;To expand on this, if TAILS fetched all of its apt sources (wheezy, backports, testing, etc) via HTTPS from the same mirror (e.g. mirrors.kernel.org), then the exit node and network observer could not really distinguish the distro the machine making the connection was running since mirrors.kernel.org hosts many distro mirrors. There are two key parts here: using HTTPS to encrypt the data, and using HTTP pipelining so that network connections are reused for multiple downloads, rather than the default behavior of making a new HTTPS for each individual download. This setup would also prevent the custom pattern of apt sources from being distinguished since it would just show as downloading some series of files, and those files could be packages, package metadata, perl modules, source tarballs, etc.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Question: central server, federated, or p2p? Answer: all!</title>
      <link>https://guardianproject.github.io/info/2014/09/18/question-central-server-federated-or-p2p-answer-all/</link>
      <pubDate>Thu, 18 Sep 2014 00:30:57 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2014/09/18/question-central-server-federated-or-p2p-answer-all/</guid>
      <description>&lt;p&gt;There are many ideas of core architectures for providing digital services, each with their own advantages and disadvantages. I break it down along the lines of central servers, federated servers, and peer-to-peer, serverless systems.&lt;/p&gt;

&lt;div id=&#34;attachment_12631&#34; style=&#34;width: 210px&#34; class=&#34;wp-caption aligncenter&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2014/09/200px-Server-based-network.svg_.png&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12631&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2014/09/200px-Server-based-network.svg_.png&#34; alt=&#34;a central service with clients connecting to it&#34; width=&#34;200&#34; height=&#34;207&#34; class=&#34;size-full wp-image-12631&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/09/200px-Server-based-network.svg_.png 200w, https://guardianproject.info/wp-content/uploads/2014/09/200px-Server-based-network.svg_-100x103.png 100w, https://guardianproject.info/wp-content/uploads/2014/09/200px-Server-based-network.svg_-150x155.png 150w&#34; sizes=&#34;(max-width: 200px) 100vw, 200px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12631&#34; class=&#34;wp-caption-text&#34;&gt;
    a central service with clients connecting to it
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Most big internet companies operate in effect as a central server (even though they are implemented differently). There is only facebook.com, there are no other services that can inter-operate with facebook.com. Have a single, central repo makes problems of finding the service and finding people within the service a lot easier. Once you are in Facebook, you just need to know the name of the person you want to contact and you are connected. The Facebook apps just need to talk to facebook.com, so the user does not need to know which service they are using in order to configure the app.&lt;/p&gt;

&lt;div id=&#34;attachment_12633&#34; style=&#34;width: 310px&#34; class=&#34;wp-caption aligncenter&#34;&gt;
  &lt;a href=&#34;http://www.bendevane.com/RDC2012/ians/2012/10/09/campsiteofthefutur/&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12633&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2014/09/Federated-01-1024x582-300x170.png&#34; alt=&#34;email as federated service&#34; width=&#34;300&#34; height=&#34;170&#34; class=&#34;size-medium wp-image-12633&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/09/Federated-01-1024x582-300x170.png 300w, https://guardianproject.info/wp-content/uploads/2014/09/Federated-01-1024x582-100x56.png 100w, https://guardianproject.info/wp-content/uploads/2014/09/Federated-01-1024x582-150x85.png 150w, https://guardianproject.info/wp-content/uploads/2014/09/Federated-01-1024x582-200x113.png 200w, https://guardianproject.info/wp-content/uploads/2014/09/Federated-01-1024x582-450x255.png 450w, https://guardianproject.info/wp-content/uploads/2014/09/Federated-01-1024x582-600x341.png 600w, https://guardianproject.info/wp-content/uploads/2014/09/Federated-01-1024x582-900x511.png 900w, https://guardianproject.info/wp-content/uploads/2014/09/Federated-01-1024x582.png 1024w&#34; sizes=&#34;(max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12633&#34; class=&#34;wp-caption-text&#34;&gt;
    email as federated service
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Email is a great example of a federated system. Each email provider acts like a central server, but then each of those central servers can easily talk to each other and exchange data. So fastmail.fm and gmail.com are both centralized services, but users do not need to know any extra information in order to exchange emails between the two services, or any other of the millions of email servers out there. A federated system provides a lot of the benefits of a centralized server with more flexibility. The downside is that federated services generally require more configuration to use them (though webmail makes that much less of an issue).&lt;/p&gt;

&lt;div id=&#34;attachment_12632&#34; style=&#34;width: 310px&#34; class=&#34;wp-caption aligncenter&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2014/09/300px-Unstructured_peer-to-peer_network_diagram.png&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12632&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2014/09/300px-Unstructured_peer-to-peer_network_diagram.png&#34; alt=&#34;a peer-to-peer network&#34; width=&#34;300&#34; height=&#34;245&#34; class=&#34;size-full wp-image-12632&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/09/300px-Unstructured_peer-to-peer_network_diagram.png 300w, https://guardianproject.info/wp-content/uploads/2014/09/300px-Unstructured_peer-to-peer_network_diagram-100x81.png 100w, https://guardianproject.info/wp-content/uploads/2014/09/300px-Unstructured_peer-to-peer_network_diagram-150x122.png 150w, https://guardianproject.info/wp-content/uploads/2014/09/300px-Unstructured_peer-to-peer_network_diagram-200x163.png 200w&#34; sizes=&#34;(max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12632&#34; class=&#34;wp-caption-text&#34;&gt;
    a peer-to-peer network
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Peer-to-peer systems can provide unique benefits of bandwidth efficiency as well as working around blockages in the internet. Sharing large files with thousands of people is quite expensive when using a central server, but with bittorrent, anyone can share large files to many many people using only a basic broadband connection.&lt;/p&gt;

&lt;p&gt;Over the past year and a half of our Bazaar project, we have been thinking a lot about how to distribute apps to people who face a number of challenges. Each of these systems offers distinct advantages and disadvantages, so it is quite difficult to choose only one. Instead, we thought why not try to make a system that combines all three? Android‚Äôs APK app package format is a good format to work in this model because they are self-contained and containing a form of embedded identity in the app signature. So if you already have an Android app installed, then Android will enforce that only APKs signed by the same key as the installed app can be installed over it.&lt;/p&gt;

&lt;p&gt;That means in theory, it does not matter where the APK came from as long as it has a valid signature. There are some details where it does matter, mostly related to exploits like ‚ÄúMaster Key‚Äù that can inject code into an existing APK. The FDroid app repository signature has a similar property: once you trust the repository signing key, it does not matter how you got the repository files as long as the signature validates. This is a model proven by GNU/Linux distros like Debian. The repository metadata also provides a way to validate APKs have not been modified since they were added to the signed repository. Since both of these do not rely on the method of transport to prove their authenticity, this combination provides a great testbed for this idea of combining a central service, with decentralized servers and peer-to-peer distribution.&lt;/p&gt;

&lt;p&gt;This work was all incorporated in the &lt;a href=&#34;https://f-droid.org&#34; target=&#34;_blank&#34;&gt;FDroid&lt;/a&gt; app store for Android. The central f-droid.org app repository means that FDroid can deliver well over one thousand apps without any configuration on the part of the user. The ‚Äúfdroidserver‚Äù developer tools means that anyone can set up their own repository of apps, and users can easily add that repository to FDroid. It is not quite zero configuration, but the process is not too difficult, and there is more we are planning to do to smooth out that process even more. This also provides a channel for users to get apps via ‚Äúcollateral freedom‚Äù techniques like using Amazon S3, Akamai, etc. to distribute files where many such services are filtered or blocked. Lastly, we made it possible to have the FDroid app itself act as an app repository, and other devices can connect to that repository using local WiFi, mesh, Bluetooth, and removable media.&lt;/p&gt;

&lt;p&gt;This stuff is all implemented and included in the FDroid app and fdroidserver developer tools. The big remaining challenge is combining them all into a usable experience for people who do not know the technical details. This has been tested, discussed, sketched out, and there is a prototype implementation in the works. So I can end with a quick overview of some positive and negative observations about the various peer-to-peer connections that we experimented with:&lt;/p&gt;

&lt;ul style=&#34;list-style-type: none;&#34;&gt;
  &lt;li&gt;
    &lt;strong&gt;+&lt;/strong&gt; Bluetooth is ubiquitous
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; very slow data rate
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; pairing is difficult
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&#34;list-style-type: none;&#34;&gt;
  &lt;li&gt;
    &lt;strong&gt;+&lt;/strong&gt; WiFi is very widespread
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;+&lt;/strong&gt; local connections are very fast
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; access points and proxies can block host-to-host connections
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; running access points on a device is not common nor easy
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&#34;list-style-type: none;&#34;&gt;
  &lt;li&gt;
    &lt;strong&gt;+&lt;/strong&gt; NFC makes Bluetooth very easy to use
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; NFC is not commonly used or available
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; NFC is far to slow and fiddly to be used as the data transmission medium
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&#34;list-style-type: none;&#34;&gt;
  &lt;li&gt;
    &lt;strong&gt;+&lt;/strong&gt; SD cards can move lots of data securely
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; not all devices have removable SD cards
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; swapping SD cards can be a fiddly process
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; swapping SD cards can not be automatic
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&#34;list-style-type: none;&#34;&gt;
  &lt;li&gt;
    &lt;strong&gt;+&lt;/strong&gt; USB thumb drives can move lots of data securely
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;+&lt;/strong&gt; they can be easily swapped between devices
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; swapping SD cards can not be automatic
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; not all devices support USB-OTG i.e. attached devices
  &lt;/li&gt;
  &lt;li&gt;
    &lt;strong&gt;‚Äì&lt;/strong&gt; USB-OTG is not widely used
  &lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Introducing TrustedIntents for Android</title>
      <link>https://guardianproject.github.io/info/2014/07/30/introducing-trustedintents-for-android/</link>
      <pubDate>Wed, 30 Jul 2014 23:29:23 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2014/07/30/introducing-trustedintents-for-android/</guid>
      <description>

&lt;p&gt;Following up on &lt;a href=&#34;https://guardianproject.info/2014/01/21/improving-trust-and-flexibility-in-interactions-between-android-apps/&#34;&gt;our research on secure Intent interactions&lt;/a&gt;, we are now announcing the first working version of the &lt;a href=&#34;https://github.com/guardianproject/TrustedIntents&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;TrustedIntents&lt;/em&gt;&lt;/a&gt; library for Android. It provides methods for checking any Intent for whether the sending and receiving app matches a specified set of trusted app providers. It does this by ‚Äúpinning‚Äù to the signing certificate of the APKs. The developer includes this ‚Äúpin‚Äù in the app, which includes the signing certificate to trust, then &lt;em&gt;TrustedIntents&lt;/em&gt; checks &lt;code&gt;Intent&lt;/code&gt;s against the configured certificate pins. The library includes pins for the Guardian Project and Tor Project signing certificates. It is also easy to generate the pin using our new utility &lt;a href=&#34;https://github.com/guardianproject/checkey&#34; target=&#34;_blank&#34;&gt;Checkey&lt;/a&gt; (available in &lt;a href=&#34;https://guardianproject.info/2014/06/30/new-official-guardian-project-app-repo-for-fdroid/&#34; target=&#34;_blank&#34;&gt;our FDroid repo&lt;/a&gt; and in &lt;a href=&#34;https://play.google.com/store/apps/details?id=info.guardianproject.checkey&#34; target=&#34;_blank&#34;&gt;Google Play&lt;/a&gt;).&lt;/p&gt;

&lt;div id=&#34;attachment_12560&#34; style=&#34;width: 310px&#34; class=&#34;wp-caption alignright&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2014/07/checkey-phone.png&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12560&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2014/07/checkey-phone-300x168.png&#34; alt=&#34;Checkey displaying the signing certificate of ChatSecure&#34; width=&#34;300&#34; height=&#34;168&#34; class=&#34;size-medium wp-image-12560&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/07/checkey-phone-300x168.png 300w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-phone-1024x576.png 1024w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-phone-100x56.png 100w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-phone-150x84.png 150w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-phone-200x112.png 200w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-phone-450x253.png 450w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-phone-600x337.png 600w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-phone-900x506.png 900w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-phone.png 1280w&#34; sizes=&#34;(max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12560&#34; class=&#34;wp-caption-text&#34;&gt;
    Checkey displaying the signing certificate of ChatSecure
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;We hope to make this process as dead simple as possible by providing developers with this library. &lt;em&gt;TrustedIntents&lt;/em&gt; is currently set up as an ‚ÄúAndroid Library Project‚Äù but it could easily be a jar too, the code is currently quite simple, the plan is to add more convenience methods and also support for TOFU/POP in addition to pinning. For usage examples, check out &lt;a href=&#34;https://github.com/guardianproject/TrustedIntentsExample&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;TrustedIntentsExample&lt;/em&gt;&lt;/a&gt; and the test project under the test/ subdir of the &lt;em&gt;TrustedIntents&lt;/em&gt; library source repo.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;TrustedIntents&lt;/em&gt; source: &lt;a href=&#34;https://github.com/guardianproject/TrustedIntents&#34; target=&#34;_blank&#34;&gt;&lt;a href=&#34;https://github.com/guardianproject/TrustedIntents&#34;&gt;https://github.com/guardianproject/TrustedIntents&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;example project: &lt;a href=&#34;https://github.com/guardianproject/TrustedIntentsExample&#34; target=&#34;_blank&#34;&gt;&lt;a href=&#34;https://github.com/guardianproject/TrustedIntentsExample&#34;&gt;https://github.com/guardianproject/TrustedIntentsExample&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;wiki, issue tracker, etc: &lt;a href=&#34;https://dev.guardianproject.info/projects/trustedintents/wiki&#34; target=&#34;_blank&#34;&gt;&lt;a href=&#34;https://dev.guardianproject.info/projects/trustedintents/wiki&#34;&gt;https://dev.guardianproject.info/projects/trustedintents/wiki&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Checkey&lt;/em&gt; source: &lt;a href=&#34;https://github.com/guardianproject/Checkey&#34; target=&#34;_blank&#34;&gt;&lt;a href=&#34;https://github.com/guardianproject/Checkey&#34;&gt;https://github.com/guardianproject/Checkey&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Checkey&lt;/em&gt; includes a simple method for generating the certificate pins. The pin is in the format of Java subclass of &lt;code&gt;ApkSignaturePin&lt;/code&gt;, which provides all needed utility functions. The create the pin file, first install the app whose certificate you want to trust. Be sure to get it from a trusted source since you are going to be trusting the signing certificate of the APK that you have installed. Launch &lt;em&gt;Checkey&lt;/em&gt; and select that app in the list, you will see the certificate details show up on the top. To generate the .java file for pinning Intents, select &lt;strong&gt;Generate Pin&lt;/strong&gt; from the menu and send the resulting file to yourself. That file is the pin, include it in your project, then load it into TrustedIntents by doing in &lt;code&gt;onCreate()&lt;/code&gt; or wherever is appropriate:&lt;br /&gt;
&lt;code&gt;&amp;lt;br /&amp;gt;
TrustedIntents ti = TrustedIntents.get(context);&amp;lt;br /&amp;gt;
ti.isTrustedSigner(MySigningCertificatePin.class);&amp;lt;br /&amp;gt;
&lt;/code&gt;&lt;/p&gt;

&lt;div id=&#34;attachment_12565&#34; style=&#34;width: 610px&#34; class=&#34;wp-caption aligncenter&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2014/07/checkey-generate-pin.png&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12565&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2014/07/checkey-generate-pin.png&#34; alt=&#34;How to generate a pin file with Checkey&#34; width=&#34;600&#34; height=&#34;444&#34; class=&#34;size-medium wp-image-12565&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/07/checkey-generate-pin-300x222.png 300w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-generate-pin-100x74.png 100w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-generate-pin-150x111.png 150w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-generate-pin-200x148.png 200w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-generate-pin-450x334.png 450w, https://guardianproject.info/wp-content/uploads/2014/07/checkey-generate-pin-600x445.png 600w&#34; sizes=&#34;(max-width: 600px) 100vw, 600px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12565&#34; class=&#34;wp-caption-text&#34;&gt;
    How to generate a pin file with Checkey
  &lt;/p&gt;
&lt;/div&gt;

&lt;h3 id=&#34;gathering-all-the-edge-cases&#34;&gt;Gathering all the edge cases&lt;/h3&gt;

&lt;p&gt;One of the things I‚Äôve focused on in the &lt;em&gt;TrustedIntents&lt;/em&gt; library is thinking about all the possible edge cases and how to check for them. It is rare that the main part of a security check algorithm fails, its almost always the edge cases that are the gotcha.&lt;/p&gt;

&lt;p&gt;One example: &lt;em&gt;TrustedIntents&lt;/em&gt; should properly check all signing certificates on an APK. From what I‚Äôve seen, it is rare that APKs are signed by more than one certificate, but the spec allows for that. There might be exploits related to not handling that.&lt;/p&gt;

&lt;p&gt;Another thing is that &lt;em&gt;TrustedIntents&lt;/em&gt; uses the method that the Android code uses for comparing signatures: it does a byte-by-byte comparison of the signature byte arrays. Some apps area already doing something similar based on the hash of the signing certificate (i.e. the ‚Äúfingerprint‚Äù). The Android technique will also be faster than hashing since the hash algorithm has to read the whole signature byte array anyway.&lt;/p&gt;

&lt;p&gt;We‚Äôd love to have feedback, flames, comments, etc on any and all of this. &lt;a href=&#34;https://guardianproject.info/contact/&#34;&gt;Let us know&lt;/a&gt; how it works for you!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Official Guardian Project app repo for FDroid!</title>
      <link>https://guardianproject.github.io/info/2014/06/30/new-official-guardian-project-app-repo-for-fdroid/</link>
      <pubDate>Mon, 30 Jun 2014 20:26:39 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2014/06/30/new-official-guardian-project-app-repo-for-fdroid/</guid>
      <description>

&lt;p&gt;We now have an official &lt;a href=&#34;https://f-droid.org&#34; target=&#34;_blank&#34;&gt;FDroid&lt;/a&gt; app repository that is available via three separate methods, to guarantee access to a trusted distribution channel throughout the world! To start with, you must have FDroid installed. Right now, I recommend using the latest test release since it has support for Tor and .onion addresses (earlier versions should work for non-onion addresses):&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://f-droid.org/repo/org.fdroid.fdroid_710.apk&#34;&gt;https://f-droid.org/repo/org.fdroid.fdroid_710.apk&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In order to add this repo to your FDroid config, you can either click directly on these links on your devices and FDroid will recognize them, or you can click on them on your desktop, and you will be presented with a QR Code to scan. Here are your options:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HTTPS: &lt;a href=&#34;https://guardianproject.info/fdroid/repo?fingerprint=B7C2EEFD8DAC7806AF67DFCD92EB18126BC08312A7F2D6F3862E46013C7A6135&#34;&gt;https://guardianproject.info/fdroid/repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Tor Hidden Service aka onion address: &lt;a href=&#34;http://bdf2wcxujkg6qqff.onion/fdroid/repo?fingerprint=B7C2EEFD8DAC7806AF67DFCD92EB18126BC08312A7F2D6F3862E46013C7A6135&#34;&gt;http://bdf2wcxujkg6qqff.onion/fdroid/repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Amazon AWS S3 Bucket (&lt;em&gt;this does not show up in a browser&lt;/em&gt;): &lt;a href=&#34;https://s3.amazonaws.com/guardianproject/fdroid/repo?fingerprint=B7C2EEFD8DAC7806AF67DFCD92EB18126BC08312A7F2D6F3862E46013C7A6135&#34;&gt;https://s3.amazonaws.com/guardianproject/fdroid/repo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From here on out, our old FDroid repo (&lt;a href=&#34;https://guardianproject.info/repo&#34;&gt;https://guardianproject.info/repo&lt;/a&gt;) is considered deprecated and will no longer be updated. It will eventually be removed. Update to the new one!&lt;/p&gt;

&lt;p&gt;Also, if you missed it before, all of our test builds are also &lt;a href=&#34;https://guardianproject.info/2014/06/06/automatic-private-distribution-of-our-test-builds/&#34;&gt;available for testing only via FDroid&lt;/a&gt;. Just remember, the builds in the test repo are only debug builds, not fully trusted builds, so use them for testing only.&lt;/p&gt;

&lt;h3 id=&#34;automate-it-all&#34;&gt;Automate it all!&lt;/h3&gt;

&lt;p&gt;This setup has three distribution channels that are all mirrors of a repo that is generated on a fully offline machine. This is only manageable because of lots of new automation features in the &lt;a href=&#34;https://gitlab.com/fdroid/fdroidserver&#34; target=&#34;_blank&#34;&gt;fdroidserver&lt;/a&gt; tools for building and managing app repos. You can now set up a USB thumb drive as the automatic courier for shuffling the repo from the offline machine to an online machine. The repo is generated, updated, and signed using &lt;code&gt;fdroid update&lt;/code&gt;, then those signed files are synced to the USB thumb drive using &lt;code&gt;fdroid server update&lt;/code&gt;. Then the online machine syncs the signed files from that USB thumb drive to multiple servers via SSH and Amazon S3 with a single command: &lt;code&gt;fdroid server update&lt;/code&gt;. The magic is in setting up the config options and letting the tools do the rest.&lt;/p&gt;

&lt;h3 id=&#34;new-repo-signing-key&#34;&gt;New Repo Signing Key&lt;/h3&gt;

&lt;p&gt;For part of this, I‚Äôve completed the process of generating a new, fully offline fdroid &lt;a href=&#34;https://guardianproject.info/home/signing-keys/&#34;&gt;signing key&lt;/a&gt;. So that means there is a new signing key for the FDroid repo, and the old repo signing key is being retired.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://guardianproject.info/releases/guardianproject-rsa4096-fdroid-repo-signing-key.pem&#34;&gt;guardianproject-rsa4096-fdroid-repo-signing-key.pem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://guardianproject.info/releases/guardianproject-rsa4096-fdroid-repo-signing-key.pem.sig&#34;&gt;guardianproject-rsa4096-fdroid-repo-signing-key.pem.sig&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The fingerprints for this signing key are:&lt;/p&gt;

&lt;pre&gt;Owner: EMAILADDRESS=root@guardianp&amp;#x72;&amp;#x6f;&amp;#x6a;&amp;#x65;&amp;#x63;&amp;#x74;&amp;#x2e;&amp;#x69;&amp;#x6e;&amp;#x66;&amp;#x6f;, CN=guardianproject.info, O=Guardian Project, OU=FDroid Repo, L=New York, ST=New York, C=US
Issuer: &amp;#x45;&amp;#x4d;&amp;#x41;ILADD&amp;#x52;&amp;#x45;&amp;#x53;&amp;#x53;=roo&amp;#x74;&amp;#x40;&amp;#x67;&amp;#x75;ardi&amp;#x61;&amp;#x6e;&amp;#x70;&amp;#x72;oject&amp;#x2e;&amp;#x69;&amp;#x6e;&amp;#x66;o, CN=guardianproject.info, O=Guardian Project, OU=FDroid Repo, L=New York, ST=New York, C=US
Serial number: a397b4da7ecda034
Valid from: Thu Jun 26 15:39:18 EDT 2014 until: Sun Nov 10 14:39:18 EST 2041
Certificate fingerprints:
 MD5:  8C:BE:60:6F:D7:7E:0D:2D:B8:06:B5:B9:AD:82:F5:5D
 SHA1: 63:9F:F1:76:2B:3E:28:EC:CE:DB:9E:01:7D:93:21:BE:90:89:CD:AD
 SHA256: B7:C2:EE:FD:8D:AC:78:06:AF:67:DF:CD:92:EB:18:12:6B:C0:83:12:A7:F2:D6:F3:86:2E:46:01:3C:7A:61:35
 Signature algorithm name: SHA1withRSA
 Version: 1
&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Security in a thumb drive: the promise and pain of hardware security modules, take one!</title>
      <link>https://guardianproject.github.io/info/2014/03/28/security-in-a-thumb-drive-the-promise-and-pain-of-hardware-security-modules-take-one/</link>
      <pubDate>Fri, 28 Mar 2014 16:54:39 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2014/03/28/security-in-a-thumb-drive-the-promise-and-pain-of-hardware-security-modules-take-one/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2014/03/cryptostick-usb-flash-drive-security-software.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2014/03/cryptostick-usb-flash-drive-security-software.jpg&#34; alt=&#34;security in a thumb drive&#34; width=&#34;219&#34; height=&#34;119&#34; class=&#34;alignleft size-full wp-image-12311&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/03/cryptostick-usb-flash-drive-security-software.jpg 219w, https://guardianproject.info/wp-content/uploads/2014/03/cryptostick-usb-flash-drive-security-software-100x54.jpg 100w, https://guardianproject.info/wp-content/uploads/2014/03/cryptostick-usb-flash-drive-security-software-150x81.jpg 150w, https://guardianproject.info/wp-content/uploads/2014/03/cryptostick-usb-flash-drive-security-software-200x108.jpg 200w&#34; sizes=&#34;(max-width: 219px) 100vw, 219px&#34; /&gt;&lt;/a&gt;Hardware Security Modules (aka Smartcards, chipcards, etc) provide a secure way to store and use cryptographic keys, while actually making the whole process a bit easier. In theory, one USB thumb drive like thing could manage all of the crypto keys you use in a way that makes them much harder to steal. That is the promise. The reality is that the world of Hardware Security Modules (HSMs) is a massive, scary minefield of endless technical gotchas, byzantine standards (PKCS#11!), technobabble, and incompatibilities. Before I dive too much into ranting about the days of my life wasted trying to find a clear path through this minefield, I‚Äôm going to tell you about one path I did find through to solve a key piece of the puzzle: Android and Java package signing.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2014/03/moreinfo_acr38t_ibs.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2014/03/moreinfo_acr38t_ibs.jpg&#34; alt=&#34;ACS ACR38-T-IBS&#34; width=&#34;320&#34; height=&#34;248&#34; class=&#34;alignright size-full wp-image-12313&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/03/moreinfo_acr38t_ibs.jpg 320w, https://guardianproject.info/wp-content/uploads/2014/03/moreinfo_acr38t_ibs-300x232.jpg 300w, https://guardianproject.info/wp-content/uploads/2014/03/moreinfo_acr38t_ibs-100x77.jpg 100w, https://guardianproject.info/wp-content/uploads/2014/03/moreinfo_acr38t_ibs-150x116.jpg 150w, https://guardianproject.info/wp-content/uploads/2014/03/moreinfo_acr38t_ibs-200x155.jpg 200w&#34; sizes=&#34;(max-width: 320px) 100vw, 320px&#34; /&gt;&lt;/a&gt;For this round, I am covering the &lt;a href=&#34;http://www.aventra.fi/English/products_MyEID_E.html&#34; target=&#34;_blank&#34;&gt;Aventra MyEID PKI Card&lt;/a&gt;. I bought a SIM-sized version to fit into an &lt;a href=&#34;http://www.smartcardfocus.com/ilp/id~99/ACR38T_IBS/p/readers.shtml&#34; target=&#34;_blank&#34;&gt;ACS ACR38T-IBS-R&lt;/a&gt; smartcard reader (it is apparently no longer made, and the &lt;a href=&#34;http://acs.com.hk/en/products/1/acr38t-d1-plug-in-sim-sized-card-reader/&#34; target=&#34;_blank&#34;&gt;ACT38T-D1&lt;/a&gt; is meant to replace it). Why such specificity you may ask? Because you have to be sure that your smartcard will work with your reader, and that your reader will have a working driver for you system, and that your smartcard will have a working PKCS#11 driver so that software can talk to the smartcard. Thankfully there is the &lt;a href=&#34;https://github.com/OpenSC/OpenSC/wiki&#34; target=&#34;_blank&#34;&gt;OpenSC&lt;/a&gt; project to cover the PKCS#11 part, it implements the PKCS#11 communications standard for many smartcards. On my Ubuntu/precise system, I had to install an extra driver, &lt;code&gt;libacr38u&lt;/code&gt;, to get the ACR38T reader to show up on my system.&lt;/p&gt;

&lt;p&gt;So let‚Äôs start there and get this thing to show up! First we need some packages. The OpenSC packages are out-of-date in a lot of releases, you need version 0.13.0-4 or newer, so you have to add our PPA (Personal Package Archive) to get current versions, which include a &lt;a href=&#34;https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=742089&#34; target=&#34;_blank&#34;&gt;specific fix for the Aventra MyEID&lt;/a&gt;: (fingerprint: &lt;code&gt;F50E ADDD 2234 F563&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo add-apt-repository ppa:guardianproject/ppa
sudo apt-get update
sudo apt-get install opensc libacr38u libacsccid1 pcsc-tools usbutils
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First thing, I use &lt;code&gt;lsusb&lt;/code&gt; in the terminal to see what USB devices the Linux kernel sees, and thankfully it sees my reader:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ lsusb
Bus 005 Device 013: ID 072f:9000 Advanced Card Systems, Ltd ACR38 AC1038-based Smart Card Reader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, its time to try &lt;code&gt;pcsc_scan&lt;/code&gt; to see if the system can see the smartcard installed in the reader. If everything is installed and in order, then &lt;code&gt;pcsc_scan&lt;/code&gt; will report this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ pcsc_scan 
PC/SC device scanner
V 1.4.18 (c) 2001-2011, Ludovic Rousseau &amp;lt;&amp;amp;#x6c;u&amp;amp;#x64;ov&amp;amp;#x69;c.&amp;amp;#x72;o&amp;amp;#x75;&amp;amp;#x73;s&amp;amp;#x65;au&amp;amp;#x40;f&amp;amp;#x72;&amp;amp;#x65;e&amp;amp;#x2e;fr&amp;gt;
Compiled with PC/SC lite version: 1.7.4
Using reader plug&#39;n play mechanism
Scanning present readers...
0: ACS ACR38U 00 00

Thu Mar 27 14:38:36 2014
Reader 0: ACS ACR38U 00 00
  Card state: Card inserted, 
  ATR: 3B F5 18 00 00 81 31 FE 45 4D 79 45 49 44 9A
[snip]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If &lt;code&gt;pcsc_scan&lt;/code&gt; cannot see the card, then things will not work. Try re-seating the smardcard in the reader, make sure you have all the right packages installed, and if you can see the reader in &lt;code&gt;lsusb&lt;/code&gt;. If your smartcard or reader cannot be read, then &lt;code&gt;pcsc_scan&lt;/code&gt; will report something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ pcsc_scan 
PC/SC device scanner
V 1.4.18 (c) 2001-2011, Ludovic Rousseau &amp;lt;&amp;amp;#x6c;&amp;amp;#x75;&amp;amp;#x64;&amp;amp;#x6f;&amp;amp;#x76;&amp;amp;#x69;c.rousse&amp;amp;#x61;&amp;amp;#x75;&amp;amp;#x40;&amp;amp;#x66;&amp;amp;#x72;&amp;amp;#x65;e.fr&amp;gt;
Compiled with PC/SC lite version: 1.7.4
Using reader plug&#39;n play mechanism
Scanning present readers...
Waiting for the first reader...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Moving right along‚Ä¶ now &lt;code&gt;pcscd&lt;/code&gt; can see the smartcard, so we can start playing with using the OpenSC tools. These are needed to setup the card, put PINs on it for access control, and upload keys and certificates to it. The last annoying little preparation tasks are finding where &lt;code&gt;opensc-pkcs11.so&lt;/code&gt; is installed and the ‚Äúslot‚Äù for the signing key in the card. These will go into a config file which &lt;code&gt;keytool&lt;/code&gt; and &lt;code&gt;jarsigner&lt;/code&gt; need. To get this info on Debian/Ubuntu/etc, run these:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ dpkg -S opensc-pkcs11.so
opensc: /usr/lib/x86_64-linux-gnu/opensc-pkcs11.so
$ pkcs11-tool --module /usr/lib/x86_64-linux-gnu/opensc-pkcs11.so \
&amp;gt;     --list-slots
Available slots:
Slot 0 (0xffffffffffffffff): Virtual hotplug slot
  (empty)
Slot 1 (0x1): ACS ACR38U 00 00
  token label        : MyEID (signing)
  token manufacturer : Aventra Ltd.
  token model        : PKCS#15
  token flags        : rng, login required, PIN initialized, token initialized
  hardware version   : 0.0
  firmware version   : 0.0
  serial num         : 0106004065952228
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the info needed to put into a &lt;code&gt;opensc-java.cfg&lt;/code&gt;, which &lt;code&gt;keytool&lt;/code&gt; and &lt;code&gt;jarsigner&lt;/code&gt; &lt;a href=&#34;http://docs.oracle.com/javase/7/docs/technotes/guides/security/p11guide.html&#34; target=&#34;_blank&#34;&gt;need in order to talk&lt;/a&gt; to the Aventra HSM. The name, library, and slot fields are essential, and the description is helpful. Here is how the &lt;code&gt;opensc-java.cfg&lt;/code&gt; using the above information looks:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;name = OpenSC
description = SunPKCS11 w/ OpenSC Smart card Framework
library = /usr/lib/x86_64-linux-gnu/opensc-pkcs11.so
slot = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now everything should be ready for initializing the HSM, generating a new key, and uploading that key to the HSM. This process generates the key and certificate, puts them into files, then uploads them to the HSM. That means you should only run this process on a trusted machine, certainly with some kind of disk encryption, and preferably on a machine that is not connected to a network, running an OS that has never been connected to the internet. A live CD is one good example, I recommend &lt;a href=&#34;https://tails.boum.org/download/index.en.html#index4h1&#34; target=&#34;_blank&#34;&gt;Tails on a USB thumb drive&lt;/a&gt; running with the &lt;a href=&#34;https://tails.boum.org/doc/first_steps/persistence/index.en.html&#34; target=&#34;_blank&#34;&gt;secure persistent store&lt;/a&gt; on it (we have been working here and there on making a TAILS-based distro specifically for managing keys, we call it &lt;a href=&#34;https://dev.guardianproject.info/projects/psst/wiki/CleanRoom&#34; target=&#34;_blank&#34;&gt;CleanRoom&lt;/a&gt;).&lt;/p&gt;

&lt;div id=&#34;attachment_12321&#34; style=&#34;width: 560px&#34; class=&#34;wp-caption aligncenter&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2014/03/cstick2.jpg&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12321&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2014/03/cstick2-1024x805.jpg&#34; alt=&#34;HSM plugged into a laptop&#34; width=&#34;550&#34; height=&#34;432&#34; class=&#34;size-large wp-image-12321&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/03/cstick2-1024x805.jpg 1024w, https://guardianproject.info/wp-content/uploads/2014/03/cstick2-300x235.jpg 300w, https://guardianproject.info/wp-content/uploads/2014/03/cstick2-100x78.jpg 100w, https://guardianproject.info/wp-content/uploads/2014/03/cstick2-150x117.jpg 150w, https://guardianproject.info/wp-content/uploads/2014/03/cstick2-200x157.jpg 200w, https://guardianproject.info/wp-content/uploads/2014/03/cstick2-450x353.jpg 450w, https://guardianproject.info/wp-content/uploads/2014/03/cstick2-600x471.jpg 600w, https://guardianproject.info/wp-content/uploads/2014/03/cstick2-900x707.jpg 900w, https://guardianproject.info/wp-content/uploads/2014/03/cstick2.jpg 1600w&#34; sizes=&#34;(max-width: 550px) 100vw, 550px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12321&#34; class=&#34;wp-caption-text&#34;&gt;
    HSM plugged into a laptop
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;First off, the HSM needs to be initialized, then set up with a signing PIN and a ‚ÄúSecurity Officer‚Äù PIN (which means basically an ‚Äúadmin‚Äù or ‚Äúroot‚Äù PIN). The signing PIN is the one you will use for signing APKs, the ‚ÄúSecurity Officer PIN‚Äù (SO-PIN) is used for modifying the HSM setup, like uploading new keys, etc. Because there are so many steps in the process, I‚Äôve written up scripts to run thru all of the steps. If you want to see the details, &lt;a href=&#34;https://github.com/guardianproject/smartcard-apk-signing/blob/master/Aventra_MyEID_Setup/setup.sh&#34; target=&#34;_blank&#34;&gt;read&lt;/a&gt; &lt;a href=&#34;https://github.com/guardianproject/smartcard-apk-signing/blob/master/openssl-gen/gen.sh&#34; target=&#34;_blank&#34;&gt;the&lt;/a&gt; &lt;a href=&#34;https://github.com/guardianproject/smartcard-apk-signing/blob/master/Aventra_MyEID_Setup/finalize.sh&#34; target=&#34;_blank&#34;&gt;scripts&lt;/a&gt;. The next step is to generate the key using &lt;code&gt;openssl&lt;/code&gt; and upload it to the HSM. Then the HSM needs to be ‚Äúfinalized‚Äù, which means the PINs are activated, and keys cannot be uploaded. Don‚Äôt worry, as long as you have the SO-PIN, you can erase the HSM and re-initialize it. But be careful! Many HSMs will permanently self-destruct if you enter in the wrong PIN too many times, some will do that after only three wrong PINs! As long as you have not finalized the HSM, any PIN will work, so play around a lot with it before finalizing it. Run the init and key upload procedure a few times, try signing an APK, etc. Take note: the script will generate a random password for the secret files, then echo that password when it completes, so make sure no one can see your screen when you generate the real key. Alright, here goes!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;code $ git clone https://github.com/guardianproject/smartcard-apk-signing
code $ cd smartcard-apk-signing/Aventra_MyEID_Setup
Aventra_MyEID_Setup $ ./setup.sh 
Edit pkcs15-init-options-file-pins to put in the PINs you want to set:
Aventra_MyEID_Setup $ emacs pkcs15-init-options-file-pins
Aventra_MyEID_Setup $ ./setup.sh 
Using reader with a card: ACS ACR38U 00 00
Connecting to card in reader ACS ACR38U 00 00...
Using card driver MyEID cards with PKCS#15 applet.
About to erase card.
PIN [Security Officer PIN] required.
Please enter PIN [Security Officer PIN]: 
Using reader with a card: ACS ACR38U 00 00
Connecting to card in reader ACS ACR38U 00 00...
Using card driver MyEID cards with PKCS#15 applet.
About to create PKCS #15 meta structure.
Using reader with a card: ACS ACR38U 00 00
Connecting to card in reader ACS ACR38U 00 00...
Using card driver MyEID cards with PKCS#15 applet.
Found MyEID
About to generate key.
Using reader with a card: ACS ACR38U 00 00
Connecting to card in reader ACS ACR38U 00 00...
Using card driver MyEID cards with PKCS#15 applet.
Found MyEID
About to generate key.
next generate a key with ./gen.sh then ./finalize.sh
Aventra_MyEID_Setup $ cd ../openssl-gen/
openssl-gen $ ./gen.sh 
Usage: ./gen.sh &amp;quot;CertDName&amp;quot; [4096]
  for example:
  &amp;quot;/C=US/ST=New York/O=Guardian Project &amp;amp;#x54;e&amp;amp;#x73;&amp;amp;#x74;/&amp;amp;#x43;N=&amp;amp;#x74;es&amp;amp;#x74;.&amp;amp;#x67;&amp;amp;#x75;a&amp;amp;#x72;di&amp;amp;#x61;np&amp;amp;#x72;o&amp;amp;#x6a;&amp;amp;#x65;c&amp;amp;#x74;&amp;amp;#x2e;i&amp;amp;#x6e;fo&amp;amp;#x2f;em&amp;amp;#x61;i&amp;amp;#x6c;&amp;amp;#x41;d&amp;amp;#x64;re&amp;amp;#x73;s=&amp;amp;#x74;e&amp;amp;#x73;&amp;amp;#x74;@&amp;amp;#x67;&amp;amp;#x75;a&amp;amp;#x72;di&amp;amp;#x61;np&amp;amp;#x72;o&amp;amp;#x6a;&amp;amp;#x65;c&amp;amp;#x74;.i&amp;amp;#x6e;fo&amp;quot;
openssl-gen $ ./gen.sh &amp;quot;/C=US/ST=New York/O=Guardian Project Te&amp;amp;#x73;t&amp;amp;#x2f;C&amp;amp;#x4e;=&amp;amp;#x74;e&amp;amp;#x73;t&amp;amp;#x2e;g&amp;amp;#x75;ardi&amp;amp;#x61;n&amp;amp;#x70;r&amp;amp;#x6f;j&amp;amp;#x65;c&amp;amp;#x74;.&amp;amp;#x69;n&amp;amp;#x66;o/em&amp;amp;#x61;i&amp;amp;#x6c;A&amp;amp;#x64;d&amp;amp;#x72;e&amp;amp;#x73;s&amp;amp;#x3d;t&amp;amp;#x65;st&amp;amp;#x40;g&amp;amp;#x75;a&amp;amp;#x72;d&amp;amp;#x69;a&amp;amp;#x6e;p&amp;amp;#x72;o&amp;amp;#x6a;e&amp;amp;#x63;t.&amp;amp;#x69;n&amp;amp;#x66;o&amp;quot;
Generating key, be patient...
2048 semi-random bytes loaded
Generating RSA private key, 2048 bit long modulus
.......................................+++
..................................................+++
e is 65537 (0x10001)
Signature ok
subject=/C=US/ST=New York/O=Guardian Project Test/&amp;amp;#x43;&amp;amp;#x4e;&amp;amp;#x3d;&amp;amp;#x74;&amp;amp;#x65;st.gu&amp;amp;#x61;&amp;amp;#x72;&amp;amp;#x64;&amp;amp;#x69;&amp;amp;#x61;nproj&amp;amp;#x65;&amp;amp;#x63;&amp;amp;#x74;&amp;amp;#x2e;&amp;amp;#x69;nfo/e&amp;amp;#x6d;&amp;amp;#x61;&amp;amp;#x69;&amp;amp;#x6c;&amp;amp;#x41;ddres&amp;amp;#x73;&amp;amp;#x3d;&amp;amp;#x74;&amp;amp;#x65;&amp;amp;#x73;t@gua&amp;amp;#x72;&amp;amp;#x64;&amp;amp;#x69;&amp;amp;#x61;&amp;amp;#x6e;proje&amp;amp;#x63;&amp;amp;#x74;&amp;amp;#x2e;&amp;amp;#x69;&amp;amp;#x6e;fo
Getting Private key
writing RSA key
Your HSM will prompt you for &#39;Security Officer&#39; aka admin PIN, wait for it!
Enter destination keystore password:  
Entry for alias 1 successfully imported.
Import command completed:  1 entries successfully imported, 0 entries failed or cancelled
[Storing keystore]
Key fingerprints for reference:
MD5 Fingerprint=90:24:68:F3:F3:22:7D:13:8C:81:11:C3:A4:B6:9A:2F
SHA1 Fingerprint=3D:9D:01:C9:28:BD:1F:F4:10:80:FC:02:95:51:39:F4:7D:E7:A9:B1
SHA256 Fingerprint=C6:3A:ED:1A:C7:9D:37:C7:B0:47:44:72:AC:6E:FA:6C:3A:B2:B1:1A:76:7A:4F:42:CF:36:0F:A5:49:6E:3C:50
The public files are: certificate.pem publickey.pem request.pem
The secret files are: secretkey.pem certificate.p12 certificate.jkr
The passphrase for the secret files is: fTQ*he-[:y+69RS+W&amp;amp;+!*0O5i%n
openssl-gen $ cd ../Aventra_MyEID_Setup/
Aventra_MyEID_Setup $ ./finalize.sh 
Using reader with a card: ACS ACR38U 00 00
Connecting to card in reader ACS ACR38U 00 00...
Using card driver MyEID cards with PKCS#15 applet.
Found MyEID
About to delete object(s).
Your HSM is ready for use! Put the secret key files someplace encrypted and safe!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now your HSM should be ready for use for signing. You can try it out with &lt;code&gt;keytool&lt;/code&gt; to see what is on it, using the signing PIN not the Security Officer PIN:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;smartcard-apk-signing $ /usr/bin/keytool -v \
&amp;gt;     -providerClass sun.security.pkcs11.SunPKCS11 \
&amp;gt;     -providerArg opensc-java.cfg \
&amp;gt;     -providerName SunPKCS11-OpenSC -keystore NONE -storetype PKCS11 \
&amp;gt;     -list
Enter keystore password:  

Keystore type: PKCS11
Keystore provider: SunPKCS11-OpenSC

Your keystore contains 1 entry

Alias name: 1
Entry type: PrivateKeyEntry
Certificate chain length: 1
Certificate[1]:
Owner: &amp;amp;#x45;&amp;amp;#x4d;&amp;amp;#x41;&amp;amp;#x49;&amp;amp;#x4c;&amp;amp;#x41;&amp;amp;#x44;&amp;amp;#x44;RESS=test@g&amp;amp;#x75;&amp;amp;#x61;&amp;amp;#x72;&amp;amp;#x64;&amp;amp;#x69;&amp;amp;#x61;&amp;amp;#x6e;&amp;amp;#x70;&amp;amp;#x72;oject.info, CN=test.guardianproject.info, O=Guardian Project Test, ST=New York, C=US
Issuer: E&amp;amp;#x4d;A&amp;amp;#x49;LA&amp;amp;#x44;D&amp;amp;#x52;ES&amp;amp;#x53;=&amp;amp;#x74;e&amp;amp;#x73;&amp;amp;#x74;@&amp;amp;#x67;u&amp;amp;#x61;rd&amp;amp;#x69;a&amp;amp;#x6e;pr&amp;amp;#x6f;j&amp;amp;#x65;ct&amp;amp;#x2e;i&amp;amp;#x6e;f&amp;amp;#x6f;, CN=test.guardianproject.info, O=Guardian Project Test, ST=New York, C=US
Serial number: aa6887be1ec84bde
Valid from: Fri Mar 28 16:41:26 EDT 2014 until: Mon Aug 12 16:41:26 EDT 2041
Certificate fingerprints:
	 MD5:  90:24:68:F3:F3:22:7D:13:8C:81:11:C3:A4:B6:9A:2F
	 SHA1: 3D:9D:01:C9:28:BD:1F:F4:10:80:FC:02:95:51:39:F4:7D:E7:A9:B1
	 SHA256: C6:3A:ED:1A:C7:9D:37:C7:B0:47:44:72:AC:6E:FA:6C:3A:B2:B1:1A:76:7A:4F:42:CF:36:0F:A5:49:6E:3C:50
	 Signature algorithm name: SHA1withRSA
	 Version: 1


*******************************************
*******************************************
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And let‚Äôs try signing an actual APK using the &lt;a href=&#34;https://developer.android.com/tools/publishing/app-signing.html&#34; target=&#34;_blank&#34;&gt;arguments that Google recommends&lt;/a&gt;, again, using the signing PIN:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;smartcard-apk-signing $ /usr/bin/jarsigner -verbose \
&amp;gt;     -providerClass sun.security.pkcs11.SunPKCS11 \
&amp;gt;     -providerArg opensc-java.cfg -providerName SunPKCS11-OpenSC \
&amp;gt;     -keystore NONE -storetype PKCS11 \
&amp;gt;     -sigalg SHA1withRSA -digestalg SHA1 \
&amp;gt;     bin/LilDebi-release-unsigned.apk 1
Enter Passphrase for keystore: 
   adding: META-INF/1.SF
   adding: META-INF/1.RSA
  signing: assets/busybox
  signing: assets/complete-debian-setup.sh
  signing: assets/configure-downloaded-image.sh
  signing: assets/create-debian-setup.sh
  signing: assets/debian-archive-keyring.gpg
  signing: assets/debootstrap.tar.bz2
  signing: assets/e2fsck.static
  signing: assets/gpgv
  signing: assets/lildebi-common
[snip]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have a working, but elaborate, process for setting up a Hardware Security Module for signing APKs. Once the HSM is setup, using it should be quite straightforward. Next steps are to work out as many kinks in this process as possible so this will be the default way to sign APKs. That means things like figuring out how &lt;a href=&#34;https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=742831&#34; target=&#34;_blank&#34;&gt;Java can be pre-configured to use OpenSC in the Debian package&lt;/a&gt;, as well as including all &lt;a href=&#34;https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=742089&#34; target=&#34;_blank&#34;&gt;relevant fixes&lt;/a&gt; in the &lt;code&gt;pcscd&lt;/code&gt; and &lt;code&gt;opensc&lt;/code&gt; packages. Then the ultimate is to add support for using HSMs in Android‚Äôs generated build files like the &lt;code&gt;build.xml&lt;/code&gt; for &lt;code&gt;ant&lt;/code&gt; that is generated by &lt;code&gt;android update project&lt;/code&gt;. Then people could just plug in the HSM and run &lt;code&gt;ant release&lt;/code&gt; and have a signed APK!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving trust and flexibility in interactions between Android apps</title>
      <link>https://guardianproject.github.io/info/2014/01/21/improving-trust-and-flexibility-in-interactions-between-android-apps/</link>
      <pubDate>Tue, 21 Jan 2014 13:51:57 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2014/01/21/improving-trust-and-flexibility-in-interactions-between-android-apps/</guid>
      <description>&lt;div id=&#34;attachment_12240&#34; style=&#34;width: 310px&#34; class=&#34;wp-caption alignright&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2014/01/Android-Intents.png&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12240&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2014/01/Android-Intents-300x61.png&#34; alt=&#34;Activity1 sending an Intent that either Activity2 or Activity3 can handle.&#34; width=&#34;300&#34; height=&#34;61&#34; class=&#34;size-medium wp-image-12240&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/01/Android-Intents-300x61.png 300w, https://guardianproject.info/wp-content/uploads/2014/01/Android-Intents.png 600w&#34; sizes=&#34;(max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12240&#34; class=&#34;wp-caption-text&#34;&gt;
    &lt;code&gt;Activity1&lt;/code&gt; sending an &lt;code&gt;Intent&lt;/code&gt; that either &lt;code&gt;Activity2&lt;/code&gt; or &lt;code&gt;Activity3&lt;/code&gt; can handle.
  &lt;/p&gt;
&lt;/div&gt;Android provides a flexible system of messaging between apps in the form of 

`&lt;a href=&#34;https://developer.android.com/guide/components/intents-filters.html&#34; target=&#34;_blank&#34;&gt;Intent&lt;/a&gt;`s. It also provides the framework for reusing large chunks of apps based on the `&lt;a href=&#34;https://developer.android.com/reference/android/app/Activity.html&#34; target=&#34;_blank&#34;&gt;Activity&lt;/a&gt;` class. `Intent`s are the messages that make the requests, and `Activity`s are the basic chunk of functionality in an app, including its interface. This combination allows apps to reuse large chunks of functionality while keeping the user experience seamless and fluent. For example, an app can send an Intent to request a camera `Activity` to prompt the user to take a picture, and that process can feel integrated into the original app that made the request. Another common use of this paradigm is choosing account information from the contacts database (aka the _People_ app). When a user is composing an new email, they will want to select who the message gets sent to. Android provides both the contacts database, and a nice overlay screen for finding and selecting the person to send to. This combination is an `Activity` provided by Android. The message that the email program sends in order to trigger that `Activity` is an `Intent`.

As usual, one of the downsides of flexibility is increased security risk. This is compounded in the Android system by rules that will automatically export an Activity to receive Intents from any app, &lt;a href=&#34;https://www.eecs.berkeley.edu/~emc/papers/spsm4027-kantola.pdf&#34; title=&#34;Reducing Attack Surfaces for Intra-Application Communication in Android&#34; target=&#34;_blank&#34;&gt;when certain conditions are met&lt;/a&gt;. If an `Activity` is exported for any app to call, &lt;a href=&#34;https://www.eecs.berkeley.edu/~emc/papers/mobi168-chin.pdf&#34; title=&#34;Analyzing Inter-Application Communication in Android&#34; target=&#34;_blank&#34;&gt;it is possible for apps to send malicious &lt;code&gt;Intent&lt;/code&gt;s&lt;/a&gt; to that `Activity`. Many `Intents` are meant to be public and others are exported as a side effect. Either way, at the very least, it is necessary to &lt;a href=&#34;http://blog.palominolabs.com/2013/05/13/android-security/&#34; title=&#34;Intent Spoofing on Android&#34; target=&#34;_blank&#34;&gt;sanitize the input&lt;/a&gt; that an `Activity` receives. On the other side of the issue, if an app is trusting another app to provide a sensitive service for it, then malware can pose as the trusted app and receive sensitive data from the trusting app. &lt;a href=&#34;http://dwaterson.com/2013/06/24/data-harvesting-by-malicious-android-apps/&#34; target=&#34;_blank&#34;&gt;An app does not need to request any permissions in order to set itself up as a receiver of &lt;code&gt;Intent&lt;/code&gt;s&lt;/a&gt;.

&lt;div id=&#34;attachment_12117&#34; style=&#34;width: 361px&#34; class=&#34;wp-caption aligncenter&#34;&gt;
  &lt;a href=&#34;https://www.eecs.berkeley.edu/~emc/papers/spsm4027-kantola.pdf&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12117&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2014/01/activity-service-hijacking.png&#34; alt=&#34;Activity/Service hijacking: watch out for the little devil in the system&#34; width=&#34;351&#34; height=&#34;153&#34; class=&#34;size-full wp-image-12117&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/01/activity-service-hijacking.png 351w, https://guardianproject.info/wp-content/uploads/2014/01/activity-service-hijacking-300x130.png 300w&#34; sizes=&#34;(max-width: 351px) 100vw, 351px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12117&#34; class=&#34;wp-caption-text&#34;&gt;
    Activity/Service hijacking: watch out for the little devil in the system
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Android, of course, does provide some added protections for cases like this. For very sensitive situations, an &lt;code&gt;Activity&lt;/code&gt; can be setup to only receive &lt;code&gt;Intent&lt;/code&gt;s from apps that meet certain criteria. &lt;a href=&#34;https://www.isecpartners.com/media/11991/isec_securing_android_apps.pdf&#34; target=&#34;_blank&#34;&gt;Android permissions can restrict other apps&lt;/a&gt; from sending &lt;code&gt;Intent&lt;/code&gt;s to any given exported &lt;code&gt;Activity&lt;/code&gt;. If a separate app wants to send an &lt;code&gt;Intent&lt;/code&gt; to an &lt;code&gt;Activity&lt;/code&gt; that has be set with a permission, then that app must include that permission in its manifest, thereby publishing that it is using that permission. This provides a good way publish an API for getting permission, but leaving it relatively open for other apps to use. Other kinds of controls can be based on two aspects of an app that the Android system enforces to remain the same: &lt;a href=&#34;http://android-developers.blogspot.com/2011/06/things-that-cannot-change.html&#34; target=&#34;_blank&#34;&gt;the package name and the signing key&lt;/a&gt;. If either of those change, then Android considers it a different app altogether. The strictest control is handled by the ‚Äúprotection level‚Äù, which can be set to only allow either the system or apps signed by the same key to send &lt;code&gt;Intent&lt;/code&gt;s to a given &lt;code&gt;Activity&lt;/code&gt;. These security tools are useful in many situations, but leave lots of privacy-oriented use cases uncovered.&lt;/p&gt;

&lt;p&gt;There are some situations that need more flexibility without opening things up entirely. The first simple example is provided by our app &lt;a href=&#34;https://guardianproject.info/apps/pixelknot/&#34; target=&#34;_blank&#34;&gt;Pixelknot&lt;/a&gt;: it needs to send pictures through services that will not mess up the hidden data in the images. It has a trusted list of apps it will send to, based on apps that have proven to pass the images through unchanged. When the user goes to share the image from Pixelknot to an cloud storage app, the user will be prompted to choose from a list of installed apps that match the whitelist in Pixelknot. We could have implemented a permission and asked lots of app providers to implement it, but it seems a mammoth task to get lots of large companies like Dropbox and Google to include our specific permission.&lt;/p&gt;

&lt;p&gt;There are other situations that require even tighter restrictions that are available. The first example here comes from our OpenPGP app for Android. &lt;a href=&#34;https://guardianproject.info/code/gnupg/&#34; target=&#34;_blank&#34;&gt;Gnu Privacy Guard (GPG)&lt;/a&gt; provides cryptographic services to any app that requests it. When the app sends data to GPG to be encrypted, it needs to be sure that the data is actually going to GPG and not to some malware. For very sensitive situations, the Android-provided package name and signing key might not be enough to ensure that the correct app is receiving the unencrypted data. Many Android devices are still unpatched to protect against &lt;a href=&#34;https://threatpost.com/second-android-master-key-attack-surfaces/101297&#34; target=&#34;_blank&#34;&gt;master key bugs&lt;/a&gt;, and for people using Android in China, Iran, etc. where the Play Store is not allowed, they don‚Äôt get the exploit scanning provided by Google. Telecoms around the world have proved to be &lt;a href=&#34;https://arstechnica.com/gadgets/2012/12/the-checkered-slow-history-of-android-handset-updates/&#34; target=&#34;_blank&#34;&gt;bad at updating the software&lt;/a&gt; for the devices that they sell, &lt;a href=&#34;https://arstechnica.com/security/2013/04/wireless-carriers-deceptive-and-unfair&#34; target=&#34;_blank&#34;&gt;leaving many security problems unfixed&lt;/a&gt;. Alternative Android app stores are a very popular way to get apps. So far, the ones that we have seen provide minimal security and no malware scanning. &lt;a href=&#34;http://www.telecoms.com/57581/china-crucial-to-android/&#34; target=&#34;_blank&#34;&gt;In China&lt;/a&gt;, &lt;a href=&#34;http://www.insidemobileapps.com/2011/09/02/china-chinese-smartphone-ios-android-market/&#34; target=&#34;_blank&#34;&gt;Android is very popular&lt;/a&gt;, so this represents a lot of Android users.&lt;/p&gt;

&lt;p&gt;Another potential use case revolves around a media reporting app that relies on other apps to provide images and video as part of regular reports. This could be something like a citizen journalist editing app or a human rights reporting app. The Guardian Project develops a handful of apps designed to create media in these situations: &lt;a href=&#34;https://guardianproject.info/apps/obscuracam/&#34; target=&#34;_blank&#34;&gt;ObscuraCam&lt;/a&gt;, InformaCam, and an new secure camera app in the works that we are contributing to. We want InformaCam to work as a provider of verifiable media to any app. It generates a package of data that includes a cryptographic signature so that its authenticity can be verified. That means that the apps that transport the InformaCam data do not need to be trusted in order to guarantee the integrity of the uploaded InformaCam data. Therefore it does not make sense in this case for InformaCam to grant itself permissions to access other apps‚Äô secured &lt;code&gt;Activity&lt;/code&gt;s. It would add to the maintenance load of the app without furthering the goals of the InformaCam project. Luckily there are other ways to address that need.&lt;/p&gt;

&lt;p&gt;The inverse of this situation is not true. The reporting app that gathers media and sends it to trusted destinations has higher requirements for validating the data it receives via &lt;code&gt;Intent&lt;/code&gt;s. If verifiable media is required, then this reporter app will want to only accept incoming media from InformaCam. Well-known human rights activists are often the target of custom malware designed to get information from their phones. For this example, a malware version of InformaCam could be designed to track all of the media that the user is sending to the human rights reporting app. To prevent this, the reporter app will want to only accept data from a list of trusted apps. When the user tries to feed media from the malware app to the reporting app, it would be rejected, alerting the user that something is amiss. If an reporting app wants to receive data only from InformaCam, it needs to have some checks setup to enforce that. The easiest way for the reporting app to implement those checks would be to add an Android permission to the receiving &lt;code&gt;Activity&lt;/code&gt;. But that requires the sending app, in the example above that is InformaCam, to implement the reporting app‚Äôs permission. Using permissions works for tailored interactions. InformaCam aims to bring tighter secure to all relevant interactions, so we need a different approach. While InformaCam could include some specific permissions, the aim is to have a single method that supports all the desired interactions. Having a single method here means less code to audit, less complexity, and fewer places for security bugs.&lt;/p&gt;

&lt;p&gt;We have started auditing the security of communication via &lt;code&gt;Intent&lt;/code&gt;s, while also working on various ideas to address the issues laid out so far. This will include laying out best-practices and defining gaps in the Android architecture. We plan on building the techniques that we find useful into reusable libraries to make it easy for others to also have more flexible and trusted interactions. When are the standard checks not enough? If the user has a malware version of an app that exploits master key bugs, then the signature on the app will be valid. If a check is based only on a package name, malware could use any given package name. Android enforces that only one app can be installed with a given package name, but if there are multiple apps with the same package name, Android will not prevent you from installing the malware version.&lt;/p&gt;

&lt;p&gt;&lt;div id=&#34;attachment_12120&#34; style=&#34;width: 160px&#34; class=&#34;wp-caption alignleft&#34;&gt;
  &lt;a href=&#34;http://www.pregnancyandbaby.com/the-hatch-blog/articles/935057/classic-vanilla-tofu-ice-pops-for-babies-from-ice-pop-joy&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12120&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2014/01/IcePopJoy-ClassicVanillaTofu-300x300.jpg&#34; alt=&#34;TOFU/POP: delicious vegan treat and clever software interaction!&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;size-medium wp-image-12120&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2014/01/IcePopJoy-ClassicVanillaTofu-300x300.jpg 300w, https://guardianproject.info/wp-content/uploads/2014/01/IcePopJoy-ClassicVanillaTofu-150x150.jpg 150w, https://guardianproject.info/wp-content/uploads/2014/01/IcePopJoy-ClassicVanillaTofu.jpg 450w&#34; sizes=&#34;(max-width: 150px) 100vw, 150px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;p id=&#34;caption-attachment-12120&#34; class=&#34;wp-caption-text&#34;&gt;
    TOFU/POP: delicious vegan treat and clever software interaction!
  &lt;/p&gt;
&lt;/div&gt;The strictest possible checks can be based on the hash of the whole APK, while tracking the signing key of a given APK is also often useful. These two data points are the most reliable ways to verify a given app. They can be tracked in two different ways: pinning and trust-on-first-use (TOFU/POP). Pinning means that a verified hash or signing key for the apps that need to be trusted is included in the app that must trust them. Then the trusting app can verify what it is sending or receiving&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Intent&lt;/code&gt;s from, the installed app is then compared to the pre-stored pinned value. This kind of pinning allows for checks like the &lt;code&gt;Signature&lt;/code&gt; permission level but based on a key that the app developer can select and include in the app. The built-in &lt;code&gt;Signature&lt;/code&gt; permissions are fixed on the signing key of the currently running app.&lt;/p&gt;

&lt;p&gt;TOFU/POP means Trust-On-First-Use/Persistence Of Pseudonym. In this model, popularized by SSH, the user marks a given hash or signing key as trusted the first time they use the app, without extended checks about that apps validity. That mark then describes a ‚Äúpseudonym‚Äù for that app, since there is no verification process, and that pseudonym is remembered for comparing in future interactions. One big advantage of TOFU/POP is that the user has control over which apps to trust, and that trust relationship is created at the moment the user takes an action to start using the app that needs to be trusted. That makes it much easier to manage than using Android permissions, which must be managed by the app‚Äôs developer. A disadvantage is that the initial trust is basically a guess, and that leaves open a method to get malware in there. The problem of installing good software, and avoiding malware, is outside of the scope of securing inter-app communication. Secure app installation is best handled by the process that is actually installing the software, like the Google Play Store or &lt;a href=&#34;https://f-droid.org&#34; target=&#34;_blank&#34;&gt;F-Droid&lt;/a&gt; does.&lt;/p&gt;

&lt;p&gt;To build on the InformaCam example, in order to setup a trusted data flow between InformaCam and the reporting app, custom checks must be implemented on both the sender and the receiver. For the sender, InformaCam, it should be able to send to any app, but it should then remember the app that it is configured to send to and make sure its really only sending to that app. It would then use TOFU/POP with the hash as the data point. For the receiver, the reporting app, it should only accept incoming data from apps that it trusts. The receiver then includes a pin for the signing key, or if the app is being deployed to unupdated devices the pin can be based on the hash to work around master key exploits. From there on out, the receiving app checks against the stored app hashes or signing keys. For less security-sensitive situations, the received can rely on TOFU/POP on the first time that an app sends media.&lt;/p&gt;

&lt;p&gt;There are various versions of these ideas floating around in various apps, and we have some in the works. We are working now to hammer out which of these ideas are the most useful, then we will be focusing our development efforts there. We would love to hear about any related effort or libraries that are out there. And we are also interested to hear about entirely different approaches than what has been outlined here.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Keys, signatures, certificates, verifications, etc. What are all these for?</title>
      <link>https://guardianproject.github.io/info/2013/12/12/keys-signatures-certificates-verifications-etc.-what-are-all-these-for/</link>
      <pubDate>Thu, 12 Dec 2013 13:20:09 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2013/12/12/keys-signatures-certificates-verifications-etc.-what-are-all-these-for/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2013/12/key.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2013/12/key-150x150.jpg&#34; alt=&#34;portable shared security token&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;alignright size-thumbnail wp-image-12129&#34; /&gt;&lt;/a&gt;For the past two years, we have been thinking about how to make it easier for anyone to achieve private communications. One particular focus has been on the ‚Äúsecurity tokens‚Äù that are required to make private communications systems work. This research area is called internally &lt;a href=&#34;https://dev.guardianproject.info/projects/psst/wiki/PSST&#34; title=&#34;PSST Wiki&#34; target=&#34;_blank&#34;&gt;Portable Shared Security Tokens aka PSST&lt;/a&gt;. All of the privacy tools that we are working on require ‚Äúkeys‚Äù and ‚Äúsignatures‚Äù, to use the language of cryptography, and these are the core of what ‚Äúsecurity tokens‚Äù are. One thing we learned a lot about is how to portray and discuss tools for private or anonymous communications to people who just want to communicate and are not interested in technical discussion. This is becoming a central issue among a lot of people working to make usable privacy tools.&lt;/p&gt;

&lt;p&gt;The widely established way of talking about privacy tools comes from the lingo of the underlying methods: cryptography, networking, etc. We talk about public and private keys, signing, validation, verification, key exchange, certificates, and fingerprints. In order for cryptography to work, keys need to be marked whether they are verified or not. &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2013/12/public_key_cryptography_sm.png&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2013/12/public_key_cryptography_sm-300x190.png&#34; alt=&#34;hide the guts of what is happening&#34; width=&#34;300&#34; height=&#34;190&#34; class=&#34;alignleft size-medium wp-image-12135&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2013/12/public_key_cryptography_sm-300x190.png 300w, https://guardianproject.info/wp-content/uploads/2013/12/public_key_cryptography_sm.png 500w&#34; sizes=&#34;(max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;Few computers users understand what these terms are referring to, even highly technical people who regularly use encryption do not know the meaning of all these things, nor should they. This is a low level detail that is not important to how the vast majority of users understand privacy in computers. Keys and verification are far too abstract to be generally understandable, and what other kind of key has a fingerprint? Even more so, few people can tell you the difference between validation and verification when it comes to keys, signatures and certificates. The software should not be exposing all this, but instead should be minimizing the complexity as much as possible, and providing as simple a user experience as possible.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Defining the Concepts that Define the Experience&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A key part of defining that simple user experience is defining the core concepts that the software is organized around. In our discussions, we mostly talked about the ideas of identity and trust, while some discussion of verifying identity seemed unavoidable. Talking about identity and trust is a lot more relevant in day-to-day life, i.e. knowing that the message came from the person you think it did, and trusting that it was private. It is most direct to talk about establishing a trusted connection to another person, but that‚Äôs not something that crypto can ever promise because there is still the analog gap between the person and the device. These core ideas must represent what is technically possible, so we searched for widely understood concepts that map well to the technical limitations: ‚Äúa private conversation‚Äù, ‚Äúa trusted app‚Äù, ‚Äúverifiable video‚Äù.&lt;/p&gt;

&lt;p&gt;&lt;div id=&#34;attachment_12128&#34; style=&#34;width: 160px&#34; class=&#34;wp-caption alignright&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2013/12/ecc.jpg&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12128&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2013/12/ecc-150x150.jpg&#34; alt=&#34;create metaphors based on what users know&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;size-thumbnail wp-image-12128&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2013/12/ecc-150x150.jpg 150w, https://guardianproject.info/wp-content/uploads/2013/12/ecc-300x300.jpg 300w, https://guardianproject.info/wp-content/uploads/2013/12/ecc.jpg 350w&#34; sizes=&#34;(max-width: 150px) 100vw, 150px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;p id=&#34;caption-attachment-12128&#34; class=&#34;wp-caption-text&#34;&gt;
    create metaphors based on what users know
  &lt;/p&gt;
&lt;/div&gt;Diving in deeper, we concluded that the balance point between technical accuracy and widely understandable lingo was to talk about trusting the device, not the person. The technology can provide trusted connections between devices, and it is pretty close to how people experience digital communications. There is the laptop, the mobile phone, the net cafe, the friend‚Äôs computer, computer at work, etc. etc. When I look at my phone to see a message from a friend, it is easy to picture that friend typing that message out on that device, though it does take some conscious effort. The hard part here is that as we communicate more and more with our devices, there is less and less separation in our minds about whether we were talking in person, via voice, or by sending text. This is a point to focus on when thinking about designing the experience of private, secure communications software.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Let the Software Handle It!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;There is a forming consensus in the world of usable security to focus on figuring out how to automate as much as possible then figure out how best tailor the experience of the essential parts that cannot be automated. The hard part will remain explaining the limitations of a given privacy tool.&lt;/p&gt;

&lt;p&gt;At Guardian Project, we work a lot on incremental progress, so many of our projects are focused on specific, narrow improvements. With &lt;a href=&#34;https://guardianproject.info/apps/chatsecure/&#34; target=&#34;_blank&#34;&gt;ChatSecure&lt;/a&gt; and &lt;a href=&#34;https://guardianproject.info/apps/keysync/&#34; target=&#34;_blank&#34;&gt;Keysync&lt;/a&gt; , we were able to automate one small part of the whole process, cryptography identity portability, which provides the foundation to provide private communications and verifiable media. Allowing users to sync their trust profiles between desktop and mobile makes it much more likely that users will have fully verified OTR conversations when chatting on their devices and laptops.&lt;/p&gt;

&lt;p&gt;With &lt;a href=&#34;https://guardianproject.info/code/gnupg/&#34; target=&#34;_blank&#34;&gt;Gnu Privacy Guard for Android (GPGA)&lt;/a&gt;, we have made it easy to import keys via QRCode as well as &lt;code&gt;openpgp4fpr:&lt;/code&gt; URLs (a standard defined in conjuction with the &lt;a href=&#34;http://web.monkeysphere.info/&#34; title=&#34;Monkeysphere Home Page&#34; target=&#34;_blank&#34;&gt;Monkeysphere&lt;/a&gt; project. We are also working on a common method of using NFC for OpenPGP key signing in conjuction with &lt;a href=&#34;http://sufficientlysecure.org/index.php/openpgp-keychain/&#34; title=&#34;OpenPGP Keychain home page&#34; target=&#34;_blank&#34;&gt;OpenPGP Keychain&lt;/a&gt;. Even little things like optimizing support for standard file extensions can go a long way to make things easier, so GPGA automatically sets itself up to receive files with the &lt;a href=&#34;https://tools.ietf.org/html/rfc2015&#34; target=&#34;_blank&#34;&gt;standard OpenPGP MIME types&lt;/a&gt; (&lt;code&gt;application/pgp-keys&lt;/code&gt;, &lt;code&gt;application/pgp-encrypted&lt;/code&gt;, &lt;code&gt;application/pgp-signature&lt;/code&gt;) as well as the corresponding file extensions (&lt;code&gt;.pkr&lt;/code&gt;, &lt;code&gt;.skr&lt;/code&gt;, &lt;code&gt;.key&lt;/code&gt;, &lt;code&gt;.sig&lt;/code&gt;, &lt;code&gt;.asc&lt;/code&gt;, etc.). That makes it so a user can just click on one of these files, and GPGA will walk them through the whole process, doing as much as possible automatically.&lt;/p&gt;

&lt;p&gt;Another interesting idea that is a big step in this direction is ‚Äúsecure introductions‚Äù. The idea is to automatically share trusted identity information when securely communicating with multiple people. For example, whenever you send a signed, encrypted email to multiple people, the email program should include the key fingerprints of each recipient in that email. Then the email program of the people receiving that email should automatically mark those keys as verified if the sender‚Äôs key is trusted and the signature is valid. There is not a meaningful amount of detail leaked in this interaction, since the existence of all the people‚Äôs keys and email address is already present in a secure email. The tricky part is figuring out how to make it harder for someone to use this maliciously to spread false identity information while keeping things as automatic as possible. This is very much a long term research idea: there are no widespread implementations of it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting keys into your keyring with Gnu Privacy Guard for Android</title>
      <link>https://guardianproject.github.io/info/2013/12/06/getting-keys-into-your-keyring-with-gnu-privacy-guard-for-android/</link>
      <pubDate>Fri, 06 Dec 2013 15:11:53 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2013/12/06/getting-keys-into-your-keyring-with-gnu-privacy-guard-for-android/</guid>
      <description>&lt;p&gt;Now that you can have a full &lt;a href=&#34;https://www.gnupg.org&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;GnuPG&lt;/em&gt;&lt;/a&gt; on your Android device with &lt;a href=&#34;https://play.google.com/store/apps/details?id=info.guardianproject.gpg&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Gnu Privacy Guard&lt;/em&gt;&lt;/a&gt; for Android, the next step is getting keys you need onto your device and included in &lt;em&gt;Gnu Privacy Guard&lt;/em&gt;. We have tried to make it as easy as possible without compromising privacy, and have implemented a few approaches, while working on others. There are a few ways to get this done right now.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Gnu Privacy Guard&lt;/em&gt; registered itself with Android as a handler of all the standard &lt;a href=&#34;https://www.rfc-editor.org/rfc/rfc3156.txt&#34; title=&#34;RFC3156: MIME Security with OpenPGP&#34; target=&#34;_blank&#34;&gt;OpenPGP MIME types&lt;/a&gt; (&lt;code&gt;application/pgp-keys&lt;/code&gt;, &lt;code&gt;application/pgp-encrypted&lt;/code&gt;, &lt;code&gt;application/pgp-signature&lt;/code&gt;), as well as all of the OpenPGP and GnuPG file extensions (&lt;code&gt;.pkr&lt;/code&gt; &lt;code&gt;.skr&lt;/code&gt; &lt;code&gt;.key&lt;/code&gt; &lt;code&gt;.sig&lt;/code&gt; &lt;code&gt;.asc&lt;/code&gt; &lt;code&gt;.gpg&lt;/code&gt; &lt;code&gt;.bin&lt;/code&gt;). This means that users just have to share a file to &lt;em&gt;Gnu Privacy Guard&lt;/em&gt; using any of the standard Android methods, these files can be launched from an email attachment, opened from the SD card using a file browser, clicked in the Downloads view, etc.&lt;/p&gt;

&lt;p&gt;So if you want to quickly send your whole public keyring from your laptop to your mobile device, you can just grab the database file directly from &lt;em&gt;GnuPG&lt;/em&gt; and copy it to your SD card. Here is how:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;plug your device into your laptop via USB so you can copy files to the SD card&lt;/li&gt;
&lt;li&gt;find your &lt;em&gt;GnuPG&lt;/em&gt; home folder (on GNU/Linux and Mac OS X, it will be in &lt;code&gt;~/.gnupg/pubring.gpg&lt;/code&gt;, on Windows it is &lt;code&gt;%APPDATA%\gnupg&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;In your &lt;em&gt;GnuPG&lt;/em&gt; home folder, copy &lt;strong&gt;pubring.gpg&lt;/strong&gt; to your device‚Äôs SD card&lt;/li&gt;
&lt;li&gt;unmount and unplug your device&lt;/li&gt;
&lt;li&gt;on your device, open your favorite file manager app (&lt;a href=&#34;https://play.google.com/store/apps/details?id=org.openintents.filemanager&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;OI File Manager&lt;/em&gt;&lt;/a&gt;, &lt;em&gt;Astro&lt;/em&gt;, etc)&lt;/li&gt;
&lt;li&gt;go to the SD card&lt;/li&gt;
&lt;li&gt;long-click on &lt;strong&gt;pubring.gpg&lt;/strong&gt; and share it to &lt;em&gt;Gnu Privacy Guard&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;click OK on the Import Keys dialog&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After that, &lt;em&gt;Gnu Privacy Guard&lt;/em&gt; will do the rest. Give is some time to sync to the Contacts database, then you‚Äôll see all of your keys from your desktop are now in your People app and are listed in &lt;em&gt;Gnu Privacy Guard&lt;/em&gt; itself. You can now encrypt files to any of those keys, or verify files signed by any of those keys. Here are a couple screenshots to illustrate key points in the process, using &lt;em&gt;OI File Manager&lt;/em&gt;:&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;
  &lt;div id=&#34;attachment_12155&#34; style=&#34;width: 209px&#34; class=&#34;wp-caption alignleft&#34;&gt;
    &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-0.png&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12155&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-0-199x300.png&#34; alt=&#34;send your public keyring file&#34; width=&#34;199&#34; height=&#34;300&#34; class=&#34;size-medium wp-image-12155&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-0-199x300.png 199w, https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-0.png 319w&#34; sizes=&#34;(max-width: 199px) 100vw, 199px&#34; /&gt;&lt;/a&gt;
    
    &lt;p id=&#34;caption-attachment-12155&#34; class=&#34;wp-caption-text&#34;&gt;
      1. send your public keyring file
    &lt;/p&gt;
  &lt;/div&gt;
&lt;/p&gt;

&lt;div id=&#34;attachment_12156&#34; style=&#34;width: 209px&#34; class=&#34;wp-caption alignright&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-1.png&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12156&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-1-199x300.png&#34; alt=&#34;choose Gnu Privacy Guard to send the file to&#34; width=&#34;199&#34; height=&#34;300&#34; class=&#34;size-medium wp-image-12156&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-1-199x300.png 199w, https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-1.png 319w&#34; sizes=&#34;(max-width: 199px) 100vw, 199px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12156&#34; class=&#34;wp-caption-text&#34;&gt;
    2. choose &lt;em&gt;Gnu Privacy Guard&lt;/em&gt; to send the file to
  &lt;/p&gt;
&lt;/div&gt;

&lt;div id=&#34;attachment_12157&#34; style=&#34;width: 209px&#34; class=&#34;wp-caption alignleft&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-2.png&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12157&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-2-199x300.png&#34; alt=&#34;click OK to import the key file&#34; width=&#34;199&#34; height=&#34;300&#34; class=&#34;size-medium wp-image-12157&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-2-199x300.png 199w, https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-2.png 319w&#34; sizes=&#34;(max-width: 199px) 100vw, 199px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12157&#34; class=&#34;wp-caption-text&#34;&gt;
    3. click OK to import the key file
  &lt;/p&gt;
&lt;/div&gt;

&lt;div id=&#34;attachment_12158&#34; style=&#34;width: 209px&#34; class=&#34;wp-caption alignright&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-3.png&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12158&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-3-199x300.png&#34; alt=&#34;now you can see the imported keys in Gnu Privacy Guard&#34; width=&#34;199&#34; height=&#34;300&#34; class=&#34;size-medium wp-image-12158&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-3-199x300.png 199w, https://guardianproject.info/wp-content/uploads/2013/12/GPGA-import-key-file-3.png 319w&#34; sizes=&#34;(max-width: 199px) 100vw, 199px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12158&#34; class=&#34;wp-caption-text&#34;&gt;
    4. now you can see the imported keys in &lt;em&gt;Gnu Privacy Guard&lt;/em&gt;
  &lt;/p&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;There are many ways to get the keyring files like &lt;strong&gt;pubring.gpg&lt;/strong&gt; to your device: you can also share the keyring files via email, chat, or even services like &lt;em&gt;Dropbox&lt;/em&gt; or &lt;em&gt;Google Drive&lt;/em&gt;. Then once the files are on your device, you can import them using the same procedure as above. But keep in mind that you are sending your whole collection of secure contacts to that service, which will have full access to read it. If you have any worries about leaking your keyring to anyone, then a good method is to copy it directly to the SD card.&lt;/p&gt;

&lt;div id=&#34;attachment_12192&#34; style=&#34;width: 209px&#34; class=&#34;wp-caption aligncenter&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-search-keyserver.png&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12192&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-search-keyserver-199x300.png&#34; alt=&#34;search the keyserver for the author&#39;s key (I lost the key from 1998, so don&#39;t use that one...)&#34; width=&#34;199&#34; height=&#34;300&#34; class=&#34;size-medium wp-image-12192&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2013/12/GPGA-search-keyserver-199x300.png 199w, https://guardianproject.info/wp-content/uploads/2013/12/GPGA-search-keyserver.png 319w&#34; sizes=&#34;(max-width: 199px) 100vw, 199px&#34; /&gt;&lt;/a&gt;
  
  &lt;p id=&#34;caption-attachment-12192&#34; class=&#34;wp-caption-text&#34;&gt;
    search the keyserver for the author‚Äôs key (the key from 1998 is lost, don‚Äôt use that one‚Ä¶)
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;You can also search and download keys via the public pool of OpenPGP keyservers. If you already know someone‚Äôs keyid or fingerprint, you can search using that. Otherwise, you can search based on name or email address. But be careful! Downloading a key from a keyserver does not give you a key you can trust. Anyone can upload a key to the keyservers, and they can make that key have any name or email address. Downloading from the keyservers is a convenient way to download a key, but you must verify the key‚Äôs fingerprint with the person you are trying to find.&lt;/p&gt;

&lt;p&gt;&lt;div id=&#34;attachment_12184&#34; style=&#34;width: 160px&#34; class=&#34;wp-caption alignleft&#34;&gt;
  &lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2013/12/0x9F0FE587374BBE81-qr.png&#34;&gt;&lt;img aria-describedby=&#34;caption-attachment-12184&#34; src=&#34;https://guardianproject.info/wp-content/uploads/2013/12/0x9F0FE587374BBE81-qr-150x150.png&#34; alt=&#34;scan this QR Code to get the author&#39;s OpenPGP key&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;size-thumbnail wp-image-12184&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2013/12/0x9F0FE587374BBE81-qr-150x150.png 150w, https://guardianproject.info/wp-content/uploads/2013/12/0x9F0FE587374BBE81-qr-300x300.png 300w, https://guardianproject.info/wp-content/uploads/2013/12/0x9F0FE587374BBE81-qr.png 330w&#34; sizes=&#34;(max-width: 150px) 100vw, 150px&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;p id=&#34;caption-attachment-12184&#34; class=&#34;wp-caption-text&#34;&gt;
    scan this QR Code to get the author‚Äôs OpenPGP key
  &lt;/p&gt;
&lt;/div&gt;In conjunction with the&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://web.monkeysphere.info/&#34; target=&#34;_blank&#34;&gt;Monkeysphere&lt;/a&gt; project, we developed a standard URI scheme for sending OpenPGP key fingerprints. For example, you can find my key ID here: &lt;a href=&#34;openpgp4fpr:9F0FE587374BBE81&#34;&gt;&lt;code&gt;openpgp4fpr:9F0FE587374BBE81&lt;/code&gt;&lt;/a&gt;. This provides a clickable way to get an OpenPGP key. On an Android device with &lt;em&gt;Gnu Privacy Guard&lt;/em&gt; installed, you can click on this link to download my key from the keyservers. This URI scheme also works well in QR Codes. Scan this QR Code on your device with an app like &lt;a href=&#34;https://play.google.com/store/apps/details?id=com.google.zxing.client.android&#34; title=&#34;Barcode Scanner in the Google Play Store&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Barcode Scanner&lt;/em&gt;&lt;/a&gt;, and click &lt;strong&gt;Open Browser&lt;/strong&gt;, and Gnu Privacy Guard will download my key to your device.&lt;/p&gt;

&lt;p&gt;There are other ideas out there that we also want to support. For example, &lt;a href=&#34;http://sufficientlysecure.org/index.php/openpgp-keychain/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;OpenPGP Keychain&lt;/em&gt;&lt;/a&gt; includes a way to transmit the whole public key via &lt;a href=&#34;https://en.wikipedia.org/wiki/Near_field_communication&#34; title=&#34;Near Field Communication&#34; target=&#34;_blank&#34;&gt;NFC&lt;/a&gt;. This allows people can swap keys directly from phone to phone without having internet access at all. But NFC is quite slow to transmit data so the devices need to be held together for a while until the whole key is received. NFC could be used to rapidly transmit an &lt;code&gt;openpgp4fpr:&lt;/code&gt; URI, and then the whole public key would be fetched from a keyserver, but that then requires internet access and also leaks a bit of metadata to the internet. A better technique would be to transmit the entire public key over Bluetooth, using NFC to setup the Bluetooth session. We‚Äôre also looking at ways to do this via WiFi and &lt;a href=&#34;https://en.wikipedia.org/wiki/Bonjour_(software)&#34; target=&#34;_blank&#34;&gt;Bonjour (mDNS)&lt;/a&gt; local service advertisements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting up your own app store with F-Droid</title>
      <link>https://guardianproject.github.io/info/2013/11/05/setting-up-your-own-app-store-with-f-droid/</link>
      <pubDate>Tue, 05 Nov 2013 11:55:43 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2013/11/05/setting-up-your-own-app-store-with-f-droid/</guid>
      <description>

&lt;p&gt;(_This blog post as now been cooked into an &lt;a href=&#34;https://f-droid.org/wiki/page/Setup_an_FDroid_App_Repo&#34; target=&#34;_blank&#34;&gt;updated HOWTO&lt;/a&gt;_)&lt;/p&gt;

&lt;p&gt;The Google Play Store for Android is not available in all parts of the world, US law restricts its use in certain countries like Iran, and many countries block access to the Play Store, like China. Also, the Google Play Store tracks all user actions, reporting back to Google what apps have been installed and also run on the phone. Because of the NSA leaks, we‚Äôre seeing that governments are &lt;a href=&#34;http://www.theguardian.com/technology/2013/oct/30/google-reports-nsa-secretly-intercepts-data-links&#34; target=&#34;_blank&#34;&gt;actively tapping&lt;/a&gt; into &lt;a href=&#34;http://www.nytimes.com/2013/10/31/technology/nsa-is-mining-google-and-yahoo-abroad.html&#34; target=&#34;_blank&#34;&gt;the raw data streams&lt;/a&gt; of Google, Yahoo, and others. So that means the information the Google Play Store sends back to Google is also intercepted by the NSA (and probably other country‚Äôs agencies), and that information is shared with other governments. In other words, your activity on the Google Play Store is far from private. Lastly, the Google Play Store is not free software, unlike the core of Android itself. It is proprietary software that Google entirely controls.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2013/11/your-own-app-store.png&#34; alt=&#34;your-own-app-store&#34; width=&#34;300&#34; height=&#34;203&#34; class=&#34;alignright size-full wp-image-11896&#34; /&gt; &lt;a href=&#34;https://f-droid.org&#34; title=&#34;F-Droid Home Page&#34; target=&#34;_blank&#34;&gt;F-Droid&lt;/a&gt; is a wonderful, free app store for Android. It is modeled after the &lt;a href=&#34;http://www.debian.org&#34; title=&#34;Debian home page&#34; target=&#34;_blank&#34;&gt;Debian GNU/Linux&lt;/a&gt; distro. It has its own package repositories (repos) and build servers for all the apps that are part of the official OS. Like Debian and Ubuntu, you can also setup your own repos for anyone to use. Any free software can be added to the official F-Droid repos, where they are built and signed by the F-Droid server. This can be annoying because it means that your apps in F-Droid are signed by a different key than your apps in the Google Play Store. If you host your own F-Droid repo, then people can use F-Droid to install your own builds signed by your own signing key.&lt;/p&gt;

&lt;p&gt;This is a quick HOWTO for how to setup such a repository on a Debian or Ubuntu box. It is somewhat technical, you will use the terminal, but you don‚Äôt need to be a terminal expert to follow along. First you need a the &lt;code&gt;fdroidserver&lt;/code&gt; tools and a webserver. For the webserver, here we use &lt;em&gt;nginx&lt;/em&gt; for the webserver since its lightweight, but any will do if you already have one running. The fdroidserver tools are not yet in the official Debian/Ubuntu/etc repos, so you have to add our PPA (Personal Package Archive) to get it (fingerprint: &lt;tt&gt;F50E ADDD 2234 F563&lt;/tt&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo add-apt-repository ppa:guardianproject/ppa
sudo apt-get update
sudo apt-get install fdroidserver nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the case of this HOWTO, we‚Äôre going to setup a ‚Äú&lt;a href=&#34;https://f-droid.org/manual/fdroid.html#Simple-Binary-Repository&#34; target=&#34;_blank&#34;&gt;Simple Binary Repository&lt;/a&gt;‚Äù to host our official APKs. The repo will be set up in the recommended &lt;code&gt;fdroid/&lt;/code&gt; subdirectory. This gives the &lt;code&gt;fdroid&lt;/code&gt; tool its own directory to work in, and makes the repo URL clearly marked as an FDroid repo. Let‚Äôs give our normal user control over this subdirectory in the web root so that we don‚Äôt need to run the F-Droid tools as root (with &lt;em&gt;nginx&lt;/em&gt;, the webroot is &lt;code&gt;/usr/share/nginx/www&lt;/code&gt;, it is different for other webservers):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mkdir /usr/share/nginx/www/fdroid
sudo chown -R $USER /usr/share/nginx/www/fdroid
cd /usr/share/nginx/www/fdroid
fdroid init
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now put your APK files into &lt;code&gt;/usr/share/nginx/www/fdroid/repo&lt;/code&gt; and you are ready to run the commands to build the repo (if &lt;code&gt;fdroid init&lt;/code&gt; cannot find your Android SDK in &lt;code&gt;/opt/android-sdk&lt;/code&gt; or &lt;code&gt;$ANDROID_HOME&lt;/code&gt;, it will prompt you for the path):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd /usr/share/nginx/www/fdroid
cp /path/to/*.apk /usr/share/nginx/www/fdroid/repo/
fdroid update -c
fdroid update
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://f-droid.org&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2013/11/fdroidheader3-300x75.png&#34; alt=&#34;fdroidheader3&#34; width=&#34;300&#34; height=&#34;75&#34; class=&#34;alignleft size-medium wp-image-11906&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2013/11/fdroidheader3-300x75.png 300w, https://guardianproject.info/wp-content/uploads/2013/11/fdroidheader3.png 720w&#34; sizes=&#34;(max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;Voila! Now you have a working F-Droid Repo! Add it to an F-Droid client on your Android device to test it out. That is done in the &lt;strong&gt;Manage Repos&lt;/strong&gt; screen available from the menu. Your repo URL will be the hostname or IP address of your machine with &lt;code&gt;/fdroid/repo/&lt;/code&gt; added to the end of it, i.e. &lt;code&gt;https://mysecureserver.com/fdroid/repo/&lt;/code&gt; or &lt;code&gt;http://192.168.2.53/fdroid/repo/&lt;/code&gt;. You can temporarily uncheck the official repos to easily see what F-Droid found in your new repo.&lt;/p&gt;

&lt;h2 id=&#34;customization&#34;&gt;Customization&lt;/h2&gt;

&lt;p&gt;You can also customize your repo by editing the config file. Be sure to use a programming text editor, like &lt;code&gt;editor /usr/share/nginx/www/fdroid/config.py&lt;/code&gt;. In the config file, you can set the name of the repo, the description, the icon, paths to specific versions of the build tools, links to a related wiki, and whether to keep stats. Here‚Äôs the basic repo description block:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;repo_url = &amp;quot;https://guardianproject.info/fdroid/repo&amp;quot;
repo_name = &amp;quot;My Local Repo&amp;quot;
repo_icon = &amp;quot;GP_Logo_hires.png&amp;quot;
repo_description = &amp;quot;&amp;quot;&amp;quot;
This is a local test repository of Hans-Christoph Steiner &amp;lt;&amp;amp;#x68;a&amp;amp;#x6e;s@&amp;amp;#x67;ua&amp;amp;#x72;d&amp;amp;#x69;&amp;amp;#x61;n&amp;amp;#x70;ro&amp;amp;#x6a;e&amp;amp;#x63;&amp;amp;#x74;.&amp;amp;#x69;nf&amp;amp;#x6f;&amp;gt;.  It is a repository of Guardian Project apps.
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To put your icon into your repo, choose a PNG image to put in your repo. The PNG goes in &lt;code&gt;/usr/share/nginx/www/fdroid/&lt;/code&gt;, the file can be named whatever you want (by default its &lt;code&gt;fdroid-icon.png&lt;/code&gt;). If you change the name from the default, be sure to update &lt;code&gt;repo_icon&lt;/code&gt; and &lt;code&gt;archive_icon&lt;/code&gt; in &lt;code&gt;/usr/share/nginx/www/fdroid/config.py&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;more-security&#34;&gt;More Security&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2010/02/apg.png&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2010/02/apg-150x150.png&#34; alt=&#34;apg&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;alignright size-thumbnail wp-image-1029&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2010/02/apg-150x150.png 150w, https://guardianproject.info/wp-content/uploads/2010/02/apg.png 256w&#34; sizes=&#34;(max-width: 150px) 100vw, 150px&#34; /&gt;&lt;/a&gt;Now that you have a working repo, its time to improve the security. Generating a repo in place is very easy, that is why this HOWTO started there, but it is not as secure as it should be if your repo is going to be your main distribution point. When generating the repo in place, make sure that &lt;code&gt;config.py&lt;/code&gt; is not accessible via the web, since it contains passwords. If the file permissions are correct (e.g. &lt;code&gt;chmod 0600 config.py&lt;/code&gt;), then &lt;code&gt;config.py&lt;/code&gt; will not be readable by the webserver. But the signing keys will still be that public server. To improve this situation, generate the repo on a non-public machine like your laptop, keeping &lt;code&gt;config.py&lt;/code&gt; and the keystore only on that machine, then use &lt;code&gt;fdroid server update&lt;/code&gt; to publish the changes to your repo on a separate server. You just need to set &lt;code&gt;serverwebroot&lt;/code&gt; in &lt;code&gt;config.py&lt;/code&gt; properly, then &lt;code&gt;fdroid server update&lt;/code&gt; will do the publishing via rsync over ssh. So both computers will have to have ssh and rsync installed and setup.&lt;/p&gt;

&lt;p&gt;You can also use your own existing signing key rather than the one generated by &lt;code&gt;fdroid init&lt;/code&gt;, just edit &lt;code&gt;repo_keyalias&lt;/code&gt;, &lt;code&gt;keystore&lt;/code&gt;, &lt;code&gt;keystorepass&lt;/code&gt;, &lt;code&gt;keypass&lt;/code&gt;, and &lt;code&gt;keydname&lt;/code&gt; in &lt;code&gt;/usr/share/nginx/www/fdroid/config.py&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Since we like Tor and its Hidden Services for providing privacy, we also want to setup an F-Droid repository that is accessible over a Tor Hidden Service aka onion address. This will be covered in a future HOWTO.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Issues when distributing software</title>
      <link>https://guardianproject.github.io/info/2013/10/31/issues-when-distributing-software/</link>
      <pubDate>Thu, 31 Oct 2013 15:51:19 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2013/10/31/issues-when-distributing-software/</guid>
      <description>&lt;p&gt;There is currently a &lt;a href=&#34;http://lists.debian.org/debian-security/2013/10/msg00027.html&#34; target=&#34;_blank&#34;&gt;discussion underway on the Debian-security list&lt;/a&gt; about adding TLS and Tor functionality to the official repositories (repos) of Debian packages that is highlighting how we need to update how we think about the risks when distributing software. Mostly, we are used to thinking about making sure that the software that the user is installing is the same exact software that has been posted for distribution. This is generally handled by signing the software package, then verifying that signature on the user‚Äôs machine. This is how it works on Mac OS X, Windows, Debian, etc. etc.&lt;/p&gt;

&lt;p&gt;But the authenticity of a software package is not the only issue that needs to be addressed, especially these days where many companies and governments around the world are trying to track everything that anyone is doing on the internet. In order to understand why Tor and TLS would be useful here, it good to break down the various concerns (or threats if you prefer):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;package authenticity &lt;em&gt;(software can be modified while being downloaded)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;package availability &lt;em&gt;(software security updates can be individually blocked)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;repo availability &lt;em&gt;(internet services can be blocked by governments and companies)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;who‚Äôs downloading what package &lt;em&gt;(currently visible to anyone who can see the network traffic, including open wifi, etc.)&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Most people distributing software are used to thinking about #1 verifying packages when thinking about the security of software distribution. #2, #3, and #4 are also important, and currently not well addressed. This is where TLS and Tor come in. Both can help prevent Man-In-The-Middle manipulations as well as reduce the amount of information that is leaked to the network. Tor can also help with #3. Since Tor is difficult to block, it is often uses to circumvent censorship. In this case a software repo could be blocked entirely, and Tor could help with gaining access to it. The Update Framework has &lt;a href=&#34;https://github.com/theupdateframework/tuf/blob/develop/README.md&#34; title=&#34;TUF: The Update Framework -  Security&#34; target=&#34;_blank&#34;&gt;a good overview of the possible attacks&lt;/a&gt; against software repos.&lt;/p&gt;

&lt;p&gt;So having software repos available with both TLS and Tor available as options is a very good idea. As far as I have seen, there are not any Debian repos available via a Tor Hidden Service. There are a number of official mirrors that already support TLS/HTTPS. You can find them using &lt;a href=&#34;https://gist.github.com/eighthave/7285154&#34; title=&#34;the script in a gist paste&#34; target=&#34;_blank&#34;&gt;this script:&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python

import urllib2
import re
import ssl
import sys

# # find generic mirrors
mirrors = urllib2.urlopen(&#39;http://www.debian.org/mirror/list&#39;)
https = []
for line in mirrors.readlines():
    m = re.match(&#39;.*&amp;lt;td valign=&amp;quot;top&amp;quot;&amp;gt;&amp;lt;a rel=&amp;quot;nofollow&amp;quot; href=&amp;quot;http(.*)&amp;quot;&amp;gt;.*&#39;, line)
    if m:
        url = &#39;https&#39; + m.group(1)
        print &#39;trying: &#39;,
        print url,
        print &#39;...&#39;,
        sys.stdout.flush()
        try:
            response=urllib2.urlopen(url, timeout=1)
            https.append(url)
            print &#39;success!&#39;
        except urllib2.URLError as err:
            print &#39;fail!&#39;
        except ssl.SSLError as err:
            print &#39;bad SSL!&#39;

# print &#39;HTTPS apt repos:&#39;
#for url in https:
#    print url


# # find security mirrors
mirrors = urllib2.urlopen(&#39;http://www.debian.org/mirror/list-full&#39;)
securitys = []
for line in mirrors.readlines():
    m = re.match(&#39;.*&amp;lt;/tt&amp;gt;&amp;lt;br&amp;gt;Security updates over HTTP: &amp;lt;tt&amp;gt;&amp;lt;a rel=&amp;quot;nofollow&amp;quot; href=&amp;quot;http(.*)&amp;quot;&amp;gt;.*/debian-security/&amp;lt;/a&amp;gt;.*&#39;, line)
    if m:
        url = &#39;https&#39; + m.group(1)
        print &#39;trying: &#39;,
        print url,
        print &#39;...&#39;,
        sys.stdout.flush()
        try:
            response=urllib2.urlopen(url, timeout=1)
            securitys.append(url)
            print &#39;success!&#39;
        except urllib2.URLError as err:
            print &#39;fail!&#39;
        except ssl.SSLError as err:
            print &#39;bad SSL!&#39;

# print &#39;HTTPS security repos:&#39;
# for url in securitys:
#     print url


# now find the backports mirrors
mirrors = urllib2.urlopen(&#39;http://backports-master.debian.org/Mirrors/&#39;)
backports = []
for line in mirrors.readlines():
#&amp;lt;td&amp;gt;&amp;lt;a href=&amp;quot;http://be.mirror.eurid.eu/debian-backports/&amp;quot;&amp;gt;/debian-backports/&amp;lt;/a&amp;gt;
    m = re.match(&#39;.*&amp;lt;td&amp;gt;&amp;lt;a href=&amp;quot;http(.*)&amp;quot;&amp;gt;.*/debian-backports/&amp;lt;/a&amp;gt;.*&#39;, line)
    if m:
        url = &#39;https&#39; + m.group(1)
        print &#39;trying: &#39;,
        print url,
        print &#39;...&#39;,
        sys.stdout.flush()
        try:
            response=urllib2.urlopen(url, timeout=1)
            backports.append(url)
            print &#39;success!&#39;
        except urllib2.URLError as err:
            print &#39;fail!&#39;
        except ssl.SSLError as err:
            print &#39;bad SSL!&#39;

#print &#39;HTTPS backports repos:&#39;
#for url in backports:
#    print url


# now find the CD image mirrors
mirrors = urllib2.urlopen(&#39;http://www.debian.org/CD/http-ftp/&#39;)
cds = []
for line in mirrors.readlines():
# &amp;lt;a rel=&amp;quot;nofollow&amp;quot; href=&amp;quot;http://mirror.easyspeedy.com/debian-cd/&amp;quot;&amp;gt;HTTP&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;
    m = re.match(&#39;.*&amp;lt;a rel=&amp;quot;nofollow&amp;quot; href=&amp;quot;http(:.*)&amp;quot;&amp;gt;HTTP&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;.*&#39;, line)
    if m:
        url = &#39;https&#39; + m.group(1)
        print &#39;trying: &#39;,
        print url,
        print &#39;...&#39;,
        sys.stdout.flush()
        try:
            response=urllib2.urlopen(url, timeout=1)
            cds.append(url)
            print &#39;success!&#39;
        except urllib2.URLError as err:
            print &#39;fail!&#39;
        except ssl.SSLError as err:
            print &#39;bad SSL!&#39;

print &#39;HTTPS CD image repos:&#39;
for url in cds:
    print url


# now write everything to a file
f = open(&#39;/tmp/https-debian-archives.txt&#39;, &#39;w&#39;)

f.write(&#39;HTTPS apt repos\n&#39;)
f.write(&#39;---------------\n&#39;)
for url in https:
    f.write(url + &#39;\n&#39;)

f.write(&#39;\n\nHTTPS security repos\n&#39;)
f.write(&#39;---------------\n&#39;)
for url in securitys:
    f.write(url + &#39;\n&#39;)

f.write(&#39;\n\nHTTPS backports repos\n&#39;)
f.write(&#39;--------------------\n&#39;)
for url in backports:
    f.write(url + &#39;\n&#39;)

f.write(&#39;\n\nHTTPS CD image repos\n&#39;)
f.write(&#39;--------------------\n&#39;)
for url in cds:
    f.write(url + &#39;\n&#39;)


f.close()
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>User scenarios to guide our crypto development</title>
      <link>https://guardianproject.github.io/info/2012/04/14/user-scenarios-to-guide-our-crypto-development/</link>
      <pubDate>Sat, 14 Apr 2012 20:16:03 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2012/04/14/user-scenarios-to-guide-our-crypto-development/</guid>
      <description>&lt;p&gt;At Guardian Project, we find user-centered development to be essential to producing useful software that addresses real world needs. To drive this, we work with user stories and scenarios as part of the process of developing software. One particular development focus is the &lt;a href=&#34;https://guardianproject.info/wiki/PSST&#34; title=&#34;Portable Shared Security Token&#34; target=&#34;_blank&#34;&gt;Portable Shared Security Token (PSST)&lt;/a&gt; project, which aims to make it easy to use encryption across both mobile and desktop computers, as well as keep the stores of cryptographic identities (i.e. trusted keys, certificates, etc) in sync between devices.&lt;/p&gt;

&lt;p&gt;This post outlines some initial user scenarios that PSST aims to address. We believe them to be common enough so that our solutions will be readily applicable to real world people now. They are a small subset of all of the types of users that we feel can ultimately benefit from the PSST core research, so these user stories provide a starting place for honing the tools for the needs of actual working organizations. These stories also discuss how the software could be used in these situations. The software as described mostly exists, but not all details are currently implemented or even fully vetted as secure practices.&lt;/p&gt;

&lt;p&gt;We are very eager for feedback, comments, and criticism on any aspect of these scenarios, from whether they are plausible to whether the user interactions described are built upon realistic expectations of actual members of organizations like the ones described here.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Small Cabal&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2012/04/activists-meeting.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2012/04/activists-meeting.jpg&#34; alt=&#34;&#34; width=&#34;300&#34; height=&#34;224&#34; class=&#34;alignright size-full wp-image-1799&#34; /&gt;&lt;/a&gt;There is a small group of people that needs to communicate as securely and anonymously as possible. They all meet up in person. They generate keys, and individually sign each person‚Äôs key and get that person‚Äôs signature on their own key. These are local-only unpublishable signatures. No one uploads their keys to any other server or device. They each generate a revocation certificate and hook it up to their panic button app. Once the panic button is hit, the phone broadcasts the revocation certificate to the pre-determined list of people.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Diffuse Activist Organization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;An activist organization has members spread out all over their country, with concentrations in certain areas, and a handful abroad. They are working in a country that aggressively tracks communications, but encryption is not banned nor aggressively tracked. Since there are many members and they are widely spread, very few of the members have met the whole membership. Many members often meet up in person at various places around the country, and some people also travel to regional and national meet-ups. The central forum for the whole group is on the internet, and there are many big group discussions and announcements that happen on internet forums.&lt;/p&gt;

&lt;p&gt;Each member has a cryptographic key that represents their online identity, which they post to the public keyservers. They generate and store a revocation certificate to upload to the keyservers in case of a compromised key or computer. They do not post any signatures to the key servers so that the social graph information remains private. Whenever they meet another person that they trust, they sign each others‚Äô keys and swap all signature data using direct peer-to-peer communication.&lt;/p&gt;

&lt;p&gt;When interacting with members who they only know on the internet, they check whether they have a cryptographic trust path to each others‚Äô keys, and if not, they establish the first step of trust via OTR by doing key verification via question/answer, shared secret or manual fingerprint validation over a trusted channel, like the phone. When they hit there panic button the post the revocation certificate to the keyserver. Each member‚Äôs computer/phone automatically checks the public keyservers for revocations hourly, and marks any revoked key as invalid as soon as it receives a revocation certificate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Multinational Organization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2012/04/orgmtg.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2012/04/orgmtg.jpg&#34; alt=&#34;&#34; width=&#34;300&#34; height=&#34;158&#34; class=&#34;alignleft size-full wp-image-1800&#34; /&gt;&lt;/a&gt;An organization has many members in a number of different countries. Some of the governments are supportive of the organization‚Äôs goals, while some of the governments are strongly hostile and are actively seeking out local members. Many members work in countries where there is little chance of active tracking and monitoring of their use of encryption, while others work in high risk environments from time to time. Certain local contacts and members work in aggressively monitored countries where use of encryption is a flag for the secret police.&lt;/p&gt;

&lt;p&gt;The public figures of the organization in safe countries have a public trust profile that is freely downloadable. They use the public OpenPGP infrastructure and publicly share all public signatures. These members also have private, unpublishable signatures related to the members in high risk situations. Operatives in high risk situations use only unpublishable local signatures and the whole collection of signatures is stored in an encrypted form. There devices only contact keyservers via anonymized connections like Tor or VPNs.&lt;/p&gt;

&lt;p&gt;When members are signing each other‚Äôs keys, the signatures are always sent to the key owner via encrypted email. The signer can then mark the signature as private or public, or their software can be set to always mark all keys as private and unpublishable. When the key owner receives the emailed signature, she can then decide how to manage the signatures: either privately import the signature to their keyring, where it will be stored in an unpublishable format; or publicly import the signature into their keyring and sync it via the public PGP servers. If the signer emailed a private signature to the key owner, then the key management software will automatically make it a private signature.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Improvised movement organized via social software&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/File:Tahrir_Square_during_8_February_2011.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2012/04/Tahrir_Square_during_8_February_2011-300x225.jpg&#34; alt=&#34;&#34; width=&#34;300&#34; height=&#34;225&#34; class=&#34;alignright size-medium wp-image-1791&#34; srcset=&#34;https://guardianproject.info/wp-content/uploads/2012/04/Tahrir_Square_during_8_February_2011-300x225.jpg 300w, https://guardianproject.info/wp-content/uploads/2012/04/Tahrir_Square_during_8_February_2011-1024x768.jpg 1024w, https://guardianproject.info/wp-content/uploads/2012/04/Tahrir_Square_during_8_February_2011.jpg 1600w&#34; sizes=&#34;(max-width: 300px) 100vw, 300px&#34; /&gt;&lt;/a&gt;People from all over a region join a popular movement to help organize protests, distribute media, spread information, etc. Many join in groups of friends or family, but overall the group is not socially well connected together. The common cause is the central binding of the group. In their communications, they want to avoid keyword filtering and communications tracking, as well as try to hinder infiltration and the injection of misinformation. They need to communicate and exchange media with some level of trust. Since the group wants as many members as possible, the infrastructure must be relatively open and public.&lt;/p&gt;

&lt;p&gt;Users who do not have any shared history will trust each other‚Äôs keys on first contact, and rely on the continued validation against the initial mark of trust (known as TOFU/POP or Trust On First Use/Persistence of Pseudonym). Once users build up some context with each other, they can deepen the cryptographic trust by using OTR question/answer or shared secret authentication. Users publicly share their TOFU/POP and OTR marks of trust on public exchanges so that people can build up public trust in their cryptographic identity.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Foreign Journalist, Diplomat, Business Person, etc.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This user is working in a place with active monitoring, tracking and filtering. She has strong links to institutions outside of the country that can help in case of trouble. She has clear outsider status so is able to use encryption and anonymizing software without a large risk of persecution. She wants to keep her communications private in the face of active monitoring.&lt;/p&gt;

&lt;p&gt;Standard public cryptography tools cover most of this situation, but they must be made easier to use, and work on mobile devices. If this user needs encrypted exchanges with locals at high risk of monitoring, local unpublishable signatures can be used in those situations.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On Verifying Identity Using Cryptography</title>
      <link>https://guardianproject.github.io/info/2012/03/19/on-verifying-identity-using-cryptography/</link>
      <pubDate>Mon, 19 Mar 2012 11:27:51 -0400</pubDate>
      
      <guid>https://guardianproject.github.io/info/2012/03/19/on-verifying-identity-using-cryptography/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2012/03/identity.gif&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2012/03/identity-150x150.gif&#34; alt=&#34;&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;alignleft size-thumbnail wp-image-1684&#34; /&gt;&lt;/a&gt;One of the most important uses of cryptography these days is verifying the identity of the other side of a digital conversation. That conversation could be between two people using OTR-encrypted IM, a web browser showing a bank website, a Debian Developer uploading a package to the Debian build server, an ssh client logging into an ssh server, and on and on. In all of these cases, cryptography is used to ensure that the software is indeed receiving replies from the expected entity. This happens by checking the current cryptographic key against one that is known to be correct. That is essential to the whole process. If you see the key for the first time, you have no way of knowing whether that is indeed the key you are expecting because there is no point of reference.&lt;/p&gt;

&lt;p&gt;In order for this validation of identity to work, there needs to be a method of verifying any given key and making it a reference. There are many ideas about how to do this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a trusted list of central certificate authorities like in HTTPS&lt;/li&gt;
&lt;li&gt;key-signing parties where people validate and sign each other‚Äôs keys in person, like used with the OpenPGP Web of Trust&lt;/li&gt;
&lt;li&gt;‚Äútrust on first use‚Äù (aka ‚ÄúPersistence of Pseudonym‚Äù), where you save the key the first time you see it, and then use that as a reference (this is the way most people use SSH)&lt;/li&gt;
&lt;li&gt;fingerprint verification, where the two people wanting to communicate cryptographically use another channel to manually check each other‚Äôs key fingerprints, like a phone call (this is used a lot in OTR and OpenPGP)&lt;/li&gt;
&lt;li&gt;the Socialist Millionaires‚Äô Protocol (SMP), which is a combination of user-generated question/answer pairs with a cryptographic technique that lets each side confirm whether the other answered the question correctly without divulging any information (this was recently added to OTR and is implemented in Pidgin, Gibberbot, and maybe a couple other programs)&lt;/li&gt;
&lt;li&gt;a manually confirmed shared secret like a short password (ZRTP uses this when starting secure phone calls)&lt;/li&gt;
&lt;li&gt;whitelists of fingerprints of widely used keys (aka &lt;a href=&#34;http://www.imperialviolet.org/2011/05/04/pinning.html&#34; target=&#34;_blank&#34;&gt;public key pinning&lt;/a&gt;) (this was recently added to Chrome in the wake of the HTTPS certificate authority failures)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2012/03/fingerprint.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2012/03/fingerprint-150x150.jpg&#34; alt=&#34;&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;alignright size-thumbnail wp-image-1686&#34; /&gt;&lt;/a&gt;Each of these techniques has its advantages and disadvantages, but generally the higher level of verification provided means the more work to do the process. Most people don‚Äôt need the high level of verification provided by OpenPGP key signing parties, but maybe if it was fun and much easier to do, then a lot more people would do it. ‚ÄúTrust on first use‚Äù is really easy to use and implement, and has been working pretty well for a lot of people who use SSH and OTR. But it has big shortcomings in environments where the state or other central authority that provides the internet infrastructure wants to spy on its users. HTTPS has proven to be quite easy to use, but it has also &lt;a href=&#34;https://www.eff.org/deeplinks/2011/08/iranian-man-middle-attack-against-google&#34; target=&#34;_blank&#34;&gt;proven&lt;/a&gt; to be &lt;a href=&#34;http://www.theregister.co.uk/2011/08/29/fraudulent_google_ssl_certificate/&#34; target=&#34;_blank&#34;&gt;quite&lt;/a&gt; &lt;a href=&#34;https://arstechnica.com//security/news/2011/03/how-the-comodo-certificate-fraud-calls-ca-trust-into-question.ars&#34; title=&#34;How the Comodo certificate fraud calls CA trust into question&#34; target=&#34;_blank&#34;&gt;breakable&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Currently, each of these techniques described above is used as the sole means of verification, then the level of verification is represented as ‚Äúverified‚Äù or ‚Äúnot verified‚Äù. This is definitely the way that HTTPS and SSH handle it. OTR is a bit different, it has 3 states of verification: ‚Äúnew key‚Äù, ‚Äúunverified key‚Äù i.e. trusted on first use, or ‚Äúverified‚Äù, and good OTR chat apps will represent these three states in the UI. Then OpenPGP is perhaps the opposite extreme: it provides both chains of verification signatures via the Web of Trust but also user-set ‚Äútrust levels‚Äù from 0 to 255 for any given key.&lt;/p&gt;

&lt;p&gt;Perhaps an answer is to cryptographically link up these different ways of verification and represent key verification as a continuum. Then when the possibility of linking in ‚Äútrust on first use‚Äù and other techniques was there, people could gradually build up cryptographic trust as they needed it. Starting with ‚ÄúI have seen this key before‚Äù, then on to ‚ÄúI have gotten them to verify their OTR key with an SMP question/answer‚Äù, then to ‚ÄúI have an OpenPGP trust path to them‚Äù, to ‚ÄúI have met them in person and manually verified their key and identity‚Äù.&lt;/p&gt;

&lt;p&gt;To go into technical detail as an example, GnuPG supports RSA, DSA, ECDSA, El Gamal, and other key types as subkeys for an OpenPGP key. Those core algorithms core basically all of the most common uses of cryptography, including HTTPS, SSH, OTR, and OpenPGP. The link between an OpenPGP key and its subkeys is perhaps the strongest link for verification that exists, so if a given person includes their OTR key, for example, into their OpenPGP key, that provides a strong cryptographic link between them, and one that is easily publicly sharable via the OpenPGP public keyservers. When two people verify their OTR keys using the SMP question/answer, this verification could then extend to their OpenPGP keys if their OTR keys were subkeys. (&lt;a href=&#34;http://web.monkeysphere.info&#34; target=&#34;_blank&#34;&gt;The Monkeysphere Project&lt;/a&gt; is one such implementation of this idea, using OpenPGP keys for SSH and HTTPS).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://guardianproject.info/wp-content/uploads/2012/03/verified.jpg&#34;&gt;&lt;img src=&#34;https://guardianproject.info/wp-content/uploads/2012/03/verified-150x150.jpg&#34; alt=&#34;&#34; width=&#34;150&#34; height=&#34;150&#34; class=&#34;alignleft size-thumbnail wp-image-1685&#34; /&gt;&lt;/a&gt;Then the last piece of this puzzle is how to represent all of this complexity to the users. The essential part is to stop representing trust as binary yes/no. A one-dimensional continuum provides a lot more info and is a very commonly understood concept in computers (think progress bars). The hard part of this question is ranking the various techniques in how much progress they provide towards the goal of solid identity verification.&lt;/p&gt;

&lt;p&gt;For this round of the &lt;a href=&#34;https://guardianproject.info/wiki/PSST&#34; title=&#34;Portable Shared Security Tokens&#34; target=&#34;_blank&#34;&gt;PSST Project&lt;/a&gt;, we have focused on first allowing people to easily move around their OTR identities, then worked on testing out the idea of linking in all identity keys into an OpenPGP key. From what we have seen so far, we believe this is not only feasible but will provide a solid platform for linking together all these verification techniques and identity keys. And on top of that, with diligent attention to user experience and testing, it should be possible to create user interfaces that make navigating all of this a common, daily task for most computer users.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
